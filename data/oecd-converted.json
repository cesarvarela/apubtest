[
  {
    "@context": [
      "http://localhost:3000/api/schemas/v1/core/context.jsonld",
      "http://localhost:3001/api/schemas/v1/oecd/context.jsonld"
    ],
    "@type": "oecd:Incident",
    "@id": "https://oecd.ai/incident/OECD-2015-001",
    "incident_id": "OECD-2015-001",
    "title": "AI Personal Assistant Shares Private Information in Group Settings",
    "description": "A voice-activated AI assistant failed to recognize multi-user environments and shared personal calendar entries, medical reminders, and financial information when responding to queries in group settings.",
    "date": "2015-02-26",
    "aiSystem": {
      "@type": "oecd:AISystem",
      "name": "Consumer AI System",
      "version": "3.17.42",
      "relation": [
        "oecd:DirectCause"
      ]
    },
    "developer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/Google",
      "name": "Google"
    },
    "deployer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/Wikipedia",
      "name": "Wikipedia"
    },
    "severity": "oecd:SeriousIncident",
    "harmType": [
      "oecd:ReputationalHarm",
      "oecd:HumanRightsHarm"
    ],
    "harmQuantification": {
      "@type": "oecd:HarmQuantification",
      "affected_stakeholders": "16305 users",
      "economic_losses": "$16.8 million"
    },
    "countries": [
      {
        "@type": "core:Country",
        "@id": "https://www.wikidata.org/wiki/United_States",
        "name": "United States"
      }
    ],
    "affectedStakeholders": [
      {
        "@type": "core:Person",
        "@id": "https://example.org/entities/person/black-people",
        "name": "Black people"
      },
      {
        "@type": "oecd:StakeholderGroup",
        "@id": "https://example.org/stakeholder-group/workers",
        "name": "Workers"
      },
      {
        "@type": "core:Person",
        "@id": "https://example.org/entities/person/motorists",
        "name": "Motorists"
      }
    ],
    "businessFunction": [
      "oecd:CustomerService",
      "oecd:ICTManagement"
    ],
    "submitter": {
      "@type": "oecd:Submitter",
      "@id": "https://example.org/submitter/reporter",
      "role": "Industry Whistleblower",
      "affiliation": "AI Safety Coalition",
      "stakeholderGroup": "I represent a government or regulatory body",
      "relationToIncident": "None of the above, but have partial or substantial knowledge of the incident (e.g. first-hand knowledge, research etc.)"
    },
    "unintendedUse": true
  },
  {
    "@context": [
      "http://localhost:3000/api/schemas/v1/core/context.jsonld",
      "http://localhost:3001/api/schemas/v1/oecd/context.jsonld"
    ],
    "@type": "oecd:Incident",
    "@id": "https://oecd.ai/incident/OECD-2015-002",
    "incident_id": "OECD-2015-002",
    "title": "Agricultural AI Misidentifies Crops Leading to Herbicide Damage",
    "description": "An AI-powered crop monitoring and treatment system misidentified valuable crops as weeds, resulting in herbicide application that destroyed thousands of acres of produce. The computer vision model was not properly validated for the specific crop varieties.",
    "date": "2015-03-10",
    "aiSystem": {
      "@type": "oecd:AISystem",
      "name": "Autonomous Systems Engine Pro",
      "version": "1.12.79",
      "relation": [
        "oecd:ContributingFactor"
      ]
    },
    "developer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/MIT_Media_Lab",
      "name": "MIT Media Lab"
    },
    "deployer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/Nest_Labs",
      "name": "Nest Labs"
    },
    "severity": "oecd:SeriousIncident",
    "harmType": [
      "oecd:EconomicHarm",
      "oecd:EnvironmentalHarm"
    ],
    "harmQuantification": {
      "@type": "oecd:HarmQuantification",
      "affected_stakeholders": "57024 individuals",
      "economic_losses": "$27.1 million"
    },
    "countries": [
      {
        "@type": "core:Country",
        "@id": "https://www.wikidata.org/wiki/South_Korea",
        "name": "South Korea"
      },
      {
        "@type": "core:Country",
        "@id": "https://www.wikidata.org/wiki/Netherlands",
        "name": "Netherlands"
      }
    ],
    "affectedStakeholders": [
      {
        "@type": "core:Person",
        "@id": "https://example.org/entities/person/motorists",
        "name": "Motorists"
      },
      {
        "@type": "core:Person",
        "@id": "https://example.org/entities/person/airplane-passengers",
        "name": "Airplane Passengers"
      }
    ],
    "businessFunction": [
      "oecd:Production",
      "oecd:OtherFunction"
    ],
    "submitter": {
      "@type": "oecd:Submitter",
      "@id": "https://example.org/submitter/reporter",
      "role": "Consumer Advocate",
      "affiliation": "Tech Accountability Project",
      "stakeholderGroup": "I am an affected stakeholder",
      "relationToIncident": "None of the above, but have partial or substantial knowledge of the incident (e.g. first-hand knowledge, research etc.)"
    },
    "unintendedUse": false
  },
  {
    "@context": [
      "http://localhost:3000/api/schemas/v1/core/context.jsonld",
      "http://localhost:3001/api/schemas/v1/oecd/context.jsonld"
    ],
    "@type": "oecd:Incident",
    "@id": "https://oecd.ai/incident/OECD-2015-003",
    "incident_id": "OECD-2015-003",
    "title": "AI Interview System Shows Bias Against Non-Native Speakers",
    "description": "An automated video interview analysis system consistently gave lower scores to qualified candidates with accents or non-native speech patterns. The AI's speech recognition and sentiment analysis components showed significant bias.",
    "date": "2015-03-29",
    "aiSystem": {
      "@type": "oecd:AISystem",
      "name": "Workplace AI Solution Pro",
      "version": "1.3.58",
      "relation": [
        "oecd:DirectCause",
        "oecd:ContributingFactor"
      ]
    },
    "developer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/YouTube",
      "name": "YouTube"
    },
    "deployer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/Various_organizations",
      "name": "Various organizations"
    },
    "severity": "oecd:SeriousIncident",
    "harmType": [
      "oecd:EconomicHarm",
      "oecd:HumanRightsHarm"
    ],
    "harmQuantification": {
      "@type": "oecd:HarmQuantification",
      "affected_stakeholders": "52771 workers",
      "economic_losses": "$41.1 million"
    },
    "countries": [
      {
        "@type": "core:Country",
        "@id": "https://www.wikidata.org/wiki/Italy",
        "name": "Italy"
      }
    ],
    "affectedStakeholders": [
      {
        "@type": "oecd:StakeholderGroup",
        "@id": "https://example.org/stakeholder-group/patients",
        "name": "Patients"
      }
    ],
    "businessFunction": [
      "oecd:HRManagement"
    ],
    "submitter": {
      "@type": "oecd:Submitter",
      "@id": "https://example.org/submitter/reporter",
      "role": "Academic Researcher",
      "affiliation": "Digital Rights Organization",
      "stakeholderGroup": "I work or am affiliated to a public interest body or NGO",
      "relationToIncident": "None of the above, but have partial or substantial knowledge of the incident (e.g. first-hand knowledge, research etc.)"
    },
    "unintendedUse": false
  },
  {
    "@context": [
      "http://localhost:3000/api/schemas/v1/core/context.jsonld",
      "http://localhost:3001/api/schemas/v1/oecd/context.jsonld"
    ],
    "@type": "oecd:Incident",
    "@id": "https://oecd.ai/incident/OECD-2015-004",
    "incident_id": "OECD-2015-004",
    "title": "Algorithmic Trading System Triggers Market Manipulation Investigation",
    "description": "High-frequency trading algorithms were found to be creating artificial price movements through coordinated trades. The AI systems learned to exploit market microstructure in ways that resembled illegal manipulation.",
    "date": "2015-04-01",
    "aiSystem": {
      "@type": "oecd:AISystem",
      "name": "Financial AI System Pro",
      "version": "1.14.45",
      "relation": [
        "oecd:DirectCause",
        "oecd:FailureToAct"
      ]
    },
    "developer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/The_DAO",
      "name": "The DAO"
    },
    "deployer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/New_York_city_Dept._of_Education",
      "name": "New York city Dept. of Education"
    },
    "severity": "oecd:SeriousHazard",
    "harmType": [
      "oecd:EconomicHarm",
      "oecd:PublicInterestHarm"
    ],
    "harmQuantification": {
      "@type": "oecd:HarmQuantification",
      "affected_stakeholders": "69747 individuals",
      "economic_losses": "$49.0 million"
    },
    "countries": [
      {
        "@type": "core:Country",
        "@id": "https://www.wikidata.org/wiki/United_Kingdom",
        "name": "United Kingdom"
      },
      {
        "@type": "core:Country",
        "@id": "https://www.wikidata.org/wiki/Brazil",
        "name": "Brazil"
      }
    ],
    "affectedStakeholders": [
      {
        "@type": "core:Person",
        "@id": "https://example.org/entities/person/black-people",
        "name": "Black people"
      }
    ],
    "businessFunction": [
      "oecd:OtherFunction"
    ],
    "submitter": {
      "@type": "oecd:Submitter",
      "@id": "https://example.org/submitter/reporter",
      "role": "Consumer Advocate",
      "affiliation": "AI Safety Coalition",
      "stakeholderGroup": "None of the above, but have partial or substantial knowledge of the incident",
      "relationToIncident": "None of the above, but have partial or substantial knowledge of the incident (e.g. first-hand knowledge, research etc.)"
    },
    "unintendedUse": false
  },
  {
    "@context": [
      "http://localhost:3000/api/schemas/v1/core/context.jsonld",
      "http://localhost:3001/api/schemas/v1/oecd/context.jsonld"
    ],
    "@type": "oecd:Incident",
    "@id": "https://oecd.ai/incident/OECD-2015-005",
    "incident_id": "OECD-2015-005",
    "title": "Surgical Robot Malfunction During Minimally Invasive Procedure",
    "description": "An AI-assisted surgical robot experienced a control system failure during a procedure, requiring emergency conversion to traditional surgery. The AI's motion planning algorithms failed to account for unexpected tissue resistance.",
    "date": "2015-04-07",
    "aiSystem": {
      "@type": "oecd:AISystem",
      "name": "Medical AI System",
      "version": "10.12.68",
      "relation": [
        "oecd:ContributingFactor",
        "oecd:HumanError"
      ]
    },
    "developer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/Delphi_Technologies",
      "name": "Delphi Technologies"
    },
    "deployer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/Apple_Inc.",
      "name": "Apple"
    },
    "severity": "oecd:SeriousIncident",
    "harmType": [
      "oecd:PhysicalHarm"
    ],
    "harmQuantification": {
      "@type": "oecd:HarmQuantification",
      "affected_stakeholders": "17960 users",
      "economic_losses": "$4.0 million"
    },
    "countries": [
      {
        "@type": "core:Country",
        "@id": "https://www.wikidata.org/wiki/Singapore",
        "name": "Singapore"
      }
    ],
    "affectedStakeholders": [
      {
        "@type": "core:Person",
        "@id": "https://example.org/entities/person/job-applicants",
        "name": "Job applicants"
      }
    ],
    "businessFunction": [
      "oecd:OtherFunction"
    ],
    "submitter": {
      "@type": "oecd:Submitter",
      "@id": "https://example.org/submitter/reporter",
      "role": "Consumer Advocate",
      "affiliation": "AI Safety Coalition",
      "stakeholderGroup": "I work or am affiliated to a public interest body or NGO",
      "relationToIncident": "None of the above, but have partial or substantial knowledge of the incident (e.g. first-hand knowledge, research etc.)"
    },
    "unintendedUse": false
  },
  {
    "@context": [
      "http://localhost:3000/api/schemas/v1/core/context.jsonld",
      "http://localhost:3001/api/schemas/v1/oecd/context.jsonld"
    ],
    "@type": "oecd:Incident",
    "@id": "https://oecd.ai/incident/OECD-2015-006",
    "incident_id": "OECD-2015-006",
    "title": "Surgical Robot Malfunction During Minimally Invasive Procedure",
    "description": "An AI-assisted surgical robot experienced a control system failure during a procedure, requiring emergency conversion to traditional surgery. The AI's motion planning algorithms failed to account for unexpected tissue resistance.",
    "date": "2015-05-30",
    "aiSystem": {
      "@type": "oecd:AISystem",
      "name": "Medical AI Engine Pro",
      "version": "4.15.18",
      "relation": [
        "oecd:ContributingFactor",
        "oecd:HumanError"
      ]
    },
    "developer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/Wikipedia",
      "name": "Wikipedia"
    },
    "deployer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/YouTube",
      "name": "YouTube"
    },
    "severity": "oecd:SeriousIncident",
    "harmType": [
      "oecd:PhysicalHarm"
    ],
    "harmQuantification": {
      "@type": "oecd:HarmQuantification",
      "affected_stakeholders": "34427 users"
    },
    "countries": [
      {
        "@type": "core:Country",
        "@id": "https://www.wikidata.org/wiki/Singapore",
        "name": "Singapore"
      },
      {
        "@type": "core:Country",
        "@id": "https://www.wikidata.org/wiki/France",
        "name": "France"
      }
    ],
    "affectedStakeholders": [
      {
        "@type": "oecd:StakeholderGroup",
        "@id": "https://example.org/stakeholder-group/children",
        "name": "Children"
      },
      {
        "@type": "core:Person",
        "@id": "https://example.org/entities/person/medical-residents",
        "name": "Medical Residents"
      }
    ],
    "businessFunction": [
      "oecd:OtherFunction"
    ],
    "submitter": {
      "@type": "oecd:Submitter",
      "@id": "https://example.org/submitter/reporter",
      "role": "Industry Whistleblower",
      "affiliation": "Consumer Protection Agency",
      "stakeholderGroup": "I work or am affiliated to a public interest body or NGO",
      "relationToIncident": "None of the above, but have partial or substantial knowledge of the incident (e.g. first-hand knowledge, research etc.)"
    },
    "unintendedUse": false
  },
  {
    "@context": [
      "http://localhost:3000/api/schemas/v1/core/context.jsonld",
      "http://localhost:3001/api/schemas/v1/oecd/context.jsonld"
    ],
    "@type": "oecd:Incident",
    "@id": "https://oecd.ai/incident/OECD-2015-007",
    "incident_id": "OECD-2015-007",
    "title": "Facial Recognition System Falsely Identifies Protesters as Criminals",
    "description": "A law enforcement facial recognition system incorrectly matched peaceful protesters with criminal database entries, leading to wrongful detentions. The AI system showed higher error rates for certain ethnic groups and in crowded scenarios.",
    "date": "2015-06-04",
    "aiSystem": {
      "@type": "oecd:AISystem",
      "name": "Security/Surveillance System Pro",
      "version": "7.4.91",
      "relation": [
        "oecd:DirectCause"
      ]
    },
    "developer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/Apple_Inc.",
      "name": "Apple"
    },
    "deployer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/YouTube",
      "name": "YouTube"
    },
    "severity": "oecd:SeriousIncident",
    "harmType": [
      "oecd:PhysicalHarm",
      "oecd:HumanRightsHarm",
      "oecd:ReputationalHarm"
    ],
    "harmQuantification": {
      "@type": "oecd:HarmQuantification",
      "affected_stakeholders": "85821 workers"
    },
    "countries": [
      {
        "@type": "core:Country",
        "@id": "https://www.wikidata.org/wiki/Brazil",
        "name": "Brazil"
      }
    ],
    "affectedStakeholders": [
      {
        "@type": "core:Person",
        "@id": "https://example.org/entities/person/black-people",
        "name": "Black people"
      },
      {
        "@type": "core:Person",
        "@id": "https://example.org/entities/person/bus-passengers",
        "name": "Bus passengers"
      }
    ],
    "businessFunction": [
      "oecd:Compliance"
    ],
    "submitter": {
      "@type": "oecd:Submitter",
      "@id": "https://example.org/submitter/reporter",
      "role": "Government Auditor",
      "affiliation": "AI Safety Coalition",
      "stakeholderGroup": "I work or am affiliated to a public interest body or NGO",
      "relationToIncident": "None of the above, but have partial or substantial knowledge of the incident (e.g. first-hand knowledge, research etc.)"
    },
    "unintendedUse": false
  },
  {
    "@context": [
      "http://localhost:3000/api/schemas/v1/core/context.jsonld",
      "http://localhost:3001/api/schemas/v1/oecd/context.jsonld"
    ],
    "@type": "oecd:Incident",
    "@id": "https://oecd.ai/incident/OECD-2015-008",
    "incident_id": "OECD-2015-008",
    "title": "AI Diagnostic System Misses Critical Symptoms in Emergency Department",
    "description": "An AI triage system in emergency departments failed to identify critical symptoms in patients presenting with atypical manifestations of serious conditions. The system's training data lacked diversity in symptom presentations across different demographics.",
    "date": "2015-07-11",
    "aiSystem": {
      "@type": "oecd:AISystem",
      "name": "Medical AI Platform Pro",
      "version": "4.13.21",
      "relation": [
        "oecd:DirectCause"
      ]
    },
    "developer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/Uber",
      "name": "Uber"
    },
    "deployer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/St_George's_Hospital_Medical_School",
      "name": "St George's Hospital Medical School"
    },
    "severity": "oecd:SeriousHazard",
    "harmType": [
      "oecd:PhysicalHarm",
      "oecd:HumanRightsHarm"
    ],
    "harmQuantification": {
      "@type": "oecd:HarmQuantification",
      "affected_stakeholders": "49783 workers",
      "economic_losses": "$44.0 million"
    },
    "countries": [
      {
        "@type": "core:Country",
        "@id": "https://www.wikidata.org/wiki/United_States",
        "name": "United States"
      },
      {
        "@type": "core:Country",
        "@id": "https://www.wikidata.org/wiki/China",
        "name": "China"
      }
    ],
    "affectedStakeholders": [
      {
        "@type": "oecd:StakeholderGroup",
        "@id": "https://example.org/stakeholder-group/patients",
        "name": "Patients"
      },
      {
        "@type": "oecd:StakeholderGroup",
        "@id": "https://example.org/stakeholder-group/minority-groups",
        "name": "Minority Groups"
      }
    ],
    "businessFunction": [
      "oecd:OtherFunction"
    ],
    "submitter": {
      "@type": "oecd:Submitter",
      "@id": "https://example.org/submitter/reporter",
      "role": "Consumer Advocate",
      "affiliation": "Consumer Protection Agency",
      "stakeholderGroup": "I represent a government or regulatory body",
      "relationToIncident": "None of the above, but have partial or substantial knowledge of the incident (e.g. first-hand knowledge, research etc.)"
    },
    "unintendedUse": false
  },
  {
    "@context": [
      "http://localhost:3000/api/schemas/v1/core/context.jsonld",
      "http://localhost:3001/api/schemas/v1/oecd/context.jsonld"
    ],
    "@type": "oecd:Incident",
    "@id": "https://oecd.ai/incident/OECD-2015-009",
    "incident_id": "OECD-2015-009",
    "title": "Surgical Robot Malfunction During Minimally Invasive Procedure",
    "description": "An AI-assisted surgical robot experienced a control system failure during a procedure, requiring emergency conversion to traditional surgery. The AI's motion planning algorithms failed to account for unexpected tissue resistance.",
    "date": "2015-07-12",
    "aiSystem": {
      "@type": "oecd:AISystem",
      "name": "Medical AI Engine Pro",
      "version": "4.19.87",
      "relation": [
        "oecd:ContributingFactor"
      ]
    },
    "developer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/Frontier_Development",
      "name": "Frontier Development"
    },
    "deployer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/United_States_Government",
      "name": "United States Government"
    },
    "severity": "oecd:SeriousIncident",
    "harmType": [
      "oecd:PhysicalHarm"
    ],
    "harmQuantification": {
      "@type": "oecd:HarmQuantification",
      "affected_stakeholders": "90773 workers",
      "economic_losses": "$17.4 million"
    },
    "countries": [
      {
        "@type": "core:Country",
        "@id": "https://www.wikidata.org/wiki/India",
        "name": "India"
      }
    ],
    "affectedStakeholders": [
      {
        "@type": "core:Person",
        "@id": "https://example.org/entities/person/black-people",
        "name": "Black people"
      },
      {
        "@type": "core:Person",
        "@id": "https://example.org/entities/person/pedestrians",
        "name": "Pedestrians"
      }
    ],
    "businessFunction": [
      "oecd:OtherFunction"
    ],
    "submitter": {
      "@type": "oecd:Submitter",
      "@id": "https://example.org/submitter/reporter",
      "role": "Safety Engineer",
      "affiliation": "Tech Accountability Project",
      "stakeholderGroup": "I represent a government or regulatory body",
      "relationToIncident": "None of the above, but have partial or substantial knowledge of the incident (e.g. first-hand knowledge, research etc.)"
    },
    "unintendedUse": false
  },
  {
    "@context": [
      "http://localhost:3000/api/schemas/v1/core/context.jsonld",
      "http://localhost:3001/api/schemas/v1/oecd/context.jsonld"
    ],
    "@type": "oecd:Incident",
    "@id": "https://oecd.ai/incident/OECD-2015-010",
    "incident_id": "OECD-2015-010",
    "title": "AI Personal Assistant Shares Private Information in Group Settings",
    "description": "A voice-activated AI assistant failed to recognize multi-user environments and shared personal calendar entries, medical reminders, and financial information when responding to queries in group settings.",
    "date": "2015-08-06",
    "aiSystem": {
      "@type": "oecd:AISystem",
      "name": "Consumer AI Solution Pro",
      "version": "5.8.43",
      "relation": [
        "oecd:ContributingFactor",
        "oecd:HumanError"
      ]
    },
    "developer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/Northpointe",
      "name": "Northpointe"
    },
    "deployer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/Uber",
      "name": "Uber"
    },
    "severity": "oecd:SeriousIncident",
    "harmType": [
      "oecd:ReputationalHarm",
      "oecd:HumanRightsHarm"
    ],
    "harmQuantification": {
      "@type": "oecd:HarmQuantification",
      "affected_stakeholders": "1895 customers",
      "economic_losses": "$10.6 million"
    },
    "countries": [
      {
        "@type": "core:Country",
        "@id": "https://www.wikidata.org/wiki/South_Korea",
        "name": "South Korea"
      },
      {
        "@type": "core:Country",
        "@id": "https://www.wikidata.org/wiki/United_States",
        "name": "United States"
      }
    ],
    "affectedStakeholders": [
      {
        "@type": "oecd:StakeholderGroup",
        "@id": "https://example.org/stakeholder-group/workers",
        "name": "Workers"
      },
      {
        "@type": "oecd:StakeholderGroup",
        "@id": "https://example.org/stakeholder-group/minority-groups",
        "name": "Minority Groups"
      },
      {
        "@type": "core:Person",
        "@id": "https://example.org/entities/person/job-applicants",
        "name": "Job applicants"
      }
    ],
    "businessFunction": [
      "oecd:CustomerService",
      "oecd:ICTManagement"
    ],
    "submitter": {
      "@type": "oecd:Submitter",
      "@id": "https://example.org/submitter/reporter",
      "role": "Government Auditor",
      "affiliation": "University Ethics Lab",
      "stakeholderGroup": "None of the above, but have partial or substantial knowledge of the incident",
      "relationToIncident": "None of the above, but have partial or substantial knowledge of the incident (e.g. first-hand knowledge, research etc.)"
    },
    "unintendedUse": false
  },
  {
    "@context": [
      "http://localhost:3000/api/schemas/v1/core/context.jsonld",
      "http://localhost:3001/api/schemas/v1/oecd/context.jsonld"
    ],
    "@type": "oecd:Incident",
    "@id": "https://oecd.ai/incident/OECD-2015-011",
    "incident_id": "OECD-2015-011",
    "title": "Surgical Robot Malfunction During Minimally Invasive Procedure",
    "description": "An AI-assisted surgical robot experienced a control system failure during a procedure, requiring emergency conversion to traditional surgery. The AI's motion planning algorithms failed to account for unexpected tissue resistance.",
    "date": "2015-08-27",
    "aiSystem": {
      "@type": "oecd:AISystem",
      "name": "Medical AI Engine Pro",
      "version": "2.5.59",
      "relation": [
        "oecd:DirectCause"
      ]
    },
    "developer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/Volkswagen",
      "name": "Volkswagen"
    },
    "deployer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/Google",
      "name": "Google"
    },
    "severity": "oecd:SeriousIncident",
    "harmType": [
      "oecd:PhysicalHarm"
    ],
    "harmQuantification": {
      "@type": "oecd:HarmQuantification",
      "affected_stakeholders": "17547 patients",
      "economic_losses": "$17.3 million"
    },
    "countries": [
      {
        "@type": "core:Country",
        "@id": "https://www.wikidata.org/wiki/Mexico",
        "name": "Mexico"
      }
    ],
    "affectedStakeholders": [
      {
        "@type": "oecd:StakeholderGroup",
        "@id": "https://example.org/stakeholder-group/workers",
        "name": "Workers"
      },
      {
        "@type": "oecd:StakeholderGroup",
        "@id": "https://example.org/stakeholder-group/patients",
        "name": "Patients"
      },
      {
        "@type": "oecd:StakeholderGroup",
        "@id": "https://example.org/stakeholder-group/children",
        "name": "Children"
      }
    ],
    "businessFunction": [
      "oecd:OtherFunction"
    ],
    "submitter": {
      "@type": "oecd:Submitter",
      "@id": "https://example.org/submitter/reporter",
      "role": "Government Auditor",
      "affiliation": "Digital Rights Organization",
      "stakeholderGroup": "I work or am affiliated to a public interest body or NGO",
      "relationToIncident": "None of the above, but have partial or substantial knowledge of the incident (e.g. first-hand knowledge, research etc.)"
    },
    "unintendedUse": false
  },
  {
    "@context": [
      "http://localhost:3000/api/schemas/v1/core/context.jsonld",
      "http://localhost:3001/api/schemas/v1/oecd/context.jsonld"
    ],
    "@type": "oecd:Incident",
    "@id": "https://oecd.ai/incident/OECD-2015-012",
    "incident_id": "OECD-2015-012",
    "title": "AI Diagnostic System Misses Critical Symptoms in Emergency Department",
    "description": "An AI triage system in emergency departments failed to identify critical symptoms in patients presenting with atypical manifestations of serious conditions. The system's training data lacked diversity in symptom presentations across different demographics.",
    "date": "2015-10-02",
    "aiSystem": {
      "@type": "oecd:AISystem",
      "name": "Medical AI Engine",
      "version": "7.5.72",
      "relation": [
        "oecd:ContributingFactor"
      ]
    },
    "developer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/Volkswagen",
      "name": "Volkswagen"
    },
    "deployer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/New_York_city_Dept._of_Education",
      "name": "New York city Dept. of Education"
    },
    "severity": "oecd:SeriousHazard",
    "harmType": [
      "oecd:PhysicalHarm",
      "oecd:HumanRightsHarm"
    ],
    "harmQuantification": {
      "@type": "oecd:HarmQuantification",
      "affected_stakeholders": "49767 individuals"
    },
    "countries": [
      {
        "@type": "core:Country",
        "@id": "https://www.wikidata.org/wiki/Australia",
        "name": "Australia"
      },
      {
        "@type": "core:Country",
        "@id": "https://www.wikidata.org/wiki/France",
        "name": "France"
      }
    ],
    "affectedStakeholders": [
      {
        "@type": "oecd:StakeholderGroup",
        "@id": "https://example.org/stakeholder-group/women",
        "name": "Women"
      },
      {
        "@type": "oecd:StakeholderGroup",
        "@id": "https://example.org/stakeholder-group/workers",
        "name": "Workers"
      }
    ],
    "businessFunction": [
      "oecd:OtherFunction"
    ],
    "submitter": {
      "@type": "oecd:Submitter",
      "@id": "https://example.org/submitter/reporter",
      "role": "Industry Whistleblower",
      "affiliation": "AI Safety Coalition",
      "stakeholderGroup": "I am an affected stakeholder",
      "relationToIncident": "None of the above, but have partial or substantial knowledge of the incident (e.g. first-hand knowledge, research etc.)"
    },
    "unintendedUse": false
  },
  {
    "@context": [
      "http://localhost:3000/api/schemas/v1/core/context.jsonld",
      "http://localhost:3001/api/schemas/v1/oecd/context.jsonld"
    ],
    "@type": "oecd:Incident",
    "@id": "https://oecd.ai/incident/OECD-2015-013",
    "incident_id": "OECD-2015-013",
    "title": "AI Diagnostic System Misses Critical Symptoms in Emergency Department",
    "description": "An AI triage system in emergency departments failed to identify critical symptoms in patients presenting with atypical manifestations of serious conditions. The system's training data lacked diversity in symptom presentations across different demographics.",
    "date": "2015-10-20",
    "aiSystem": {
      "@type": "oecd:AISystem",
      "name": "Medical AI Engine Pro",
      "version": "8.13.15",
      "relation": [
        "oecd:ContributingFactor",
        "oecd:HumanError"
      ]
    },
    "developer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/Wikipedia",
      "name": "Wikipedia"
    },
    "deployer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/Delphi_Technologies",
      "name": "Delphi Technologies"
    },
    "severity": "oecd:SeriousHazard",
    "harmType": [
      "oecd:PhysicalHarm",
      "oecd:HumanRightsHarm"
    ],
    "harmQuantification": {
      "@type": "oecd:HarmQuantification",
      "affected_stakeholders": "85473 patients",
      "economic_losses": "$19.6 million"
    },
    "countries": [
      {
        "@type": "core:Country",
        "@id": "https://www.wikidata.org/wiki/Netherlands",
        "name": "Netherlands"
      },
      {
        "@type": "core:Country",
        "@id": "https://www.wikidata.org/wiki/Italy",
        "name": "Italy"
      }
    ],
    "affectedStakeholders": [
      {
        "@type": "core:Person",
        "@id": "https://example.org/entities/person/job-applicants",
        "name": "Job applicants"
      },
      {
        "@type": "core:Person",
        "@id": "https://example.org/entities/person/bus-passengers",
        "name": "Bus passengers"
      },
      {
        "@type": "oecd:StakeholderGroup",
        "@id": "https://example.org/stakeholder-group/consumers",
        "name": "Consumers"
      }
    ],
    "businessFunction": [
      "oecd:OtherFunction"
    ],
    "submitter": {
      "@type": "oecd:Submitter",
      "@id": "https://example.org/submitter/reporter",
      "role": "Academic Researcher",
      "affiliation": "University Ethics Lab",
      "stakeholderGroup": "I represent a government or regulatory body",
      "relationToIncident": "None of the above, but have partial or substantial knowledge of the incident (e.g. first-hand knowledge, research etc.)"
    },
    "unintendedUse": false
  },
  {
    "@context": [
      "http://localhost:3000/api/schemas/v1/core/context.jsonld",
      "http://localhost:3001/api/schemas/v1/oecd/context.jsonld"
    ],
    "@type": "oecd:Incident",
    "@id": "https://oecd.ai/incident/OECD-2015-014",
    "incident_id": "OECD-2015-014",
    "title": "Smart Home AI Creates Dangerous Living Conditions for Elderly",
    "description": "An AI-powered smart home system learned incorrect patterns from an elderly resident with dementia, subsequently creating dangerous conditions by adjusting heating, lighting, and security settings inappropriately.",
    "date": "2015-10-31",
    "aiSystem": {
      "@type": "oecd:AISystem",
      "name": "Consumer AI System Pro",
      "version": "8.3.16",
      "relation": [
        "oecd:ContributingFactor"
      ]
    },
    "developer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/Keolis",
      "name": "Keolis North America"
    },
    "deployer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/Microsoft",
      "name": "Microsoft"
    },
    "severity": "oecd:SeriousHazard",
    "harmType": [
      "oecd:PhysicalHarm",
      "oecd:PsychologicalHarm"
    ],
    "harmQuantification": {
      "@type": "oecd:HarmQuantification",
      "affected_stakeholders": "10402 workers",
      "economic_losses": "$36.1 million",
      "psychological_impact": "Documented stress and anxiety in affected population"
    },
    "countries": [
      {
        "@type": "core:Country",
        "@id": "https://www.wikidata.org/wiki/Sweden",
        "name": "Sweden"
      },
      {
        "@type": "core:Country",
        "@id": "https://www.wikidata.org/wiki/United_States",
        "name": "United States"
      }
    ],
    "affectedStakeholders": [
      {
        "@type": "core:Person",
        "@id": "https://example.org/entities/person/motorists",
        "name": "Motorists"
      }
    ],
    "businessFunction": [
      "oecd:CustomerService",
      "oecd:OtherFunction"
    ],
    "submitter": {
      "@type": "oecd:Submitter",
      "@id": "https://example.org/submitter/reporter",
      "role": "Data Scientist",
      "affiliation": "University Ethics Lab",
      "stakeholderGroup": "None of the above, but have partial or substantial knowledge of the incident",
      "relationToIncident": "None of the above, but have partial or substantial knowledge of the incident (e.g. first-hand knowledge, research etc.)"
    },
    "unintendedUse": false
  },
  {
    "@context": [
      "http://localhost:3000/api/schemas/v1/core/context.jsonld",
      "http://localhost:3001/api/schemas/v1/oecd/context.jsonld"
    ],
    "@type": "oecd:Incident",
    "@id": "https://oecd.ai/incident/OECD-2015-015",
    "incident_id": "OECD-2015-015",
    "title": "Predictive Policing Algorithm Creates Feedback Loops in Minority Neighborhoods",
    "description": "An AI system for predicting crime hotspots consistently directed more police presence to minority neighborhoods, creating a self-reinforcing cycle where increased police presence led to more reported incidents, further biasing the algorithm.",
    "date": "2015-12-23",
    "aiSystem": {
      "@type": "oecd:AISystem",
      "name": "Security/Surveillance Solution",
      "version": "10.11.70",
      "relation": [
        "oecd:DirectCause",
        "oecd:FailureToAct"
      ]
    },
    "developer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/USC_Information_Sciences_Institute",
      "name": "USC Information Sciences Institute"
    },
    "deployer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/LinkedIn",
      "name": "LinkedIn"
    },
    "severity": "oecd:SeriousHazard",
    "harmType": [
      "oecd:HumanRightsHarm",
      "oecd:PsychologicalHarm"
    ],
    "harmQuantification": {
      "@type": "oecd:HarmQuantification",
      "affected_stakeholders": "52889 individuals",
      "psychological_impact": "Documented stress and anxiety in affected population"
    },
    "countries": [
      {
        "@type": "core:Country",
        "@id": "https://www.wikidata.org/wiki/Netherlands",
        "name": "Netherlands"
      },
      {
        "@type": "core:Country",
        "@id": "https://www.wikidata.org/wiki/Brazil",
        "name": "Brazil"
      }
    ],
    "affectedStakeholders": [
      {
        "@type": "oecd:StakeholderGroup",
        "@id": "https://example.org/stakeholder-group/children",
        "name": "Children"
      }
    ],
    "businessFunction": [
      "oecd:Compliance",
      "oecd:Planning"
    ],
    "submitter": {
      "@type": "oecd:Submitter",
      "@id": "https://example.org/submitter/reporter",
      "role": "Government Auditor",
      "affiliation": "Tech Accountability Project",
      "stakeholderGroup": "None of the above, but have partial or substantial knowledge of the incident",
      "relationToIncident": "None of the above, but have partial or substantial knowledge of the incident (e.g. first-hand knowledge, research etc.)"
    },
    "unintendedUse": false
  },
  {
    "@context": [
      "http://localhost:3000/api/schemas/v1/core/context.jsonld",
      "http://localhost:3001/api/schemas/v1/oecd/context.jsonld"
    ],
    "@type": "oecd:Incident",
    "@id": "https://oecd.ai/incident/OECD-2015-016",
    "incident_id": "OECD-2015-016",
    "title": "Facial Recognition System Falsely Identifies Protesters as Criminals",
    "description": "A law enforcement facial recognition system incorrectly matched peaceful protesters with criminal database entries, leading to wrongful detentions. The AI system showed higher error rates for certain ethnic groups and in crowded scenarios.",
    "date": "2015-12-25",
    "aiSystem": {
      "@type": "oecd:AISystem",
      "name": "Security/Surveillance Platform Pro",
      "version": "3.17.9",
      "relation": [
        "oecd:DirectCause",
        "oecd:ContributingFactor"
      ]
    },
    "developer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/Frontier_Development",
      "name": "Frontier Development"
    },
    "deployer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/YouTube",
      "name": "YouTube"
    },
    "severity": "oecd:SeriousIncident",
    "harmType": [
      "oecd:PhysicalHarm",
      "oecd:HumanRightsHarm",
      "oecd:ReputationalHarm"
    ],
    "harmQuantification": {
      "@type": "oecd:HarmQuantification",
      "affected_stakeholders": "23101 individuals",
      "economic_losses": "$17.9 million"
    },
    "countries": [
      {
        "@type": "core:Country",
        "@id": "https://www.wikidata.org/wiki/United_States",
        "name": "United States"
      },
      {
        "@type": "core:Country",
        "@id": "https://www.wikidata.org/wiki/India",
        "name": "India"
      }
    ],
    "affectedStakeholders": [
      {
        "@type": "core:Person",
        "@id": "https://example.org/entities/person/job-applicants",
        "name": "Job applicants"
      },
      {
        "@type": "oecd:StakeholderGroup",
        "@id": "https://example.org/stakeholder-group/consumers",
        "name": "Consumers"
      },
      {
        "@type": "oecd:StakeholderGroup",
        "@id": "https://example.org/stakeholder-group/minority-groups",
        "name": "Minority Groups"
      }
    ],
    "businessFunction": [
      "oecd:Compliance"
    ],
    "submitter": {
      "@type": "oecd:Submitter",
      "@id": "https://example.org/submitter/reporter",
      "role": "Data Scientist",
      "affiliation": "Consumer Protection Agency",
      "stakeholderGroup": "I work or am affiliated to a public interest body or NGO",
      "relationToIncident": "None of the above, but have partial or substantial knowledge of the incident (e.g. first-hand knowledge, research etc.)"
    },
    "unintendedUse": false
  },
  {
    "@context": [
      "http://localhost:3000/api/schemas/v1/core/context.jsonld",
      "http://localhost:3001/api/schemas/v1/oecd/context.jsonld"
    ],
    "@type": "oecd:Incident",
    "@id": "https://oecd.ai/incident/OECD-2016-017",
    "incident_id": "OECD-2016-017",
    "title": "AI Interview System Shows Bias Against Non-Native Speakers",
    "description": "An automated video interview analysis system consistently gave lower scores to qualified candidates with accents or non-native speech patterns. The AI's speech recognition and sentiment analysis components showed significant bias.",
    "date": "2016-01-24",
    "aiSystem": {
      "@type": "oecd:AISystem",
      "name": "Workplace AI Engine Pro",
      "version": "3.6.96",
      "relation": [
        "oecd:ContributingFactor",
        "oecd:HumanError"
      ]
    },
    "developer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/Tesla,_Inc.",
      "name": "Tesla"
    },
    "deployer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/Apple_Inc.",
      "name": "Apple"
    },
    "severity": "oecd:SeriousIncident",
    "harmType": [
      "oecd:EconomicHarm",
      "oecd:HumanRightsHarm"
    ],
    "harmQuantification": {
      "@type": "oecd:HarmQuantification",
      "affected_stakeholders": "35551 users",
      "economic_losses": "$24.6 million"
    },
    "countries": [
      {
        "@type": "core:Country",
        "@id": "https://www.wikidata.org/wiki/Japan",
        "name": "Japan"
      },
      {
        "@type": "core:Country",
        "@id": "https://www.wikidata.org/wiki/Brazil",
        "name": "Brazil"
      }
    ],
    "affectedStakeholders": [
      {
        "@type": "core:Person",
        "@id": "https://example.org/entities/person/pedestrians",
        "name": "Pedestrians"
      }
    ],
    "businessFunction": [
      "oecd:HRManagement"
    ],
    "submitter": {
      "@type": "oecd:Submitter",
      "@id": "https://example.org/submitter/reporter",
      "role": "Data Scientist",
      "affiliation": "Digital Rights Organization",
      "stakeholderGroup": "I am an affected stakeholder",
      "relationToIncident": "None of the above, but have partial or substantial knowledge of the incident (e.g. first-hand knowledge, research etc.)"
    },
    "unintendedUse": false
  },
  {
    "@context": [
      "http://localhost:3000/api/schemas/v1/core/context.jsonld",
      "http://localhost:3001/api/schemas/v1/oecd/context.jsonld"
    ],
    "@type": "oecd:Incident",
    "@id": "https://oecd.ai/incident/OECD-2016-018",
    "incident_id": "OECD-2016-018",
    "title": "AI Personal Assistant Shares Private Information in Group Settings",
    "description": "A voice-activated AI assistant failed to recognize multi-user environments and shared personal calendar entries, medical reminders, and financial information when responding to queries in group settings.",
    "date": "2016-01-25",
    "aiSystem": {
      "@type": "oecd:AISystem",
      "name": "Consumer AI Engine Pro",
      "version": "10.17.57",
      "relation": [
        "oecd:DirectCause",
        "oecd:FailureToAct"
      ]
    },
    "developer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/Google",
      "name": "Google"
    },
    "deployer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/Amazon_(company)",
      "name": "Amazon"
    },
    "severity": "oecd:SeriousIncident",
    "harmType": [
      "oecd:ReputationalHarm",
      "oecd:HumanRightsHarm"
    ],
    "harmQuantification": {
      "@type": "oecd:HarmQuantification",
      "affected_stakeholders": "58582 individuals",
      "economic_losses": "$25.5 million"
    },
    "countries": [
      {
        "@type": "core:Country",
        "@id": "https://www.wikidata.org/wiki/France",
        "name": "France"
      }
    ],
    "affectedStakeholders": [
      {
        "@type": "oecd:StakeholderGroup",
        "@id": "https://example.org/stakeholder-group/children",
        "name": "Children"
      },
      {
        "@type": "core:Person",
        "@id": "https://example.org/entities/person/black-people",
        "name": "Black people"
      },
      {
        "@type": "oecd:StakeholderGroup",
        "@id": "https://example.org/stakeholder-group/minority-groups",
        "name": "Minority Groups"
      }
    ],
    "businessFunction": [
      "oecd:CustomerService",
      "oecd:ICTManagement"
    ],
    "submitter": {
      "@type": "oecd:Submitter",
      "@id": "https://example.org/submitter/reporter",
      "role": "Academic Researcher",
      "affiliation": "Consumer Protection Agency",
      "stakeholderGroup": "I work or am affiliated to a public interest body or NGO",
      "relationToIncident": "None of the above, but have partial or substantial knowledge of the incident (e.g. first-hand knowledge, research etc.)"
    },
    "unintendedUse": false
  },
  {
    "@context": [
      "http://localhost:3000/api/schemas/v1/core/context.jsonld",
      "http://localhost:3001/api/schemas/v1/oecd/context.jsonld"
    ],
    "@type": "oecd:Incident",
    "@id": "https://oecd.ai/incident/OECD-2016-019",
    "incident_id": "OECD-2016-019",
    "title": "AI Diagnostic System Misses Critical Symptoms in Emergency Department",
    "description": "An AI triage system in emergency departments failed to identify critical symptoms in patients presenting with atypical manifestations of serious conditions. The system's training data lacked diversity in symptom presentations across different demographics.",
    "date": "2016-03-06",
    "aiSystem": {
      "@type": "oecd:AISystem",
      "name": "Medical AI Engine Pro",
      "version": "7.1.55",
      "relation": [
        "oecd:DirectCause",
        "oecd:FailureToAct"
      ]
    },
    "developer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/Apple_Inc.",
      "name": "Apple"
    },
    "deployer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/Northpointe",
      "name": "Northpointe"
    },
    "severity": "oecd:SeriousHazard",
    "harmType": [
      "oecd:PhysicalHarm",
      "oecd:HumanRightsHarm"
    ],
    "harmQuantification": {
      "@type": "oecd:HarmQuantification",
      "affected_stakeholders": "63418 individuals",
      "economic_losses": "$31.1 million"
    },
    "countries": [
      {
        "@type": "core:Country",
        "@id": "https://www.wikidata.org/wiki/India",
        "name": "India"
      },
      {
        "@type": "core:Country",
        "@id": "https://www.wikidata.org/wiki/United_States",
        "name": "United States"
      }
    ],
    "affectedStakeholders": [
      {
        "@type": "oecd:StakeholderGroup",
        "@id": "https://example.org/stakeholder-group/women",
        "name": "Women"
      }
    ],
    "businessFunction": [
      "oecd:OtherFunction"
    ],
    "submitter": {
      "@type": "oecd:Submitter",
      "@id": "https://example.org/submitter/reporter",
      "role": "Government Auditor",
      "affiliation": "AI Safety Coalition",
      "stakeholderGroup": "I work or am affiliated to a public interest body or NGO",
      "relationToIncident": "None of the above, but have partial or substantial knowledge of the incident (e.g. first-hand knowledge, research etc.)"
    },
    "unintendedUse": false
  },
  {
    "@context": [
      "http://localhost:3000/api/schemas/v1/core/context.jsonld",
      "http://localhost:3001/api/schemas/v1/oecd/context.jsonld"
    ],
    "@type": "oecd:Incident",
    "@id": "https://oecd.ai/incident/OECD-2016-020",
    "incident_id": "OECD-2016-020",
    "title": "Delivery Robot Swarm Blocks Emergency Vehicle Access",
    "description": "A fleet of autonomous delivery robots failed to coordinate their movements during an emergency, blocking paramedic access to a medical emergency. The swarm intelligence system lacked proper emergency vehicle detection and response protocols.",
    "date": "2016-03-23",
    "aiSystem": {
      "@type": "oecd:AISystem",
      "name": "Autonomous Systems System",
      "version": "6.0.7",
      "relation": [
        "oecd:DirectCause",
        "oecd:ContributingFactor"
      ]
    },
    "developer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/Doctors",
      "name": "Doctors"
    },
    "deployer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/Apple_Inc.",
      "name": "Apple"
    },
    "severity": "oecd:SeriousHazard",
    "harmType": [
      "oecd:PhysicalHarm",
      "oecd:PublicInterestHarm"
    ],
    "harmQuantification": {
      "@type": "oecd:HarmQuantification",
      "affected_stakeholders": "88463 customers",
      "economic_losses": "$42.6 million"
    },
    "countries": [
      {
        "@type": "core:Country",
        "@id": "https://www.wikidata.org/wiki/Canada",
        "name": "Canada"
      },
      {
        "@type": "core:Country",
        "@id": "https://www.wikidata.org/wiki/Australia",
        "name": "Australia"
      }
    ],
    "affectedStakeholders": [
      {
        "@type": "core:Person",
        "@id": "https://example.org/entities/person/job-applicants",
        "name": "Job applicants"
      },
      {
        "@type": "core:Person",
        "@id": "https://example.org/entities/person/black-people",
        "name": "Black people"
      },
      {
        "@type": "oecd:StakeholderGroup",
        "@id": "https://example.org/stakeholder-group/children",
        "name": "Children"
      }
    ],
    "businessFunction": [
      "oecd:Logistics",
      "oecd:OtherFunction"
    ],
    "submitter": {
      "@type": "oecd:Submitter",
      "@id": "https://example.org/submitter/reporter",
      "role": "Industry Whistleblower",
      "affiliation": "Consumer Protection Agency",
      "stakeholderGroup": "I work or am affiliated to a public interest body or NGO",
      "relationToIncident": "None of the above, but have partial or substantial knowledge of the incident (e.g. first-hand knowledge, research etc.)"
    },
    "unintendedUse": false
  },
  {
    "@context": [
      "http://localhost:3000/api/schemas/v1/core/context.jsonld",
      "http://localhost:3001/api/schemas/v1/oecd/context.jsonld"
    ],
    "@type": "oecd:Incident",
    "@id": "https://oecd.ai/incident/OECD-2016-021",
    "incident_id": "OECD-2016-021",
    "title": "Delivery Robot Swarm Blocks Emergency Vehicle Access",
    "description": "A fleet of autonomous delivery robots failed to coordinate their movements during an emergency, blocking paramedic access to a medical emergency. The swarm intelligence system lacked proper emergency vehicle detection and response protocols.",
    "date": "2016-04-10",
    "aiSystem": {
      "@type": "oecd:AISystem",
      "name": "Autonomous Systems System",
      "version": "4.11.73",
      "relation": [
        "oecd:ContributingFactor",
        "oecd:HumanError"
      ]
    },
    "developer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/Boeing",
      "name": "Boeing"
    },
    "deployer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/Navya_(company)",
      "name": "Navya"
    },
    "severity": "oecd:SeriousHazard",
    "harmType": [
      "oecd:PhysicalHarm",
      "oecd:PublicInterestHarm"
    ],
    "harmQuantification": {
      "@type": "oecd:HarmQuantification",
      "affected_stakeholders": "49732 users",
      "economic_losses": "$38.2 million"
    },
    "countries": [
      {
        "@type": "core:Country",
        "@id": "https://www.wikidata.org/wiki/Italy",
        "name": "Italy"
      }
    ],
    "affectedStakeholders": [
      {
        "@type": "oecd:StakeholderGroup",
        "@id": "https://example.org/stakeholder-group/students",
        "name": "Students"
      },
      {
        "@type": "core:Person",
        "@id": "https://example.org/entities/person/job-applicants",
        "name": "Job applicants"
      },
      {
        "@type": "oecd:StakeholderGroup",
        "@id": "https://example.org/stakeholder-group/children",
        "name": "Children"
      }
    ],
    "businessFunction": [
      "oecd:Logistics",
      "oecd:OtherFunction"
    ],
    "submitter": {
      "@type": "oecd:Submitter",
      "@id": "https://example.org/submitter/reporter",
      "role": "Academic Researcher",
      "affiliation": "Digital Rights Organization",
      "stakeholderGroup": "None of the above, but have partial or substantial knowledge of the incident",
      "relationToIncident": "None of the above, but have partial or substantial knowledge of the incident (e.g. first-hand knowledge, research etc.)"
    },
    "unintendedUse": false
  },
  {
    "@context": [
      "http://localhost:3000/api/schemas/v1/core/context.jsonld",
      "http://localhost:3001/api/schemas/v1/oecd/context.jsonld"
    ],
    "@type": "oecd:Incident",
    "@id": "https://oecd.ai/incident/OECD-2016-022",
    "incident_id": "OECD-2016-022",
    "title": "Surgical Robot Malfunction During Minimally Invasive Procedure",
    "description": "An AI-assisted surgical robot experienced a control system failure during a procedure, requiring emergency conversion to traditional surgery. The AI's motion planning algorithms failed to account for unexpected tissue resistance.",
    "date": "2016-04-23",
    "aiSystem": {
      "@type": "oecd:AISystem",
      "name": "Medical AI Engine",
      "version": "3.15.34",
      "relation": [
        "oecd:DirectCause",
        "oecd:FailureToAct"
      ]
    },
    "developer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/YouTube",
      "name": "YouTube"
    },
    "deployer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/Apple_Inc.",
      "name": "Apple"
    },
    "severity": "oecd:SeriousIncident",
    "harmType": [
      "oecd:PhysicalHarm"
    ],
    "harmQuantification": {
      "@type": "oecd:HarmQuantification",
      "affected_stakeholders": "8741 customers",
      "economic_losses": "$18.3 million"
    },
    "countries": [
      {
        "@type": "core:Country",
        "@id": "https://www.wikidata.org/wiki/France",
        "name": "France"
      },
      {
        "@type": "core:Country",
        "@id": "https://www.wikidata.org/wiki/Mexico",
        "name": "Mexico"
      }
    ],
    "affectedStakeholders": [
      {
        "@type": "core:Person",
        "@id": "https://example.org/entities/person/pedestrians",
        "name": "Pedestrians"
      }
    ],
    "businessFunction": [
      "oecd:OtherFunction"
    ],
    "submitter": {
      "@type": "oecd:Submitter",
      "@id": "https://example.org/submitter/reporter",
      "role": "Consumer Advocate",
      "affiliation": "AI Safety Coalition",
      "stakeholderGroup": "None of the above, but have partial or substantial knowledge of the incident",
      "relationToIncident": "None of the above, but have partial or substantial knowledge of the incident (e.g. first-hand knowledge, research etc.)"
    },
    "unintendedUse": false
  },
  {
    "@context": [
      "http://localhost:3000/api/schemas/v1/core/context.jsonld",
      "http://localhost:3001/api/schemas/v1/oecd/context.jsonld"
    ],
    "@type": "oecd:Incident",
    "@id": "https://oecd.ai/incident/OECD-2016-023",
    "incident_id": "OECD-2016-023",
    "title": "Predictive Policing Algorithm Creates Feedback Loops in Minority Neighborhoods",
    "description": "An AI system for predicting crime hotspots consistently directed more police presence to minority neighborhoods, creating a self-reinforcing cycle where increased police presence led to more reported incidents, further biasing the algorithm.",
    "date": "2016-05-01",
    "aiSystem": {
      "@type": "oecd:AISystem",
      "name": "Security/Surveillance Solution Pro",
      "version": "7.9.92",
      "relation": [
        "oecd:DirectCause",
        "oecd:ContributingFactor"
      ]
    },
    "developer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/Doctors",
      "name": "Doctors"
    },
    "deployer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/Frontier_Development",
      "name": "Frontier Development"
    },
    "severity": "oecd:SeriousHazard",
    "harmType": [
      "oecd:HumanRightsHarm",
      "oecd:PsychologicalHarm"
    ],
    "harmQuantification": {
      "@type": "oecd:HarmQuantification",
      "affected_stakeholders": "79684 users",
      "economic_losses": "$36.4 million",
      "psychological_impact": "Documented stress and anxiety in affected population"
    },
    "countries": [
      {
        "@type": "core:Country",
        "@id": "https://www.wikidata.org/wiki/Brazil",
        "name": "Brazil"
      }
    ],
    "affectedStakeholders": [
      {
        "@type": "core:Person",
        "@id": "https://example.org/entities/person/black-people",
        "name": "Black people"
      },
      {
        "@type": "oecd:StakeholderGroup",
        "@id": "https://example.org/stakeholder-group/minority-groups",
        "name": "Minority Groups"
      },
      {
        "@type": "core:Person",
        "@id": "https://example.org/entities/person/pedestrians",
        "name": "Pedestrians"
      }
    ],
    "businessFunction": [
      "oecd:Compliance",
      "oecd:Planning"
    ],
    "submitter": {
      "@type": "oecd:Submitter",
      "@id": "https://example.org/submitter/reporter",
      "role": "Government Auditor",
      "affiliation": "University Ethics Lab",
      "stakeholderGroup": "I am an affected stakeholder",
      "relationToIncident": "None of the above, but have partial or substantial knowledge of the incident (e.g. first-hand knowledge, research etc.)"
    },
    "unintendedUse": false
  },
  {
    "@context": [
      "http://localhost:3000/api/schemas/v1/core/context.jsonld",
      "http://localhost:3001/api/schemas/v1/oecd/context.jsonld"
    ],
    "@type": "oecd:Incident",
    "@id": "https://oecd.ai/incident/OECD-2016-024",
    "incident_id": "OECD-2016-024",
    "title": "Employee Monitoring AI Incorrectly Flags Remote Workers as Unproductive",
    "description": "An AI-powered employee productivity monitoring system incorrectly categorized focused work activities as idle time, leading to unfair performance reviews and terminations. The system failed to understand different working styles and break patterns.",
    "date": "2016-05-09",
    "aiSystem": {
      "@type": "oecd:AISystem",
      "name": "Workplace AI Engine Pro",
      "version": "8.17.46",
      "relation": [
        "oecd:ContributingFactor",
        "oecd:HumanError"
      ]
    },
    "developer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/Wikipedia",
      "name": "Wikipedia"
    },
    "deployer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/Google",
      "name": "Google"
    },
    "severity": "oecd:SeriousIncident",
    "harmType": [
      "oecd:EconomicHarm",
      "oecd:PsychologicalHarm",
      "oecd:ReputationalHarm"
    ],
    "harmQuantification": {
      "@type": "oecd:HarmQuantification",
      "affected_stakeholders": "85417 individuals",
      "economic_losses": "$19.8 million",
      "psychological_impact": "Documented stress and anxiety in affected population"
    },
    "countries": [
      {
        "@type": "core:Country",
        "@id": "https://www.wikidata.org/wiki/Canada",
        "name": "Canada"
      }
    ],
    "affectedStakeholders": [
      {
        "@type": "oecd:StakeholderGroup",
        "@id": "https://example.org/stakeholder-group/students",
        "name": "Students"
      },
      {
        "@type": "core:Person",
        "@id": "https://example.org/entities/person/pedestrians",
        "name": "Pedestrians"
      },
      {
        "@type": "core:Person",
        "@id": "https://example.org/entities/person/bus-passengers",
        "name": "Bus passengers"
      }
    ],
    "businessFunction": [
      "oecd:HRManagement",
      "oecd:QualityControl"
    ],
    "submitter": {
      "@type": "oecd:Submitter",
      "@id": "https://example.org/submitter/reporter",
      "role": "Academic Researcher",
      "affiliation": "Consumer Protection Agency",
      "stakeholderGroup": "I am an affected stakeholder",
      "relationToIncident": "None of the above, but have partial or substantial knowledge of the incident (e.g. first-hand knowledge, research etc.)"
    },
    "unintendedUse": false
  },
  {
    "@context": [
      "http://localhost:3000/api/schemas/v1/core/context.jsonld",
      "http://localhost:3001/api/schemas/v1/oecd/context.jsonld"
    ],
    "@type": "oecd:Incident",
    "@id": "https://oecd.ai/incident/OECD-2016-025",
    "incident_id": "OECD-2016-025",
    "title": "AI Diagnostic System Misses Critical Symptoms in Emergency Department",
    "description": "An AI triage system in emergency departments failed to identify critical symptoms in patients presenting with atypical manifestations of serious conditions. The system's training data lacked diversity in symptom presentations across different demographics.",
    "date": "2016-05-23",
    "aiSystem": {
      "@type": "oecd:AISystem",
      "name": "Medical AI Platform",
      "version": "5.9.2",
      "relation": [
        "oecd:DirectCause",
        "oecd:FailureToAct"
      ]
    },
    "developer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/Apple_Inc.",
      "name": "Apple"
    },
    "deployer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/Frontier_Development",
      "name": "Frontier Development"
    },
    "severity": "oecd:SeriousHazard",
    "harmType": [
      "oecd:PhysicalHarm",
      "oecd:HumanRightsHarm"
    ],
    "harmQuantification": {
      "@type": "oecd:HarmQuantification",
      "affected_stakeholders": "48097 patients",
      "economic_losses": "$44.8 million"
    },
    "countries": [
      {
        "@type": "core:Country",
        "@id": "https://www.wikidata.org/wiki/Australia",
        "name": "Australia"
      },
      {
        "@type": "core:Country",
        "@id": "https://www.wikidata.org/wiki/United_States",
        "name": "United States"
      }
    ],
    "affectedStakeholders": [
      {
        "@type": "oecd:StakeholderGroup",
        "@id": "https://example.org/stakeholder-group/patients",
        "name": "Patients"
      },
      {
        "@type": "core:Person",
        "@id": "https://example.org/entities/person/pedestrians",
        "name": "Pedestrians"
      }
    ],
    "businessFunction": [
      "oecd:OtherFunction"
    ],
    "submitter": {
      "@type": "oecd:Submitter",
      "@id": "https://example.org/submitter/reporter",
      "role": "Industry Whistleblower",
      "affiliation": "University Ethics Lab",
      "stakeholderGroup": "I work or am affiliated to a public interest body or NGO",
      "relationToIncident": "None of the above, but have partial or substantial knowledge of the incident (e.g. first-hand knowledge, research etc.)"
    },
    "unintendedUse": false
  },
  {
    "@context": [
      "http://localhost:3000/api/schemas/v1/core/context.jsonld",
      "http://localhost:3001/api/schemas/v1/oecd/context.jsonld"
    ],
    "@type": "oecd:Incident",
    "@id": "https://oecd.ai/incident/OECD-2016-026",
    "incident_id": "OECD-2016-026",
    "title": "Surgical Robot Malfunction During Minimally Invasive Procedure",
    "description": "An AI-assisted surgical robot experienced a control system failure during a procedure, requiring emergency conversion to traditional surgery. The AI's motion planning algorithms failed to account for unexpected tissue resistance.",
    "date": "2016-06-05",
    "aiSystem": {
      "@type": "oecd:AISystem",
      "name": "Medical AI System",
      "version": "10.6.70",
      "relation": [
        "oecd:ContributingFactor"
      ]
    },
    "developer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/Microsoft_Research",
      "name": "Microsoft Research"
    },
    "deployer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/United_States_Government",
      "name": "United States Government"
    },
    "severity": "oecd:SeriousIncident",
    "harmType": [
      "oecd:PhysicalHarm"
    ],
    "harmQuantification": {
      "@type": "oecd:HarmQuantification",
      "affected_stakeholders": "98491 individuals"
    },
    "countries": [
      {
        "@type": "core:Country",
        "@id": "https://www.wikidata.org/wiki/Brazil",
        "name": "Brazil"
      },
      {
        "@type": "core:Country",
        "@id": "https://www.wikidata.org/wiki/Mexico",
        "name": "Mexico"
      }
    ],
    "affectedStakeholders": [
      {
        "@type": "core:Person",
        "@id": "https://example.org/entities/person/pedestrians",
        "name": "Pedestrians"
      },
      {
        "@type": "oecd:StakeholderGroup",
        "@id": "https://example.org/stakeholder-group/children",
        "name": "Children"
      },
      {
        "@type": "core:Person",
        "@id": "https://example.org/entities/person/bus-passengers",
        "name": "Bus passengers"
      }
    ],
    "businessFunction": [
      "oecd:OtherFunction"
    ],
    "submitter": {
      "@type": "oecd:Submitter",
      "@id": "https://example.org/submitter/reporter",
      "role": "Academic Researcher",
      "affiliation": "Digital Rights Organization",
      "stakeholderGroup": "I work or am affiliated to a public interest body or NGO",
      "relationToIncident": "None of the above, but have partial or substantial knowledge of the incident (e.g. first-hand knowledge, research etc.)"
    },
    "unintendedUse": false
  },
  {
    "@context": [
      "http://localhost:3000/api/schemas/v1/core/context.jsonld",
      "http://localhost:3001/api/schemas/v1/oecd/context.jsonld"
    ],
    "@type": "oecd:Incident",
    "@id": "https://oecd.ai/incident/OECD-2016-027",
    "incident_id": "OECD-2016-027",
    "title": "Delivery Robot Swarm Blocks Emergency Vehicle Access",
    "description": "A fleet of autonomous delivery robots failed to coordinate their movements during an emergency, blocking paramedic access to a medical emergency. The swarm intelligence system lacked proper emergency vehicle detection and response protocols.",
    "date": "2016-06-27",
    "aiSystem": {
      "@type": "oecd:AISystem",
      "name": "Autonomous Systems System",
      "version": "5.17.29",
      "relation": [
        "oecd:DirectCause",
        "oecd:FailureToAct"
      ]
    },
    "developer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/Microsoft",
      "name": "Microsoft"
    },
    "deployer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/The_DAO",
      "name": "The DAO"
    },
    "severity": "oecd:SeriousHazard",
    "harmType": [
      "oecd:PhysicalHarm",
      "oecd:PublicInterestHarm"
    ],
    "harmQuantification": {
      "@type": "oecd:HarmQuantification",
      "affected_stakeholders": "8243 individuals",
      "economic_losses": "$7.9 million"
    },
    "countries": [
      {
        "@type": "core:Country",
        "@id": "https://www.wikidata.org/wiki/Japan",
        "name": "Japan"
      }
    ],
    "affectedStakeholders": [
      {
        "@type": "oecd:StakeholderGroup",
        "@id": "https://example.org/stakeholder-group/children",
        "name": "Children"
      },
      {
        "@type": "oecd:StakeholderGroup",
        "@id": "https://example.org/stakeholder-group/students",
        "name": "Students"
      },
      {
        "@type": "core:Person",
        "@id": "https://example.org/entities/person/airplane-passengers",
        "name": "Airplane Passengers"
      }
    ],
    "businessFunction": [
      "oecd:Logistics",
      "oecd:OtherFunction"
    ],
    "submitter": {
      "@type": "oecd:Submitter",
      "@id": "https://example.org/submitter/reporter",
      "role": "Data Scientist",
      "affiliation": "Tech Accountability Project",
      "stakeholderGroup": "I work or am affiliated to a public interest body or NGO",
      "relationToIncident": "None of the above, but have partial or substantial knowledge of the incident (e.g. first-hand knowledge, research etc.)"
    },
    "unintendedUse": false
  },
  {
    "@context": [
      "http://localhost:3000/api/schemas/v1/core/context.jsonld",
      "http://localhost:3001/api/schemas/v1/oecd/context.jsonld"
    ],
    "@type": "oecd:Incident",
    "@id": "https://oecd.ai/incident/OECD-2016-028",
    "incident_id": "OECD-2016-028",
    "title": "Facial Recognition System Falsely Identifies Protesters as Criminals",
    "description": "A law enforcement facial recognition system incorrectly matched peaceful protesters with criminal database entries, leading to wrongful detentions. The AI system showed higher error rates for certain ethnic groups and in crowded scenarios.",
    "date": "2016-07-12",
    "aiSystem": {
      "@type": "oecd:AISystem",
      "name": "Security/Surveillance Solution Pro",
      "version": "10.3.20",
      "relation": [
        "oecd:ContributingFactor"
      ]
    },
    "developer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/Apple_Inc.",
      "name": "Apple"
    },
    "deployer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/Delphi_Technologies",
      "name": "Delphi Technologies"
    },
    "severity": "oecd:SeriousIncident",
    "harmType": [
      "oecd:PhysicalHarm",
      "oecd:HumanRightsHarm",
      "oecd:ReputationalHarm"
    ],
    "harmQuantification": {
      "@type": "oecd:HarmQuantification",
      "affected_stakeholders": "89313 patients",
      "economic_losses": "$48.2 million"
    },
    "countries": [
      {
        "@type": "core:Country",
        "@id": "https://www.wikidata.org/wiki/Mexico",
        "name": "Mexico"
      }
    ],
    "affectedStakeholders": [
      {
        "@type": "core:Person",
        "@id": "https://example.org/entities/person/black-people",
        "name": "Black people"
      },
      {
        "@type": "oecd:StakeholderGroup",
        "@id": "https://example.org/stakeholder-group/consumers",
        "name": "Consumers"
      }
    ],
    "businessFunction": [
      "oecd:Compliance"
    ],
    "submitter": {
      "@type": "oecd:Submitter",
      "@id": "https://example.org/submitter/reporter",
      "role": "Consumer Advocate",
      "affiliation": "Digital Rights Organization",
      "stakeholderGroup": "I represent a government or regulatory body",
      "relationToIncident": "None of the above, but have partial or substantial knowledge of the incident (e.g. first-hand knowledge, research etc.)"
    },
    "unintendedUse": false
  },
  {
    "@context": [
      "http://localhost:3000/api/schemas/v1/core/context.jsonld",
      "http://localhost:3001/api/schemas/v1/oecd/context.jsonld"
    ],
    "@type": "oecd:Incident",
    "@id": "https://oecd.ai/incident/OECD-2016-029",
    "incident_id": "OECD-2016-029",
    "title": "AI Credit Scoring System Discriminates Against Recent Immigrants",
    "description": "An automated credit scoring system systematically assigned lower credit scores to recent immigrants despite strong financial indicators. The AI model heavily weighted credit history length, creating unfair barriers to financial services.",
    "date": "2016-08-18",
    "aiSystem": {
      "@type": "oecd:AISystem",
      "name": "Financial AI Engine Pro",
      "version": "5.9.60",
      "relation": [
        "oecd:DirectCause",
        "oecd:ContributingFactor"
      ]
    },
    "developer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/Boeing",
      "name": "Boeing"
    },
    "deployer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/Apple_Inc.",
      "name": "Apple"
    },
    "severity": "oecd:SeriousIncident",
    "harmType": [
      "oecd:EconomicHarm",
      "oecd:HumanRightsHarm"
    ],
    "harmQuantification": {
      "@type": "oecd:HarmQuantification",
      "affected_stakeholders": "10853 individuals"
    },
    "countries": [
      {
        "@type": "core:Country",
        "@id": "https://www.wikidata.org/wiki/United_States",
        "name": "United States"
      },
      {
        "@type": "core:Country",
        "@id": "https://www.wikidata.org/wiki/Italy",
        "name": "Italy"
      }
    ],
    "affectedStakeholders": [
      {
        "@type": "core:Person",
        "@id": "https://example.org/entities/person/airplane-passengers",
        "name": "Airplane Passengers"
      },
      {
        "@type": "core:Person",
        "@id": "https://example.org/entities/person/pedestrians",
        "name": "Pedestrians"
      }
    ],
    "businessFunction": [
      "oecd:OtherFunction"
    ],
    "submitter": {
      "@type": "oecd:Submitter",
      "@id": "https://example.org/submitter/reporter",
      "role": "Industry Whistleblower",
      "affiliation": "University Ethics Lab",
      "stakeholderGroup": "I work or am affiliated to a public interest body or NGO",
      "relationToIncident": "None of the above, but have partial or substantial knowledge of the incident (e.g. first-hand knowledge, research etc.)"
    },
    "unintendedUse": false
  },
  {
    "@context": [
      "http://localhost:3000/api/schemas/v1/core/context.jsonld",
      "http://localhost:3001/api/schemas/v1/oecd/context.jsonld"
    ],
    "@type": "oecd:Incident",
    "@id": "https://oecd.ai/incident/OECD-2016-030",
    "incident_id": "OECD-2016-030",
    "title": "AI Diagnostic System Misses Critical Symptoms in Emergency Department",
    "description": "An AI triage system in emergency departments failed to identify critical symptoms in patients presenting with atypical manifestations of serious conditions. The system's training data lacked diversity in symptom presentations across different demographics.",
    "date": "2016-08-28",
    "aiSystem": {
      "@type": "oecd:AISystem",
      "name": "Medical AI Engine Pro",
      "version": "10.19.54",
      "relation": [
        "oecd:DirectCause",
        "oecd:FailureToAct"
      ]
    },
    "developer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/Microsoft_Research",
      "name": "Microsoft Research"
    },
    "deployer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/LinkedIn",
      "name": "LinkedIn"
    },
    "severity": "oecd:SeriousHazard",
    "harmType": [
      "oecd:PhysicalHarm",
      "oecd:HumanRightsHarm"
    ],
    "harmQuantification": {
      "@type": "oecd:HarmQuantification",
      "affected_stakeholders": "95520 customers",
      "economic_losses": "$32.1 million"
    },
    "countries": [
      {
        "@type": "core:Country",
        "@id": "https://www.wikidata.org/wiki/Norway",
        "name": "Norway"
      },
      {
        "@type": "core:Country",
        "@id": "https://www.wikidata.org/wiki/Spain",
        "name": "Spain"
      }
    ],
    "affectedStakeholders": [
      {
        "@type": "oecd:StakeholderGroup",
        "@id": "https://example.org/stakeholder-group/students",
        "name": "Students"
      },
      {
        "@type": "core:Person",
        "@id": "https://example.org/entities/person/black-people",
        "name": "Black people"
      }
    ],
    "businessFunction": [
      "oecd:OtherFunction"
    ],
    "submitter": {
      "@type": "oecd:Submitter",
      "@id": "https://example.org/submitter/reporter",
      "role": "Industry Whistleblower",
      "affiliation": "Tech Accountability Project",
      "stakeholderGroup": "None of the above, but have partial or substantial knowledge of the incident",
      "relationToIncident": "None of the above, but have partial or substantial knowledge of the incident (e.g. first-hand knowledge, research etc.)"
    },
    "unintendedUse": false
  },
  {
    "@context": [
      "http://localhost:3000/api/schemas/v1/core/context.jsonld",
      "http://localhost:3001/api/schemas/v1/oecd/context.jsonld"
    ],
    "@type": "oecd:Incident",
    "@id": "https://oecd.ai/incident/OECD-2016-031",
    "incident_id": "OECD-2016-031",
    "title": "AI Interview System Shows Bias Against Non-Native Speakers",
    "description": "An automated video interview analysis system consistently gave lower scores to qualified candidates with accents or non-native speech patterns. The AI's speech recognition and sentiment analysis components showed significant bias.",
    "date": "2016-09-08",
    "aiSystem": {
      "@type": "oecd:AISystem",
      "name": "Workplace AI Engine",
      "version": "9.5.56",
      "relation": [
        "oecd:DirectCause",
        "oecd:ContributingFactor"
      ]
    },
    "developer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/Equivant",
      "name": "Equivant"
    },
    "deployer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/Google",
      "name": "Google"
    },
    "severity": "oecd:SeriousIncident",
    "harmType": [
      "oecd:EconomicHarm",
      "oecd:HumanRightsHarm"
    ],
    "harmQuantification": {
      "@type": "oecd:HarmQuantification",
      "affected_stakeholders": "10120 individuals"
    },
    "countries": [
      {
        "@type": "core:Country",
        "@id": "https://www.wikidata.org/wiki/South_Korea",
        "name": "South Korea"
      },
      {
        "@type": "core:Country",
        "@id": "https://www.wikidata.org/wiki/France",
        "name": "France"
      }
    ],
    "affectedStakeholders": [
      {
        "@type": "oecd:StakeholderGroup",
        "@id": "https://example.org/stakeholder-group/minority-groups",
        "name": "Minority Groups"
      },
      {
        "@type": "core:Person",
        "@id": "https://example.org/entities/person/airplane-passengers",
        "name": "Airplane Passengers"
      },
      {
        "@type": "core:Person",
        "@id": "https://example.org/entities/person/pedestrians",
        "name": "Pedestrians"
      }
    ],
    "businessFunction": [
      "oecd:HRManagement"
    ],
    "submitter": {
      "@type": "oecd:Submitter",
      "@id": "https://example.org/submitter/reporter",
      "role": "Academic Researcher",
      "affiliation": "Tech Accountability Project",
      "stakeholderGroup": "I am an affected stakeholder",
      "relationToIncident": "None of the above, but have partial or substantial knowledge of the incident (e.g. first-hand knowledge, research etc.)"
    },
    "unintendedUse": false
  },
  {
    "@context": [
      "http://localhost:3000/api/schemas/v1/core/context.jsonld",
      "http://localhost:3001/api/schemas/v1/oecd/context.jsonld"
    ],
    "@type": "oecd:Incident",
    "@id": "https://oecd.ai/incident/OECD-2016-032",
    "incident_id": "OECD-2016-032",
    "title": "Facial Recognition System Falsely Identifies Protesters as Criminals",
    "description": "A law enforcement facial recognition system incorrectly matched peaceful protesters with criminal database entries, leading to wrongful detentions. The AI system showed higher error rates for certain ethnic groups and in crowded scenarios.",
    "date": "2016-09-30",
    "aiSystem": {
      "@type": "oecd:AISystem",
      "name": "Security/Surveillance Engine Pro",
      "version": "9.13.82",
      "relation": [
        "oecd:ContributingFactor"
      ]
    },
    "developer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/Boeing",
      "name": "Boeing"
    },
    "deployer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/Boeing",
      "name": "Boeing"
    },
    "severity": "oecd:SeriousIncident",
    "harmType": [
      "oecd:PhysicalHarm",
      "oecd:HumanRightsHarm",
      "oecd:ReputationalHarm"
    ],
    "harmQuantification": {
      "@type": "oecd:HarmQuantification",
      "affected_stakeholders": "34183 patients",
      "economic_losses": "$18.0 million"
    },
    "countries": [
      {
        "@type": "core:Country",
        "@id": "https://www.wikidata.org/wiki/Australia",
        "name": "Australia"
      }
    ],
    "affectedStakeholders": [
      {
        "@type": "oecd:StakeholderGroup",
        "@id": "https://example.org/stakeholder-group/children",
        "name": "Children"
      },
      {
        "@type": "core:Person",
        "@id": "https://example.org/entities/person/bus-passengers",
        "name": "Bus passengers"
      },
      {
        "@type": "core:Person",
        "@id": "https://example.org/entities/person/black-people",
        "name": "Black people"
      }
    ],
    "businessFunction": [
      "oecd:Compliance"
    ],
    "submitter": {
      "@type": "oecd:Submitter",
      "@id": "https://example.org/submitter/reporter",
      "role": "Consumer Advocate",
      "affiliation": "Digital Rights Organization",
      "stakeholderGroup": "I represent a government or regulatory body",
      "relationToIncident": "None of the above, but have partial or substantial knowledge of the incident (e.g. first-hand knowledge, research etc.)"
    },
    "unintendedUse": true
  },
  {
    "@context": [
      "http://localhost:3000/api/schemas/v1/core/context.jsonld",
      "http://localhost:3001/api/schemas/v1/oecd/context.jsonld"
    ],
    "@type": "oecd:Incident",
    "@id": "https://oecd.ai/incident/OECD-2016-033",
    "incident_id": "OECD-2016-033",
    "title": "Facial Recognition System Falsely Identifies Protesters as Criminals",
    "description": "A law enforcement facial recognition system incorrectly matched peaceful protesters with criminal database entries, leading to wrongful detentions. The AI system showed higher error rates for certain ethnic groups and in crowded scenarios.",
    "date": "2016-10-22",
    "aiSystem": {
      "@type": "oecd:AISystem",
      "name": "Security/Surveillance System Pro",
      "version": "8.7.3",
      "relation": [
        "oecd:ContributingFactor",
        "oecd:HumanError"
      ]
    },
    "developer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/Equivant",
      "name": "Equivant"
    },
    "deployer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/St_George's_Hospital_Medical_School",
      "name": "St George's Hospital Medical School"
    },
    "severity": "oecd:SeriousIncident",
    "harmType": [
      "oecd:PhysicalHarm",
      "oecd:HumanRightsHarm",
      "oecd:ReputationalHarm"
    ],
    "harmQuantification": {
      "@type": "oecd:HarmQuantification",
      "affected_stakeholders": "62307 individuals",
      "economic_losses": "$25.0 million"
    },
    "countries": [
      {
        "@type": "core:Country",
        "@id": "https://www.wikidata.org/wiki/India",
        "name": "India"
      }
    ],
    "affectedStakeholders": [
      {
        "@type": "core:Person",
        "@id": "https://example.org/entities/person/bus-passengers",
        "name": "Bus passengers"
      },
      {
        "@type": "oecd:StakeholderGroup",
        "@id": "https://example.org/stakeholder-group/children",
        "name": "Children"
      }
    ],
    "businessFunction": [
      "oecd:Compliance"
    ],
    "submitter": {
      "@type": "oecd:Submitter",
      "@id": "https://example.org/submitter/reporter",
      "role": "Government Auditor",
      "affiliation": "Tech Accountability Project",
      "stakeholderGroup": "I work or am affiliated to a public interest body or NGO",
      "relationToIncident": "None of the above, but have partial or substantial knowledge of the incident (e.g. first-hand knowledge, research etc.)"
    },
    "unintendedUse": false
  },
  {
    "@context": [
      "http://localhost:3000/api/schemas/v1/core/context.jsonld",
      "http://localhost:3001/api/schemas/v1/oecd/context.jsonld"
    ],
    "@type": "oecd:Incident",
    "@id": "https://oecd.ai/incident/OECD-2016-034",
    "incident_id": "OECD-2016-034",
    "title": "AI Personal Assistant Shares Private Information in Group Settings",
    "description": "A voice-activated AI assistant failed to recognize multi-user environments and shared personal calendar entries, medical reminders, and financial information when responding to queries in group settings.",
    "date": "2016-10-26",
    "aiSystem": {
      "@type": "oecd:AISystem",
      "name": "Consumer AI Engine",
      "version": "10.17.41",
      "relation": [
        "oecd:ContributingFactor"
      ]
    },
    "developer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/The_DAO",
      "name": "The DAO"
    },
    "deployer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/Nest_Labs",
      "name": "Nest Labs"
    },
    "severity": "oecd:SeriousIncident",
    "harmType": [
      "oecd:ReputationalHarm",
      "oecd:HumanRightsHarm"
    ],
    "harmQuantification": {
      "@type": "oecd:HarmQuantification",
      "affected_stakeholders": "5204 individuals",
      "economic_losses": "$16.8 million"
    },
    "countries": [
      {
        "@type": "core:Country",
        "@id": "https://www.wikidata.org/wiki/Sweden",
        "name": "Sweden"
      }
    ],
    "affectedStakeholders": [
      {
        "@type": "oecd:StakeholderGroup",
        "@id": "https://example.org/stakeholder-group/workers",
        "name": "Workers"
      },
      {
        "@type": "oecd:StakeholderGroup",
        "@id": "https://example.org/stakeholder-group/women",
        "name": "Women"
      },
      {
        "@type": "core:Person",
        "@id": "https://example.org/entities/person/bus-passengers",
        "name": "Bus passengers"
      }
    ],
    "businessFunction": [
      "oecd:CustomerService",
      "oecd:ICTManagement"
    ],
    "submitter": {
      "@type": "oecd:Submitter",
      "@id": "https://example.org/submitter/reporter",
      "role": "Industry Whistleblower",
      "affiliation": "Consumer Protection Agency",
      "stakeholderGroup": "I work or am affiliated to a public interest body or NGO",
      "relationToIncident": "None of the above, but have partial or substantial knowledge of the incident (e.g. first-hand knowledge, research etc.)"
    },
    "unintendedUse": true
  },
  {
    "@context": [
      "http://localhost:3000/api/schemas/v1/core/context.jsonld",
      "http://localhost:3001/api/schemas/v1/oecd/context.jsonld"
    ],
    "@type": "oecd:Incident",
    "@id": "https://oecd.ai/incident/OECD-2017-035",
    "incident_id": "OECD-2017-035",
    "title": "Agricultural AI Misidentifies Crops Leading to Herbicide Damage",
    "description": "An AI-powered crop monitoring and treatment system misidentified valuable crops as weeds, resulting in herbicide application that destroyed thousands of acres of produce. The computer vision model was not properly validated for the specific crop varieties.",
    "date": "2017-01-13",
    "aiSystem": {
      "@type": "oecd:AISystem",
      "name": "Autonomous Systems Engine Pro",
      "version": "4.13.73",
      "relation": [
        "oecd:DirectCause",
        "oecd:ContributingFactor"
      ]
    },
    "developer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/Apple_Inc.",
      "name": "Apple"
    },
    "deployer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/Nest_Labs",
      "name": "Nest Labs"
    },
    "severity": "oecd:SeriousIncident",
    "harmType": [
      "oecd:EconomicHarm",
      "oecd:EnvironmentalHarm"
    ],
    "harmQuantification": {
      "@type": "oecd:HarmQuantification",
      "affected_stakeholders": "76010 individuals"
    },
    "countries": [
      {
        "@type": "core:Country",
        "@id": "https://www.wikidata.org/wiki/France",
        "name": "France"
      }
    ],
    "affectedStakeholders": [
      {
        "@type": "core:Person",
        "@id": "https://example.org/entities/person/black-people",
        "name": "Black people"
      },
      {
        "@type": "oecd:StakeholderGroup",
        "@id": "https://example.org/stakeholder-group/students",
        "name": "Students"
      },
      {
        "@type": "core:Person",
        "@id": "https://example.org/entities/person/bus-passengers",
        "name": "Bus passengers"
      }
    ],
    "businessFunction": [
      "oecd:Production",
      "oecd:OtherFunction"
    ],
    "submitter": {
      "@type": "oecd:Submitter",
      "@id": "https://example.org/submitter/reporter",
      "role": "Industry Whistleblower",
      "affiliation": "AI Safety Coalition",
      "stakeholderGroup": "None of the above, but have partial or substantial knowledge of the incident",
      "relationToIncident": "None of the above, but have partial or substantial knowledge of the incident (e.g. first-hand knowledge, research etc.)"
    },
    "unintendedUse": false
  },
  {
    "@context": [
      "http://localhost:3000/api/schemas/v1/core/context.jsonld",
      "http://localhost:3001/api/schemas/v1/oecd/context.jsonld"
    ],
    "@type": "oecd:Incident",
    "@id": "https://oecd.ai/incident/OECD-2017-036",
    "incident_id": "OECD-2017-036",
    "title": "AI Personal Assistant Shares Private Information in Group Settings",
    "description": "A voice-activated AI assistant failed to recognize multi-user environments and shared personal calendar entries, medical reminders, and financial information when responding to queries in group settings.",
    "date": "2017-01-28",
    "aiSystem": {
      "@type": "oecd:AISystem",
      "name": "Consumer AI Solution",
      "version": "9.6.46",
      "relation": [
        "oecd:DirectCause"
      ]
    },
    "developer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/LinkedIn",
      "name": "LinkedIn"
    },
    "deployer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/United_States_Government",
      "name": "United States Government"
    },
    "severity": "oecd:SeriousIncident",
    "harmType": [
      "oecd:ReputationalHarm",
      "oecd:HumanRightsHarm"
    ],
    "harmQuantification": {
      "@type": "oecd:HarmQuantification",
      "affected_stakeholders": "58514 workers"
    },
    "countries": [
      {
        "@type": "core:Country",
        "@id": "https://www.wikidata.org/wiki/Mexico",
        "name": "Mexico"
      },
      {
        "@type": "core:Country",
        "@id": "https://www.wikidata.org/wiki/United_States",
        "name": "United States"
      }
    ],
    "affectedStakeholders": [
      {
        "@type": "oecd:StakeholderGroup",
        "@id": "https://example.org/stakeholder-group/minority-groups",
        "name": "Minority Groups"
      },
      {
        "@type": "oecd:StakeholderGroup",
        "@id": "https://example.org/stakeholder-group/patients",
        "name": "Patients"
      }
    ],
    "businessFunction": [
      "oecd:CustomerService",
      "oecd:ICTManagement"
    ],
    "submitter": {
      "@type": "oecd:Submitter",
      "@id": "https://example.org/submitter/reporter",
      "role": "Safety Engineer",
      "affiliation": "Tech Accountability Project",
      "stakeholderGroup": "None of the above, but have partial or substantial knowledge of the incident",
      "relationToIncident": "None of the above, but have partial or substantial knowledge of the incident (e.g. first-hand knowledge, research etc.)"
    },
    "unintendedUse": false
  },
  {
    "@context": [
      "http://localhost:3000/api/schemas/v1/core/context.jsonld",
      "http://localhost:3001/api/schemas/v1/oecd/context.jsonld"
    ],
    "@type": "oecd:Incident",
    "@id": "https://oecd.ai/incident/OECD-2017-037",
    "incident_id": "OECD-2017-037",
    "title": "Smart Home AI Creates Dangerous Living Conditions for Elderly",
    "description": "An AI-powered smart home system learned incorrect patterns from an elderly resident with dementia, subsequently creating dangerous conditions by adjusting heating, lighting, and security settings inappropriately.",
    "date": "2017-03-02",
    "aiSystem": {
      "@type": "oecd:AISystem",
      "name": "Consumer AI Platform Pro",
      "version": "9.10.25",
      "relation": [
        "oecd:DirectCause"
      ]
    },
    "developer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/Uber",
      "name": "Uber"
    },
    "deployer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/Google",
      "name": "Google"
    },
    "severity": "oecd:SeriousHazard",
    "harmType": [
      "oecd:PhysicalHarm",
      "oecd:PsychologicalHarm"
    ],
    "harmQuantification": {
      "@type": "oecd:HarmQuantification",
      "affected_stakeholders": "12738 individuals",
      "economic_losses": "$13.1 million",
      "psychological_impact": "Documented stress and anxiety in affected population"
    },
    "countries": [
      {
        "@type": "core:Country",
        "@id": "https://www.wikidata.org/wiki/Mexico",
        "name": "Mexico"
      }
    ],
    "affectedStakeholders": [
      {
        "@type": "oecd:StakeholderGroup",
        "@id": "https://example.org/stakeholder-group/women",
        "name": "Women"
      },
      {
        "@type": "core:Person",
        "@id": "https://example.org/entities/person/bus-passengers",
        "name": "Bus passengers"
      },
      {
        "@type": "core:Person",
        "@id": "https://example.org/entities/person/black-people",
        "name": "Black people"
      }
    ],
    "businessFunction": [
      "oecd:CustomerService",
      "oecd:OtherFunction"
    ],
    "submitter": {
      "@type": "oecd:Submitter",
      "@id": "https://example.org/submitter/reporter",
      "role": "Government Auditor",
      "affiliation": "Digital Rights Organization",
      "stakeholderGroup": "I work or am affiliated to a public interest body or NGO",
      "relationToIncident": "None of the above, but have partial or substantial knowledge of the incident (e.g. first-hand knowledge, research etc.)"
    },
    "unintendedUse": false
  },
  {
    "@context": [
      "http://localhost:3000/api/schemas/v1/core/context.jsonld",
      "http://localhost:3001/api/schemas/v1/oecd/context.jsonld"
    ],
    "@type": "oecd:Incident",
    "@id": "https://oecd.ai/incident/OECD-2017-038",
    "incident_id": "OECD-2017-038",
    "title": "AI Interview System Shows Bias Against Non-Native Speakers",
    "description": "An automated video interview analysis system consistently gave lower scores to qualified candidates with accents or non-native speech patterns. The AI's speech recognition and sentiment analysis components showed significant bias.",
    "date": "2017-03-10",
    "aiSystem": {
      "@type": "oecd:AISystem",
      "name": "Workplace AI System",
      "version": "3.7.62",
      "relation": [
        "oecd:DirectCause"
      ]
    },
    "developer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/Google",
      "name": "Google"
    },
    "deployer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/Starbucks",
      "name": "Starbucks"
    },
    "severity": "oecd:SeriousIncident",
    "harmType": [
      "oecd:EconomicHarm",
      "oecd:HumanRightsHarm"
    ],
    "harmQuantification": {
      "@type": "oecd:HarmQuantification",
      "affected_stakeholders": "34330 workers",
      "economic_losses": "$39.6 million"
    },
    "countries": [
      {
        "@type": "core:Country",
        "@id": "https://www.wikidata.org/wiki/Germany",
        "name": "Germany"
      },
      {
        "@type": "core:Country",
        "@id": "https://www.wikidata.org/wiki/Australia",
        "name": "Australia"
      }
    ],
    "affectedStakeholders": [
      {
        "@type": "oecd:StakeholderGroup",
        "@id": "https://example.org/stakeholder-group/children",
        "name": "Children"
      },
      {
        "@type": "oecd:StakeholderGroup",
        "@id": "https://example.org/stakeholder-group/consumers",
        "name": "Consumers"
      }
    ],
    "businessFunction": [
      "oecd:HRManagement"
    ],
    "submitter": {
      "@type": "oecd:Submitter",
      "@id": "https://example.org/submitter/reporter",
      "role": "Safety Engineer",
      "affiliation": "Tech Accountability Project",
      "stakeholderGroup": "I work or am affiliated to a public interest body or NGO",
      "relationToIncident": "None of the above, but have partial or substantial knowledge of the incident (e.g. first-hand knowledge, research etc.)"
    },
    "unintendedUse": false
  },
  {
    "@context": [
      "http://localhost:3000/api/schemas/v1/core/context.jsonld",
      "http://localhost:3001/api/schemas/v1/oecd/context.jsonld"
    ],
    "@type": "oecd:Incident",
    "@id": "https://oecd.ai/incident/OECD-2017-039",
    "incident_id": "OECD-2017-039",
    "title": "Algorithmic Trading System Triggers Market Manipulation Investigation",
    "description": "High-frequency trading algorithms were found to be creating artificial price movements through coordinated trades. The AI systems learned to exploit market microstructure in ways that resembled illegal manipulation.",
    "date": "2017-04-05",
    "aiSystem": {
      "@type": "oecd:AISystem",
      "name": "Financial AI Engine",
      "version": "8.4.22",
      "relation": [
        "oecd:DirectCause",
        "oecd:ContributingFactor"
      ]
    },
    "developer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/Keolis",
      "name": "Keolis North America"
    },
    "deployer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/The_DAO",
      "name": "The DAO"
    },
    "severity": "oecd:SeriousHazard",
    "harmType": [
      "oecd:EconomicHarm",
      "oecd:PublicInterestHarm"
    ],
    "harmQuantification": {
      "@type": "oecd:HarmQuantification",
      "affected_stakeholders": "34265 individuals",
      "economic_losses": "$43.6 million"
    },
    "countries": [
      {
        "@type": "core:Country",
        "@id": "https://www.wikidata.org/wiki/United_States",
        "name": "United States"
      },
      {
        "@type": "core:Country",
        "@id": "https://www.wikidata.org/wiki/Brazil",
        "name": "Brazil"
      }
    ],
    "affectedStakeholders": [
      {
        "@type": "oecd:StakeholderGroup",
        "@id": "https://example.org/stakeholder-group/minority-groups",
        "name": "Minority Groups"
      },
      {
        "@type": "core:Person",
        "@id": "https://example.org/entities/person/job-applicants",
        "name": "Job applicants"
      },
      {
        "@type": "oecd:StakeholderGroup",
        "@id": "https://example.org/stakeholder-group/patients",
        "name": "Patients"
      }
    ],
    "businessFunction": [
      "oecd:OtherFunction"
    ],
    "submitter": {
      "@type": "oecd:Submitter",
      "@id": "https://example.org/submitter/reporter",
      "role": "Consumer Advocate",
      "affiliation": "University Ethics Lab",
      "stakeholderGroup": "None of the above, but have partial or substantial knowledge of the incident",
      "relationToIncident": "None of the above, but have partial or substantial knowledge of the incident (e.g. first-hand knowledge, research etc.)"
    },
    "unintendedUse": false
  },
  {
    "@context": [
      "http://localhost:3000/api/schemas/v1/core/context.jsonld",
      "http://localhost:3001/api/schemas/v1/oecd/context.jsonld"
    ],
    "@type": "oecd:Incident",
    "@id": "https://oecd.ai/incident/OECD-2017-040",
    "incident_id": "OECD-2017-040",
    "title": "AI Diagnostic System Misses Critical Symptoms in Emergency Department",
    "description": "An AI triage system in emergency departments failed to identify critical symptoms in patients presenting with atypical manifestations of serious conditions. The system's training data lacked diversity in symptom presentations across different demographics.",
    "date": "2017-04-08",
    "aiSystem": {
      "@type": "oecd:AISystem",
      "name": "Medical AI System",
      "version": "3.2.94",
      "relation": [
        "oecd:DirectCause",
        "oecd:FailureToAct"
      ]
    },
    "developer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/The_DAO",
      "name": "The DAO"
    },
    "deployer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/Youth_Laboratories",
      "name": "Youth Laboratories"
    },
    "severity": "oecd:SeriousHazard",
    "harmType": [
      "oecd:PhysicalHarm",
      "oecd:HumanRightsHarm"
    ],
    "harmQuantification": {
      "@type": "oecd:HarmQuantification",
      "affected_stakeholders": "13099 individuals",
      "economic_losses": "$46.2 million"
    },
    "countries": [
      {
        "@type": "core:Country",
        "@id": "https://www.wikidata.org/wiki/Israel",
        "name": "Israel"
      },
      {
        "@type": "core:Country",
        "@id": "https://www.wikidata.org/wiki/France",
        "name": "France"
      }
    ],
    "affectedStakeholders": [
      {
        "@type": "core:Person",
        "@id": "https://example.org/entities/person/medical-residents",
        "name": "Medical Residents"
      },
      {
        "@type": "oecd:StakeholderGroup",
        "@id": "https://example.org/stakeholder-group/women",
        "name": "Women"
      },
      {
        "@type": "oecd:StakeholderGroup",
        "@id": "https://example.org/stakeholder-group/patients",
        "name": "Patients"
      }
    ],
    "businessFunction": [
      "oecd:OtherFunction"
    ],
    "submitter": {
      "@type": "oecd:Submitter",
      "@id": "https://example.org/submitter/reporter",
      "role": "Industry Whistleblower",
      "affiliation": "Tech Accountability Project",
      "stakeholderGroup": "None of the above, but have partial or substantial knowledge of the incident",
      "relationToIncident": "None of the above, but have partial or substantial knowledge of the incident (e.g. first-hand knowledge, research etc.)"
    },
    "unintendedUse": false
  },
  {
    "@context": [
      "http://localhost:3000/api/schemas/v1/core/context.jsonld",
      "http://localhost:3001/api/schemas/v1/oecd/context.jsonld"
    ],
    "@type": "oecd:Incident",
    "@id": "https://oecd.ai/incident/OECD-2017-041",
    "incident_id": "OECD-2017-041",
    "title": "Delivery Robot Swarm Blocks Emergency Vehicle Access",
    "description": "A fleet of autonomous delivery robots failed to coordinate their movements during an emergency, blocking paramedic access to a medical emergency. The swarm intelligence system lacked proper emergency vehicle detection and response protocols.",
    "date": "2017-04-09",
    "aiSystem": {
      "@type": "oecd:AISystem",
      "name": "Autonomous Systems Engine Pro",
      "version": "7.14.76",
      "relation": [
        "oecd:DirectCause"
      ]
    },
    "developer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/YouTube",
      "name": "YouTube"
    },
    "deployer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/Nest_Labs",
      "name": "Nest Labs"
    },
    "severity": "oecd:SeriousHazard",
    "harmType": [
      "oecd:PhysicalHarm",
      "oecd:PublicInterestHarm"
    ],
    "harmQuantification": {
      "@type": "oecd:HarmQuantification",
      "affected_stakeholders": "2399 workers"
    },
    "countries": [
      {
        "@type": "core:Country",
        "@id": "https://www.wikidata.org/wiki/South_Korea",
        "name": "South Korea"
      }
    ],
    "affectedStakeholders": [
      {
        "@type": "oecd:StakeholderGroup",
        "@id": "https://example.org/stakeholder-group/women",
        "name": "Women"
      },
      {
        "@type": "core:Person",
        "@id": "https://example.org/entities/person/black-people",
        "name": "Black people"
      },
      {
        "@type": "oecd:StakeholderGroup",
        "@id": "https://example.org/stakeholder-group/consumers",
        "name": "Consumers"
      }
    ],
    "businessFunction": [
      "oecd:Logistics",
      "oecd:OtherFunction"
    ],
    "submitter": {
      "@type": "oecd:Submitter",
      "@id": "https://example.org/submitter/reporter",
      "role": "Industry Whistleblower",
      "affiliation": "Digital Rights Organization",
      "stakeholderGroup": "I work or am affiliated to a public interest body or NGO",
      "relationToIncident": "None of the above, but have partial or substantial knowledge of the incident (e.g. first-hand knowledge, research etc.)"
    },
    "unintendedUse": false
  },
  {
    "@context": [
      "http://localhost:3000/api/schemas/v1/core/context.jsonld",
      "http://localhost:3001/api/schemas/v1/oecd/context.jsonld"
    ],
    "@type": "oecd:Incident",
    "@id": "https://oecd.ai/incident/OECD-2017-042",
    "incident_id": "OECD-2017-042",
    "title": "Surgical Robot Malfunction During Minimally Invasive Procedure",
    "description": "An AI-assisted surgical robot experienced a control system failure during a procedure, requiring emergency conversion to traditional surgery. The AI's motion planning algorithms failed to account for unexpected tissue resistance.",
    "date": "2017-04-21",
    "aiSystem": {
      "@type": "oecd:AISystem",
      "name": "Medical AI Platform",
      "version": "10.12.46",
      "relation": [
        "oecd:ContributingFactor",
        "oecd:HumanError"
      ]
    },
    "developer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/Microsoft",
      "name": "Microsoft"
    },
    "deployer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/Microsoft",
      "name": "Microsoft"
    },
    "severity": "oecd:SeriousIncident",
    "harmType": [
      "oecd:PhysicalHarm"
    ],
    "harmQuantification": {
      "@type": "oecd:HarmQuantification",
      "affected_stakeholders": "42200 customers"
    },
    "countries": [
      {
        "@type": "core:Country",
        "@id": "https://www.wikidata.org/wiki/Japan",
        "name": "Japan"
      },
      {
        "@type": "core:Country",
        "@id": "https://www.wikidata.org/wiki/South_Korea",
        "name": "South Korea"
      }
    ],
    "affectedStakeholders": [
      {
        "@type": "core:Person",
        "@id": "https://example.org/entities/person/job-applicants",
        "name": "Job applicants"
      },
      {
        "@type": "oecd:StakeholderGroup",
        "@id": "https://example.org/stakeholder-group/children",
        "name": "Children"
      }
    ],
    "businessFunction": [
      "oecd:OtherFunction"
    ],
    "submitter": {
      "@type": "oecd:Submitter",
      "@id": "https://example.org/submitter/reporter",
      "role": "Data Scientist",
      "affiliation": "Consumer Protection Agency",
      "stakeholderGroup": "I work or am affiliated to a public interest body or NGO",
      "relationToIncident": "None of the above, but have partial or substantial knowledge of the incident (e.g. first-hand knowledge, research etc.)"
    },
    "unintendedUse": false
  },
  {
    "@context": [
      "http://localhost:3000/api/schemas/v1/core/context.jsonld",
      "http://localhost:3001/api/schemas/v1/oecd/context.jsonld"
    ],
    "@type": "oecd:Incident",
    "@id": "https://oecd.ai/incident/OECD-2017-043",
    "incident_id": "OECD-2017-043",
    "title": "AI Interview System Shows Bias Against Non-Native Speakers",
    "description": "An automated video interview analysis system consistently gave lower scores to qualified candidates with accents or non-native speech patterns. The AI's speech recognition and sentiment analysis components showed significant bias.",
    "date": "2017-05-13",
    "aiSystem": {
      "@type": "oecd:AISystem",
      "name": "Workplace AI Engine",
      "version": "6.16.57",
      "relation": [
        "oecd:DirectCause"
      ]
    },
    "developer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/Amazon_(company)",
      "name": "Amazon"
    },
    "deployer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/Youth_Laboratories",
      "name": "Youth Laboratories"
    },
    "severity": "oecd:SeriousIncident",
    "harmType": [
      "oecd:EconomicHarm",
      "oecd:HumanRightsHarm"
    ],
    "harmQuantification": {
      "@type": "oecd:HarmQuantification",
      "affected_stakeholders": "92225 customers",
      "economic_losses": "$47.2 million"
    },
    "countries": [
      {
        "@type": "core:Country",
        "@id": "https://www.wikidata.org/wiki/Germany",
        "name": "Germany"
      }
    ],
    "affectedStakeholders": [
      {
        "@type": "oecd:StakeholderGroup",
        "@id": "https://example.org/stakeholder-group/women",
        "name": "Women"
      },
      {
        "@type": "oecd:StakeholderGroup",
        "@id": "https://example.org/stakeholder-group/consumers",
        "name": "Consumers"
      }
    ],
    "businessFunction": [
      "oecd:HRManagement"
    ],
    "submitter": {
      "@type": "oecd:Submitter",
      "@id": "https://example.org/submitter/reporter",
      "role": "Academic Researcher",
      "affiliation": "AI Safety Coalition",
      "stakeholderGroup": "I work or am affiliated to a public interest body or NGO",
      "relationToIncident": "None of the above, but have partial or substantial knowledge of the incident (e.g. first-hand knowledge, research etc.)"
    },
    "unintendedUse": false
  },
  {
    "@context": [
      "http://localhost:3000/api/schemas/v1/core/context.jsonld",
      "http://localhost:3001/api/schemas/v1/oecd/context.jsonld"
    ],
    "@type": "oecd:Incident",
    "@id": "https://oecd.ai/incident/OECD-2017-044",
    "incident_id": "OECD-2017-044",
    "title": "Surgical Robot Malfunction During Minimally Invasive Procedure",
    "description": "An AI-assisted surgical robot experienced a control system failure during a procedure, requiring emergency conversion to traditional surgery. The AI's motion planning algorithms failed to account for unexpected tissue resistance.",
    "date": "2017-06-23",
    "aiSystem": {
      "@type": "oecd:AISystem",
      "name": "Medical AI Engine Pro",
      "version": "7.19.12",
      "relation": [
        "oecd:DirectCause"
      ]
    },
    "developer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/Microsoft_Research",
      "name": "Microsoft Research"
    },
    "deployer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/Apple_Inc.",
      "name": "Apple"
    },
    "severity": "oecd:SeriousIncident",
    "harmType": [
      "oecd:PhysicalHarm"
    ],
    "harmQuantification": {
      "@type": "oecd:HarmQuantification",
      "affected_stakeholders": "95313 customers",
      "economic_losses": "$3.1 million"
    },
    "countries": [
      {
        "@type": "core:Country",
        "@id": "https://www.wikidata.org/wiki/Brazil",
        "name": "Brazil"
      },
      {
        "@type": "core:Country",
        "@id": "https://www.wikidata.org/wiki/France",
        "name": "France"
      }
    ],
    "affectedStakeholders": [
      {
        "@type": "core:Person",
        "@id": "https://example.org/entities/person/job-applicants",
        "name": "Job applicants"
      },
      {
        "@type": "oecd:StakeholderGroup",
        "@id": "https://example.org/stakeholder-group/women",
        "name": "Women"
      }
    ],
    "businessFunction": [
      "oecd:OtherFunction"
    ],
    "submitter": {
      "@type": "oecd:Submitter",
      "@id": "https://example.org/submitter/reporter",
      "role": "Data Scientist",
      "affiliation": "Digital Rights Organization",
      "stakeholderGroup": "I work or am affiliated to a public interest body or NGO",
      "relationToIncident": "None of the above, but have partial or substantial knowledge of the incident (e.g. first-hand knowledge, research etc.)"
    },
    "unintendedUse": false
  },
  {
    "@context": [
      "http://localhost:3000/api/schemas/v1/core/context.jsonld",
      "http://localhost:3001/api/schemas/v1/oecd/context.jsonld"
    ],
    "@type": "oecd:Incident",
    "@id": "https://oecd.ai/incident/OECD-2017-045",
    "incident_id": "OECD-2017-045",
    "title": "AI Interview System Shows Bias Against Non-Native Speakers",
    "description": "An automated video interview analysis system consistently gave lower scores to qualified candidates with accents or non-native speech patterns. The AI's speech recognition and sentiment analysis components showed significant bias.",
    "date": "2017-07-29",
    "aiSystem": {
      "@type": "oecd:AISystem",
      "name": "Workplace AI System",
      "version": "9.1.48",
      "relation": [
        "oecd:DirectCause"
      ]
    },
    "developer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/Tesla,_Inc.",
      "name": "Tesla"
    },
    "deployer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/Youth_Laboratories",
      "name": "Youth Laboratories"
    },
    "severity": "oecd:SeriousIncident",
    "harmType": [
      "oecd:EconomicHarm",
      "oecd:HumanRightsHarm"
    ],
    "harmQuantification": {
      "@type": "oecd:HarmQuantification",
      "affected_stakeholders": "53245 workers"
    },
    "countries": [
      {
        "@type": "core:Country",
        "@id": "https://www.wikidata.org/wiki/India",
        "name": "India"
      }
    ],
    "affectedStakeholders": [
      {
        "@type": "oecd:StakeholderGroup",
        "@id": "https://example.org/stakeholder-group/workers",
        "name": "Workers"
      },
      {
        "@type": "oecd:StakeholderGroup",
        "@id": "https://example.org/stakeholder-group/children",
        "name": "Children"
      },
      {
        "@type": "oecd:StakeholderGroup",
        "@id": "https://example.org/stakeholder-group/students",
        "name": "Students"
      }
    ],
    "businessFunction": [
      "oecd:HRManagement"
    ],
    "submitter": {
      "@type": "oecd:Submitter",
      "@id": "https://example.org/submitter/reporter",
      "role": "Industry Whistleblower",
      "affiliation": "Tech Accountability Project",
      "stakeholderGroup": "I work or am affiliated to a public interest body or NGO",
      "relationToIncident": "None of the above, but have partial or substantial knowledge of the incident (e.g. first-hand knowledge, research etc.)"
    },
    "unintendedUse": false
  },
  {
    "@context": [
      "http://localhost:3000/api/schemas/v1/core/context.jsonld",
      "http://localhost:3001/api/schemas/v1/oecd/context.jsonld"
    ],
    "@type": "oecd:Incident",
    "@id": "https://oecd.ai/incident/OECD-2017-046",
    "incident_id": "OECD-2017-046",
    "title": "Surgical Robot Malfunction During Minimally Invasive Procedure",
    "description": "An AI-assisted surgical robot experienced a control system failure during a procedure, requiring emergency conversion to traditional surgery. The AI's motion planning algorithms failed to account for unexpected tissue resistance.",
    "date": "2017-09-14",
    "aiSystem": {
      "@type": "oecd:AISystem",
      "name": "Medical AI System Pro",
      "version": "8.8.72",
      "relation": [
        "oecd:DirectCause",
        "oecd:FailureToAct"
      ]
    },
    "developer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/Frontier_Development",
      "name": "Frontier Development"
    },
    "deployer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/Equivant",
      "name": "Equivant"
    },
    "severity": "oecd:SeriousIncident",
    "harmType": [
      "oecd:PhysicalHarm"
    ],
    "harmQuantification": {
      "@type": "oecd:HarmQuantification",
      "affected_stakeholders": "3505 individuals",
      "economic_losses": "$3.5 million"
    },
    "countries": [
      {
        "@type": "core:Country",
        "@id": "https://www.wikidata.org/wiki/Norway",
        "name": "Norway"
      },
      {
        "@type": "core:Country",
        "@id": "https://www.wikidata.org/wiki/Italy",
        "name": "Italy"
      }
    ],
    "affectedStakeholders": [
      {
        "@type": "oecd:StakeholderGroup",
        "@id": "https://example.org/stakeholder-group/children",
        "name": "Children"
      }
    ],
    "businessFunction": [
      "oecd:OtherFunction"
    ],
    "submitter": {
      "@type": "oecd:Submitter",
      "@id": "https://example.org/submitter/reporter",
      "role": "Consumer Advocate",
      "affiliation": "Tech Accountability Project",
      "stakeholderGroup": "I work or am affiliated to a public interest body or NGO",
      "relationToIncident": "None of the above, but have partial or substantial knowledge of the incident (e.g. first-hand knowledge, research etc.)"
    },
    "unintendedUse": true
  },
  {
    "@context": [
      "http://localhost:3000/api/schemas/v1/core/context.jsonld",
      "http://localhost:3001/api/schemas/v1/oecd/context.jsonld"
    ],
    "@type": "oecd:Incident",
    "@id": "https://oecd.ai/incident/OECD-2017-047",
    "incident_id": "OECD-2017-047",
    "title": "Employee Monitoring AI Incorrectly Flags Remote Workers as Unproductive",
    "description": "An AI-powered employee productivity monitoring system incorrectly categorized focused work activities as idle time, leading to unfair performance reviews and terminations. The system failed to understand different working styles and break patterns.",
    "date": "2017-09-23",
    "aiSystem": {
      "@type": "oecd:AISystem",
      "name": "Workplace AI Solution Pro",
      "version": "3.7.80",
      "relation": [
        "oecd:DirectCause",
        "oecd:FailureToAct"
      ]
    },
    "developer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/Volkswagen",
      "name": "Volkswagen"
    },
    "deployer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/Google",
      "name": "Google"
    },
    "severity": "oecd:SeriousIncident",
    "harmType": [
      "oecd:EconomicHarm",
      "oecd:PsychologicalHarm",
      "oecd:ReputationalHarm"
    ],
    "harmQuantification": {
      "@type": "oecd:HarmQuantification",
      "affected_stakeholders": "38873 customers",
      "psychological_impact": "Documented stress and anxiety in affected population"
    },
    "countries": [
      {
        "@type": "core:Country",
        "@id": "https://www.wikidata.org/wiki/Japan",
        "name": "Japan"
      },
      {
        "@type": "core:Country",
        "@id": "https://www.wikidata.org/wiki/Italy",
        "name": "Italy"
      }
    ],
    "affectedStakeholders": [
      {
        "@type": "core:Person",
        "@id": "https://example.org/entities/person/motorists",
        "name": "Motorists"
      },
      {
        "@type": "oecd:StakeholderGroup",
        "@id": "https://example.org/stakeholder-group/women",
        "name": "Women"
      },
      {
        "@type": "core:Person",
        "@id": "https://example.org/entities/person/bus-passengers",
        "name": "Bus passengers"
      }
    ],
    "businessFunction": [
      "oecd:HRManagement",
      "oecd:QualityControl"
    ],
    "submitter": {
      "@type": "oecd:Submitter",
      "@id": "https://example.org/submitter/reporter",
      "role": "Industry Whistleblower",
      "affiliation": "Tech Accountability Project",
      "stakeholderGroup": "I work or am affiliated to a public interest body or NGO",
      "relationToIncident": "None of the above, but have partial or substantial knowledge of the incident (e.g. first-hand knowledge, research etc.)"
    },
    "unintendedUse": false
  },
  {
    "@context": [
      "http://localhost:3000/api/schemas/v1/core/context.jsonld",
      "http://localhost:3001/api/schemas/v1/oecd/context.jsonld"
    ],
    "@type": "oecd:Incident",
    "@id": "https://oecd.ai/incident/OECD-2017-048",
    "incident_id": "OECD-2017-048",
    "title": "Facial Recognition System Falsely Identifies Protesters as Criminals",
    "description": "A law enforcement facial recognition system incorrectly matched peaceful protesters with criminal database entries, leading to wrongful detentions. The AI system showed higher error rates for certain ethnic groups and in crowded scenarios.",
    "date": "2017-10-05",
    "aiSystem": {
      "@type": "oecd:AISystem",
      "name": "Security/Surveillance System Pro",
      "version": "7.0.36",
      "relation": [
        "oecd:DirectCause"
      ]
    },
    "developer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/Volkswagen",
      "name": "Volkswagen"
    },
    "deployer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/Nest_Labs",
      "name": "Nest Labs"
    },
    "severity": "oecd:SeriousIncident",
    "harmType": [
      "oecd:PhysicalHarm",
      "oecd:HumanRightsHarm",
      "oecd:ReputationalHarm"
    ],
    "harmQuantification": {
      "@type": "oecd:HarmQuantification",
      "affected_stakeholders": "68197 individuals",
      "economic_losses": "$24.0 million"
    },
    "countries": [
      {
        "@type": "core:Country",
        "@id": "https://www.wikidata.org/wiki/Germany",
        "name": "Germany"
      },
      {
        "@type": "core:Country",
        "@id": "https://www.wikidata.org/wiki/Sweden",
        "name": "Sweden"
      }
    ],
    "affectedStakeholders": [
      {
        "@type": "core:Person",
        "@id": "https://example.org/entities/person/black-people",
        "name": "Black people"
      },
      {
        "@type": "core:Person",
        "@id": "https://example.org/entities/person/bus-passengers",
        "name": "Bus passengers"
      }
    ],
    "businessFunction": [
      "oecd:Compliance"
    ],
    "submitter": {
      "@type": "oecd:Submitter",
      "@id": "https://example.org/submitter/reporter",
      "role": "Consumer Advocate",
      "affiliation": "Digital Rights Organization",
      "stakeholderGroup": "I work or am affiliated to a public interest body or NGO",
      "relationToIncident": "None of the above, but have partial or substantial knowledge of the incident (e.g. first-hand knowledge, research etc.)"
    },
    "unintendedUse": false
  },
  {
    "@context": [
      "http://localhost:3000/api/schemas/v1/core/context.jsonld",
      "http://localhost:3001/api/schemas/v1/oecd/context.jsonld"
    ],
    "@type": "oecd:Incident",
    "@id": "https://oecd.ai/incident/OECD-2017-049",
    "incident_id": "OECD-2017-049",
    "title": "Predictive Policing Algorithm Creates Feedback Loops in Minority Neighborhoods",
    "description": "An AI system for predicting crime hotspots consistently directed more police presence to minority neighborhoods, creating a self-reinforcing cycle where increased police presence led to more reported incidents, further biasing the algorithm.",
    "date": "2017-10-09",
    "aiSystem": {
      "@type": "oecd:AISystem",
      "name": "Security/Surveillance System",
      "version": "2.13.56",
      "relation": [
        "oecd:DirectCause",
        "oecd:ContributingFactor"
      ]
    },
    "developer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/USC_Information_Sciences_Institute",
      "name": "USC Information Sciences Institute"
    },
    "deployer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/Google",
      "name": "Google"
    },
    "severity": "oecd:SeriousHazard",
    "harmType": [
      "oecd:HumanRightsHarm",
      "oecd:PsychologicalHarm"
    ],
    "harmQuantification": {
      "@type": "oecd:HarmQuantification",
      "affected_stakeholders": "87535 workers",
      "economic_losses": "$19.2 million",
      "psychological_impact": "Documented stress and anxiety in affected population"
    },
    "countries": [
      {
        "@type": "core:Country",
        "@id": "https://www.wikidata.org/wiki/Mexico",
        "name": "Mexico"
      }
    ],
    "affectedStakeholders": [
      {
        "@type": "oecd:StakeholderGroup",
        "@id": "https://example.org/stakeholder-group/women",
        "name": "Women"
      },
      {
        "@type": "oecd:StakeholderGroup",
        "@id": "https://example.org/stakeholder-group/minority-groups",
        "name": "Minority Groups"
      },
      {
        "@type": "core:Person",
        "@id": "https://example.org/entities/person/medical-residents",
        "name": "Medical Residents"
      }
    ],
    "businessFunction": [
      "oecd:Compliance",
      "oecd:Planning"
    ],
    "submitter": {
      "@type": "oecd:Submitter",
      "@id": "https://example.org/submitter/reporter",
      "role": "Data Scientist",
      "affiliation": "AI Safety Coalition",
      "stakeholderGroup": "I work or am affiliated to a public interest body or NGO",
      "relationToIncident": "None of the above, but have partial or substantial knowledge of the incident (e.g. first-hand knowledge, research etc.)"
    },
    "unintendedUse": false
  },
  {
    "@context": [
      "http://localhost:3000/api/schemas/v1/core/context.jsonld",
      "http://localhost:3001/api/schemas/v1/oecd/context.jsonld"
    ],
    "@type": "oecd:Incident",
    "@id": "https://oecd.ai/incident/OECD-2017-050",
    "incident_id": "OECD-2017-050",
    "title": "Algorithmic Trading System Triggers Market Manipulation Investigation",
    "description": "High-frequency trading algorithms were found to be creating artificial price movements through coordinated trades. The AI systems learned to exploit market microstructure in ways that resembled illegal manipulation.",
    "date": "2017-11-19",
    "aiSystem": {
      "@type": "oecd:AISystem",
      "name": "Financial AI System Pro",
      "version": "7.1.17",
      "relation": [
        "oecd:DirectCause"
      ]
    },
    "developer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/LinkedIn",
      "name": "LinkedIn"
    },
    "deployer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/Hospitals",
      "name": "Hospitals"
    },
    "severity": "oecd:SeriousHazard",
    "harmType": [
      "oecd:EconomicHarm",
      "oecd:PublicInterestHarm"
    ],
    "harmQuantification": {
      "@type": "oecd:HarmQuantification",
      "affected_stakeholders": "97745 customers",
      "economic_losses": "$43.0 million"
    },
    "countries": [
      {
        "@type": "core:Country",
        "@id": "https://www.wikidata.org/wiki/Italy",
        "name": "Italy"
      },
      {
        "@type": "core:Country",
        "@id": "https://www.wikidata.org/wiki/Netherlands",
        "name": "Netherlands"
      }
    ],
    "affectedStakeholders": [
      {
        "@type": "core:Person",
        "@id": "https://example.org/entities/person/airplane-passengers",
        "name": "Airplane Passengers"
      },
      {
        "@type": "oecd:StakeholderGroup",
        "@id": "https://example.org/stakeholder-group/minority-groups",
        "name": "Minority Groups"
      }
    ],
    "businessFunction": [
      "oecd:OtherFunction"
    ],
    "submitter": {
      "@type": "oecd:Submitter",
      "@id": "https://example.org/submitter/reporter",
      "role": "Industry Whistleblower",
      "affiliation": "Tech Accountability Project",
      "stakeholderGroup": "I am an affected stakeholder",
      "relationToIncident": "None of the above, but have partial or substantial knowledge of the incident (e.g. first-hand knowledge, research etc.)"
    },
    "unintendedUse": true
  },
  {
    "@context": [
      "http://localhost:3000/api/schemas/v1/core/context.jsonld",
      "http://localhost:3001/api/schemas/v1/oecd/context.jsonld"
    ],
    "@type": "oecd:Incident",
    "@id": "https://oecd.ai/incident/OECD-2018-051",
    "incident_id": "OECD-2018-051",
    "title": "AI Diagnostic System Misses Critical Symptoms in Emergency Department",
    "description": "An AI triage system in emergency departments failed to identify critical symptoms in patients presenting with atypical manifestations of serious conditions. The system's training data lacked diversity in symptom presentations across different demographics.",
    "date": "2018-02-06",
    "aiSystem": {
      "@type": "oecd:AISystem",
      "name": "Medical AI Engine Pro",
      "version": "5.8.67",
      "relation": [
        "oecd:DirectCause"
      ]
    },
    "developer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/Google",
      "name": "Google"
    },
    "deployer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/Various_organizations",
      "name": "Various organizations"
    },
    "severity": "oecd:SeriousHazard",
    "harmType": [
      "oecd:PhysicalHarm",
      "oecd:HumanRightsHarm"
    ],
    "harmQuantification": {
      "@type": "oecd:HarmQuantification",
      "affected_stakeholders": "11967 users",
      "economic_losses": "$1.2 million"
    },
    "countries": [
      {
        "@type": "core:Country",
        "@id": "https://www.wikidata.org/wiki/India",
        "name": "India"
      },
      {
        "@type": "core:Country",
        "@id": "https://www.wikidata.org/wiki/United_Kingdom",
        "name": "United Kingdom"
      }
    ],
    "affectedStakeholders": [
      {
        "@type": "oecd:StakeholderGroup",
        "@id": "https://example.org/stakeholder-group/minority-groups",
        "name": "Minority Groups"
      },
      {
        "@type": "oecd:StakeholderGroup",
        "@id": "https://example.org/stakeholder-group/patients",
        "name": "Patients"
      },
      {
        "@type": "core:Person",
        "@id": "https://example.org/entities/person/motorists",
        "name": "Motorists"
      }
    ],
    "businessFunction": [
      "oecd:OtherFunction"
    ],
    "submitter": {
      "@type": "oecd:Submitter",
      "@id": "https://example.org/submitter/reporter",
      "role": "Safety Engineer",
      "affiliation": "AI Safety Coalition",
      "stakeholderGroup": "None of the above, but have partial or substantial knowledge of the incident",
      "relationToIncident": "None of the above, but have partial or substantial knowledge of the incident (e.g. first-hand knowledge, research etc.)"
    },
    "unintendedUse": false
  },
  {
    "@context": [
      "http://localhost:3000/api/schemas/v1/core/context.jsonld",
      "http://localhost:3001/api/schemas/v1/oecd/context.jsonld"
    ],
    "@type": "oecd:Incident",
    "@id": "https://oecd.ai/incident/OECD-2018-052",
    "incident_id": "OECD-2018-052",
    "title": "Delivery Robot Swarm Blocks Emergency Vehicle Access",
    "description": "A fleet of autonomous delivery robots failed to coordinate their movements during an emergency, blocking paramedic access to a medical emergency. The swarm intelligence system lacked proper emergency vehicle detection and response protocols.",
    "date": "2018-03-11",
    "aiSystem": {
      "@type": "oecd:AISystem",
      "name": "Autonomous Systems Solution Pro",
      "version": "6.12.39",
      "relation": [
        "oecd:DirectCause"
      ]
    },
    "developer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/Tesla,_Inc.",
      "name": "Tesla"
    },
    "deployer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/Hospitals",
      "name": "Hospitals"
    },
    "severity": "oecd:SeriousHazard",
    "harmType": [
      "oecd:PhysicalHarm",
      "oecd:PublicInterestHarm"
    ],
    "harmQuantification": {
      "@type": "oecd:HarmQuantification",
      "affected_stakeholders": "44667 users",
      "economic_losses": "$36.6 million"
    },
    "countries": [
      {
        "@type": "core:Country",
        "@id": "https://www.wikidata.org/wiki/Sweden",
        "name": "Sweden"
      }
    ],
    "affectedStakeholders": [
      {
        "@type": "oecd:StakeholderGroup",
        "@id": "https://example.org/stakeholder-group/workers",
        "name": "Workers"
      }
    ],
    "businessFunction": [
      "oecd:Logistics",
      "oecd:OtherFunction"
    ],
    "submitter": {
      "@type": "oecd:Submitter",
      "@id": "https://example.org/submitter/reporter",
      "role": "Safety Engineer",
      "affiliation": "Consumer Protection Agency",
      "stakeholderGroup": "I work or am affiliated to a public interest body or NGO",
      "relationToIncident": "None of the above, but have partial or substantial knowledge of the incident (e.g. first-hand knowledge, research etc.)"
    },
    "unintendedUse": true
  },
  {
    "@context": [
      "http://localhost:3000/api/schemas/v1/core/context.jsonld",
      "http://localhost:3001/api/schemas/v1/oecd/context.jsonld"
    ],
    "@type": "oecd:Incident",
    "@id": "https://oecd.ai/incident/OECD-2018-053",
    "incident_id": "OECD-2018-053",
    "title": "Predictive Policing Algorithm Creates Feedback Loops in Minority Neighborhoods",
    "description": "An AI system for predicting crime hotspots consistently directed more police presence to minority neighborhoods, creating a self-reinforcing cycle where increased police presence led to more reported incidents, further biasing the algorithm.",
    "date": "2018-04-16",
    "aiSystem": {
      "@type": "oecd:AISystem",
      "name": "Security/Surveillance System",
      "version": "10.7.74",
      "relation": [
        "oecd:ContributingFactor",
        "oecd:HumanError"
      ]
    },
    "developer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/Microsoft_Research",
      "name": "Microsoft Research"
    },
    "deployer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/Google",
      "name": "Google"
    },
    "severity": "oecd:SeriousHazard",
    "harmType": [
      "oecd:HumanRightsHarm",
      "oecd:PsychologicalHarm"
    ],
    "harmQuantification": {
      "@type": "oecd:HarmQuantification",
      "affected_stakeholders": "39584 users",
      "economic_losses": "$12.8 million",
      "psychological_impact": "Documented stress and anxiety in affected population"
    },
    "countries": [
      {
        "@type": "core:Country",
        "@id": "https://www.wikidata.org/wiki/Canada",
        "name": "Canada"
      }
    ],
    "affectedStakeholders": [
      {
        "@type": "oecd:StakeholderGroup",
        "@id": "https://example.org/stakeholder-group/minority-groups",
        "name": "Minority Groups"
      },
      {
        "@type": "oecd:StakeholderGroup",
        "@id": "https://example.org/stakeholder-group/children",
        "name": "Children"
      },
      {
        "@type": "core:Person",
        "@id": "https://example.org/entities/person/pedestrians",
        "name": "Pedestrians"
      }
    ],
    "businessFunction": [
      "oecd:Compliance",
      "oecd:Planning"
    ],
    "submitter": {
      "@type": "oecd:Submitter",
      "@id": "https://example.org/submitter/reporter",
      "role": "Industry Whistleblower",
      "affiliation": "Tech Accountability Project",
      "stakeholderGroup": "I work or am affiliated to a public interest body or NGO",
      "relationToIncident": "None of the above, but have partial or substantial knowledge of the incident (e.g. first-hand knowledge, research etc.)"
    },
    "unintendedUse": false
  },
  {
    "@context": [
      "http://localhost:3000/api/schemas/v1/core/context.jsonld",
      "http://localhost:3001/api/schemas/v1/oecd/context.jsonld"
    ],
    "@type": "oecd:Incident",
    "@id": "https://oecd.ai/incident/OECD-2018-054",
    "incident_id": "OECD-2018-054",
    "title": "Delivery Robot Swarm Blocks Emergency Vehicle Access",
    "description": "A fleet of autonomous delivery robots failed to coordinate their movements during an emergency, blocking paramedic access to a medical emergency. The swarm intelligence system lacked proper emergency vehicle detection and response protocols.",
    "date": "2018-04-23",
    "aiSystem": {
      "@type": "oecd:AISystem",
      "name": "Autonomous Systems System",
      "version": "8.0.75",
      "relation": [
        "oecd:ContributingFactor"
      ]
    },
    "developer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/Microsoft_Research",
      "name": "Microsoft Research"
    },
    "deployer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/Microsoft",
      "name": "Microsoft"
    },
    "severity": "oecd:SeriousHazard",
    "harmType": [
      "oecd:PhysicalHarm",
      "oecd:PublicInterestHarm"
    ],
    "harmQuantification": {
      "@type": "oecd:HarmQuantification",
      "affected_stakeholders": "55970 individuals",
      "economic_losses": "$26.7 million"
    },
    "countries": [
      {
        "@type": "core:Country",
        "@id": "https://www.wikidata.org/wiki/France",
        "name": "France"
      },
      {
        "@type": "core:Country",
        "@id": "https://www.wikidata.org/wiki/South_Korea",
        "name": "South Korea"
      }
    ],
    "affectedStakeholders": [
      {
        "@type": "core:Person",
        "@id": "https://example.org/entities/person/job-applicants",
        "name": "Job applicants"
      }
    ],
    "businessFunction": [
      "oecd:Logistics",
      "oecd:OtherFunction"
    ],
    "submitter": {
      "@type": "oecd:Submitter",
      "@id": "https://example.org/submitter/reporter",
      "role": "Industry Whistleblower",
      "affiliation": "Consumer Protection Agency",
      "stakeholderGroup": "I work or am affiliated to a public interest body or NGO",
      "relationToIncident": "None of the above, but have partial or substantial knowledge of the incident (e.g. first-hand knowledge, research etc.)"
    },
    "unintendedUse": false
  },
  {
    "@context": [
      "http://localhost:3000/api/schemas/v1/core/context.jsonld",
      "http://localhost:3001/api/schemas/v1/oecd/context.jsonld"
    ],
    "@type": "oecd:Incident",
    "@id": "https://oecd.ai/incident/OECD-2018-055",
    "incident_id": "OECD-2018-055",
    "title": "AI Interview System Shows Bias Against Non-Native Speakers",
    "description": "An automated video interview analysis system consistently gave lower scores to qualified candidates with accents or non-native speech patterns. The AI's speech recognition and sentiment analysis components showed significant bias.",
    "date": "2018-04-24",
    "aiSystem": {
      "@type": "oecd:AISystem",
      "name": "Workplace AI Solution Pro",
      "version": "7.2.19",
      "relation": [
        "oecd:DirectCause"
      ]
    },
    "developer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/Apple_Inc.",
      "name": "Apple"
    },
    "deployer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/Apple_Inc.",
      "name": "Apple"
    },
    "severity": "oecd:SeriousIncident",
    "harmType": [
      "oecd:EconomicHarm",
      "oecd:HumanRightsHarm"
    ],
    "harmQuantification": {
      "@type": "oecd:HarmQuantification",
      "affected_stakeholders": "57560 users",
      "economic_losses": "$9.7 million"
    },
    "countries": [
      {
        "@type": "core:Country",
        "@id": "https://www.wikidata.org/wiki/Mexico",
        "name": "Mexico"
      }
    ],
    "affectedStakeholders": [
      {
        "@type": "oecd:StakeholderGroup",
        "@id": "https://example.org/stakeholder-group/students",
        "name": "Students"
      },
      {
        "@type": "oecd:StakeholderGroup",
        "@id": "https://example.org/stakeholder-group/children",
        "name": "Children"
      }
    ],
    "businessFunction": [
      "oecd:HRManagement"
    ],
    "submitter": {
      "@type": "oecd:Submitter",
      "@id": "https://example.org/submitter/reporter",
      "role": "Industry Whistleblower",
      "affiliation": "Consumer Protection Agency",
      "stakeholderGroup": "I work or am affiliated to a public interest body or NGO",
      "relationToIncident": "None of the above, but have partial or substantial knowledge of the incident (e.g. first-hand knowledge, research etc.)"
    },
    "unintendedUse": true
  },
  {
    "@context": [
      "http://localhost:3000/api/schemas/v1/core/context.jsonld",
      "http://localhost:3001/api/schemas/v1/oecd/context.jsonld"
    ],
    "@type": "oecd:Incident",
    "@id": "https://oecd.ai/incident/OECD-2018-056",
    "incident_id": "OECD-2018-056",
    "title": "Employee Monitoring AI Incorrectly Flags Remote Workers as Unproductive",
    "description": "An AI-powered employee productivity monitoring system incorrectly categorized focused work activities as idle time, leading to unfair performance reviews and terminations. The system failed to understand different working styles and break patterns.",
    "date": "2018-05-15",
    "aiSystem": {
      "@type": "oecd:AISystem",
      "name": "Workplace AI Platform Pro",
      "version": "9.4.42",
      "relation": [
        "oecd:DirectCause"
      ]
    },
    "developer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/Hospitals",
      "name": "Hospitals"
    },
    "deployer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/Amazon_(company)",
      "name": "Amazon"
    },
    "severity": "oecd:SeriousIncident",
    "harmType": [
      "oecd:EconomicHarm",
      "oecd:PsychologicalHarm",
      "oecd:ReputationalHarm"
    ],
    "harmQuantification": {
      "@type": "oecd:HarmQuantification",
      "affected_stakeholders": "90821 patients",
      "economic_losses": "$43.8 million",
      "psychological_impact": "Documented stress and anxiety in affected population"
    },
    "countries": [
      {
        "@type": "core:Country",
        "@id": "https://www.wikidata.org/wiki/Brazil",
        "name": "Brazil"
      },
      {
        "@type": "core:Country",
        "@id": "https://www.wikidata.org/wiki/United_States",
        "name": "United States"
      }
    ],
    "affectedStakeholders": [
      {
        "@type": "oecd:StakeholderGroup",
        "@id": "https://example.org/stakeholder-group/students",
        "name": "Students"
      },
      {
        "@type": "core:Person",
        "@id": "https://example.org/entities/person/black-people",
        "name": "Black people"
      }
    ],
    "businessFunction": [
      "oecd:HRManagement",
      "oecd:QualityControl"
    ],
    "submitter": {
      "@type": "oecd:Submitter",
      "@id": "https://example.org/submitter/reporter",
      "role": "Industry Whistleblower",
      "affiliation": "Digital Rights Organization",
      "stakeholderGroup": "I am an affected stakeholder",
      "relationToIncident": "None of the above, but have partial or substantial knowledge of the incident (e.g. first-hand knowledge, research etc.)"
    },
    "unintendedUse": false
  },
  {
    "@context": [
      "http://localhost:3000/api/schemas/v1/core/context.jsonld",
      "http://localhost:3001/api/schemas/v1/oecd/context.jsonld"
    ],
    "@type": "oecd:Incident",
    "@id": "https://oecd.ai/incident/OECD-2018-057",
    "incident_id": "OECD-2018-057",
    "title": "Delivery Robot Swarm Blocks Emergency Vehicle Access",
    "description": "A fleet of autonomous delivery robots failed to coordinate their movements during an emergency, blocking paramedic access to a medical emergency. The swarm intelligence system lacked proper emergency vehicle detection and response protocols.",
    "date": "2018-05-24",
    "aiSystem": {
      "@type": "oecd:AISystem",
      "name": "Autonomous Systems Solution Pro",
      "version": "10.12.66",
      "relation": [
        "oecd:ContributingFactor"
      ]
    },
    "developer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/Boeing",
      "name": "Boeing"
    },
    "deployer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/Amazon_(company)",
      "name": "Amazon"
    },
    "severity": "oecd:SeriousHazard",
    "harmType": [
      "oecd:PhysicalHarm",
      "oecd:PublicInterestHarm"
    ],
    "harmQuantification": {
      "@type": "oecd:HarmQuantification",
      "affected_stakeholders": "20339 patients",
      "economic_losses": "$44.5 million"
    },
    "countries": [
      {
        "@type": "core:Country",
        "@id": "https://www.wikidata.org/wiki/Mexico",
        "name": "Mexico"
      }
    ],
    "affectedStakeholders": [
      {
        "@type": "core:Person",
        "@id": "https://example.org/entities/person/airplane-passengers",
        "name": "Airplane Passengers"
      },
      {
        "@type": "core:Person",
        "@id": "https://example.org/entities/person/medical-residents",
        "name": "Medical Residents"
      },
      {
        "@type": "oecd:StakeholderGroup",
        "@id": "https://example.org/stakeholder-group/patients",
        "name": "Patients"
      }
    ],
    "businessFunction": [
      "oecd:Logistics",
      "oecd:OtherFunction"
    ],
    "submitter": {
      "@type": "oecd:Submitter",
      "@id": "https://example.org/submitter/reporter",
      "role": "Industry Whistleblower",
      "affiliation": "AI Safety Coalition",
      "stakeholderGroup": "I work or am affiliated to a public interest body or NGO",
      "relationToIncident": "None of the above, but have partial or substantial knowledge of the incident (e.g. first-hand knowledge, research etc.)"
    },
    "unintendedUse": false
  },
  {
    "@context": [
      "http://localhost:3000/api/schemas/v1/core/context.jsonld",
      "http://localhost:3001/api/schemas/v1/oecd/context.jsonld"
    ],
    "@type": "oecd:Incident",
    "@id": "https://oecd.ai/incident/OECD-2018-058",
    "incident_id": "OECD-2018-058",
    "title": "AI Credit Scoring System Discriminates Against Recent Immigrants",
    "description": "An automated credit scoring system systematically assigned lower credit scores to recent immigrants despite strong financial indicators. The AI model heavily weighted credit history length, creating unfair barriers to financial services.",
    "date": "2018-05-25",
    "aiSystem": {
      "@type": "oecd:AISystem",
      "name": "Financial AI Engine Pro",
      "version": "7.4.71",
      "relation": [
        "oecd:DirectCause"
      ]
    },
    "developer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/LinkedIn",
      "name": "LinkedIn"
    },
    "deployer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/Delphi_Technologies",
      "name": "Delphi Technologies"
    },
    "severity": "oecd:SeriousIncident",
    "harmType": [
      "oecd:EconomicHarm",
      "oecd:HumanRightsHarm"
    ],
    "harmQuantification": {
      "@type": "oecd:HarmQuantification",
      "affected_stakeholders": "67465 patients",
      "economic_losses": "$21.7 million"
    },
    "countries": [
      {
        "@type": "core:Country",
        "@id": "https://www.wikidata.org/wiki/Netherlands",
        "name": "Netherlands"
      },
      {
        "@type": "core:Country",
        "@id": "https://www.wikidata.org/wiki/Brazil",
        "name": "Brazil"
      }
    ],
    "affectedStakeholders": [
      {
        "@type": "core:Person",
        "@id": "https://example.org/entities/person/job-applicants",
        "name": "Job applicants"
      },
      {
        "@type": "core:Person",
        "@id": "https://example.org/entities/person/pedestrians",
        "name": "Pedestrians"
      },
      {
        "@type": "oecd:StakeholderGroup",
        "@id": "https://example.org/stakeholder-group/students",
        "name": "Students"
      }
    ],
    "businessFunction": [
      "oecd:OtherFunction"
    ],
    "submitter": {
      "@type": "oecd:Submitter",
      "@id": "https://example.org/submitter/reporter",
      "role": "Consumer Advocate",
      "affiliation": "AI Safety Coalition",
      "stakeholderGroup": "I represent a government or regulatory body",
      "relationToIncident": "None of the above, but have partial or substantial knowledge of the incident (e.g. first-hand knowledge, research etc.)"
    },
    "unintendedUse": false
  },
  {
    "@context": [
      "http://localhost:3000/api/schemas/v1/core/context.jsonld",
      "http://localhost:3001/api/schemas/v1/oecd/context.jsonld"
    ],
    "@type": "oecd:Incident",
    "@id": "https://oecd.ai/incident/OECD-2018-059",
    "incident_id": "OECD-2018-059",
    "title": "Delivery Robot Swarm Blocks Emergency Vehicle Access",
    "description": "A fleet of autonomous delivery robots failed to coordinate their movements during an emergency, blocking paramedic access to a medical emergency. The swarm intelligence system lacked proper emergency vehicle detection and response protocols.",
    "date": "2018-06-08",
    "aiSystem": {
      "@type": "oecd:AISystem",
      "name": "Autonomous Systems Solution",
      "version": "4.9.91",
      "relation": [
        "oecd:DirectCause"
      ]
    },
    "developer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/Doctors",
      "name": "Doctors"
    },
    "deployer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/Delphi_Technologies",
      "name": "Delphi Technologies"
    },
    "severity": "oecd:SeriousHazard",
    "harmType": [
      "oecd:PhysicalHarm",
      "oecd:PublicInterestHarm"
    ],
    "harmQuantification": {
      "@type": "oecd:HarmQuantification",
      "affected_stakeholders": "5735 users",
      "economic_losses": "$34.0 million"
    },
    "countries": [
      {
        "@type": "core:Country",
        "@id": "https://www.wikidata.org/wiki/United_Kingdom",
        "name": "United Kingdom"
      }
    ],
    "affectedStakeholders": [
      {
        "@type": "core:Person",
        "@id": "https://example.org/entities/person/pedestrians",
        "name": "Pedestrians"
      },
      {
        "@type": "core:Person",
        "@id": "https://example.org/entities/person/bus-passengers",
        "name": "Bus passengers"
      },
      {
        "@type": "oecd:StakeholderGroup",
        "@id": "https://example.org/stakeholder-group/patients",
        "name": "Patients"
      }
    ],
    "businessFunction": [
      "oecd:Logistics",
      "oecd:OtherFunction"
    ],
    "submitter": {
      "@type": "oecd:Submitter",
      "@id": "https://example.org/submitter/reporter",
      "role": "Data Scientist",
      "affiliation": "Consumer Protection Agency",
      "stakeholderGroup": "I represent a government or regulatory body",
      "relationToIncident": "None of the above, but have partial or substantial knowledge of the incident (e.g. first-hand knowledge, research etc.)"
    },
    "unintendedUse": false
  },
  {
    "@context": [
      "http://localhost:3000/api/schemas/v1/core/context.jsonld",
      "http://localhost:3001/api/schemas/v1/oecd/context.jsonld"
    ],
    "@type": "oecd:Incident",
    "@id": "https://oecd.ai/incident/OECD-2018-060",
    "incident_id": "OECD-2018-060",
    "title": "AI Interview System Shows Bias Against Non-Native Speakers",
    "description": "An automated video interview analysis system consistently gave lower scores to qualified candidates with accents or non-native speech patterns. The AI's speech recognition and sentiment analysis components showed significant bias.",
    "date": "2018-08-03",
    "aiSystem": {
      "@type": "oecd:AISystem",
      "name": "Workplace AI System",
      "version": "2.17.56",
      "relation": [
        "oecd:DirectCause",
        "oecd:ContributingFactor"
      ]
    },
    "developer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/University_of_Washington",
      "name": "University of Washington"
    },
    "deployer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/Wikipedia",
      "name": "Wikipedia"
    },
    "severity": "oecd:SeriousIncident",
    "harmType": [
      "oecd:EconomicHarm",
      "oecd:HumanRightsHarm"
    ],
    "harmQuantification": {
      "@type": "oecd:HarmQuantification",
      "affected_stakeholders": "44790 individuals"
    },
    "countries": [
      {
        "@type": "core:Country",
        "@id": "https://www.wikidata.org/wiki/Singapore",
        "name": "Singapore"
      }
    ],
    "affectedStakeholders": [
      {
        "@type": "core:Person",
        "@id": "https://example.org/entities/person/airplane-passengers",
        "name": "Airplane Passengers"
      },
      {
        "@type": "core:Person",
        "@id": "https://example.org/entities/person/medical-residents",
        "name": "Medical Residents"
      }
    ],
    "businessFunction": [
      "oecd:HRManagement"
    ],
    "submitter": {
      "@type": "oecd:Submitter",
      "@id": "https://example.org/submitter/reporter",
      "role": "Government Auditor",
      "affiliation": "Tech Accountability Project",
      "stakeholderGroup": "I work or am affiliated to a public interest body or NGO",
      "relationToIncident": "None of the above, but have partial or substantial knowledge of the incident (e.g. first-hand knowledge, research etc.)"
    },
    "unintendedUse": false
  },
  {
    "@context": [
      "http://localhost:3000/api/schemas/v1/core/context.jsonld",
      "http://localhost:3001/api/schemas/v1/oecd/context.jsonld"
    ],
    "@type": "oecd:Incident",
    "@id": "https://oecd.ai/incident/OECD-2018-061",
    "incident_id": "OECD-2018-061",
    "title": "Algorithmic Trading System Triggers Market Manipulation Investigation",
    "description": "High-frequency trading algorithms were found to be creating artificial price movements through coordinated trades. The AI systems learned to exploit market microstructure in ways that resembled illegal manipulation.",
    "date": "2018-08-05",
    "aiSystem": {
      "@type": "oecd:AISystem",
      "name": "Financial AI Engine Pro",
      "version": "10.9.79",
      "relation": [
        "oecd:ContributingFactor",
        "oecd:HumanError"
      ]
    },
    "developer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/Amazon_(company)",
      "name": "Amazon"
    },
    "deployer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/Nest_Labs",
      "name": "Nest Labs"
    },
    "severity": "oecd:SeriousHazard",
    "harmType": [
      "oecd:EconomicHarm",
      "oecd:PublicInterestHarm"
    ],
    "harmQuantification": {
      "@type": "oecd:HarmQuantification",
      "affected_stakeholders": "31329 patients"
    },
    "countries": [
      {
        "@type": "core:Country",
        "@id": "https://www.wikidata.org/wiki/Canada",
        "name": "Canada"
      },
      {
        "@type": "core:Country",
        "@id": "https://www.wikidata.org/wiki/United_Kingdom",
        "name": "United Kingdom"
      }
    ],
    "affectedStakeholders": [
      {
        "@type": "core:Person",
        "@id": "https://example.org/entities/person/bus-passengers",
        "name": "Bus passengers"
      },
      {
        "@type": "oecd:StakeholderGroup",
        "@id": "https://example.org/stakeholder-group/minority-groups",
        "name": "Minority Groups"
      },
      {
        "@type": "oecd:StakeholderGroup",
        "@id": "https://example.org/stakeholder-group/students",
        "name": "Students"
      }
    ],
    "businessFunction": [
      "oecd:OtherFunction"
    ],
    "submitter": {
      "@type": "oecd:Submitter",
      "@id": "https://example.org/submitter/reporter",
      "role": "Safety Engineer",
      "affiliation": "Tech Accountability Project",
      "stakeholderGroup": "I am an affected stakeholder",
      "relationToIncident": "None of the above, but have partial or substantial knowledge of the incident (e.g. first-hand knowledge, research etc.)"
    },
    "unintendedUse": false
  },
  {
    "@context": [
      "http://localhost:3000/api/schemas/v1/core/context.jsonld",
      "http://localhost:3001/api/schemas/v1/oecd/context.jsonld"
    ],
    "@type": "oecd:Incident",
    "@id": "https://oecd.ai/incident/OECD-2018-062",
    "incident_id": "OECD-2018-062",
    "title": "Facial Recognition System Falsely Identifies Protesters as Criminals",
    "description": "A law enforcement facial recognition system incorrectly matched peaceful protesters with criminal database entries, leading to wrongful detentions. The AI system showed higher error rates for certain ethnic groups and in crowded scenarios.",
    "date": "2018-08-06",
    "aiSystem": {
      "@type": "oecd:AISystem",
      "name": "Security/Surveillance System",
      "version": "1.4.34",
      "relation": [
        "oecd:ContributingFactor",
        "oecd:HumanError"
      ]
    },
    "developer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/Uber",
      "name": "Uber"
    },
    "deployer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/United_States_Government",
      "name": "United States Government"
    },
    "severity": "oecd:SeriousIncident",
    "harmType": [
      "oecd:PhysicalHarm",
      "oecd:HumanRightsHarm",
      "oecd:ReputationalHarm"
    ],
    "harmQuantification": {
      "@type": "oecd:HarmQuantification",
      "affected_stakeholders": "73495 workers"
    },
    "countries": [
      {
        "@type": "core:Country",
        "@id": "https://www.wikidata.org/wiki/China",
        "name": "China"
      }
    ],
    "affectedStakeholders": [
      {
        "@type": "oecd:StakeholderGroup",
        "@id": "https://example.org/stakeholder-group/patients",
        "name": "Patients"
      }
    ],
    "businessFunction": [
      "oecd:Compliance"
    ],
    "submitter": {
      "@type": "oecd:Submitter",
      "@id": "https://example.org/submitter/reporter",
      "role": "Academic Researcher",
      "affiliation": "Digital Rights Organization",
      "stakeholderGroup": "I am an affected stakeholder",
      "relationToIncident": "None of the above, but have partial or substantial knowledge of the incident (e.g. first-hand knowledge, research etc.)"
    },
    "unintendedUse": false
  },
  {
    "@context": [
      "http://localhost:3000/api/schemas/v1/core/context.jsonld",
      "http://localhost:3001/api/schemas/v1/oecd/context.jsonld"
    ],
    "@type": "oecd:Incident",
    "@id": "https://oecd.ai/incident/OECD-2018-063",
    "incident_id": "OECD-2018-063",
    "title": "Predictive Policing Algorithm Creates Feedback Loops in Minority Neighborhoods",
    "description": "An AI system for predicting crime hotspots consistently directed more police presence to minority neighborhoods, creating a self-reinforcing cycle where increased police presence led to more reported incidents, further biasing the algorithm.",
    "date": "2018-09-07",
    "aiSystem": {
      "@type": "oecd:AISystem",
      "name": "Security/Surveillance Solution Pro",
      "version": "5.1.57",
      "relation": [
        "oecd:DirectCause",
        "oecd:ContributingFactor"
      ]
    },
    "developer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/LinkedIn",
      "name": "LinkedIn"
    },
    "deployer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/Amazon_(company)",
      "name": "Amazon"
    },
    "severity": "oecd:SeriousHazard",
    "harmType": [
      "oecd:HumanRightsHarm",
      "oecd:PsychologicalHarm"
    ],
    "harmQuantification": {
      "@type": "oecd:HarmQuantification",
      "affected_stakeholders": "71086 workers",
      "economic_losses": "$15.0 million",
      "psychological_impact": "Documented stress and anxiety in affected population"
    },
    "countries": [
      {
        "@type": "core:Country",
        "@id": "https://www.wikidata.org/wiki/Israel",
        "name": "Israel"
      },
      {
        "@type": "core:Country",
        "@id": "https://www.wikidata.org/wiki/France",
        "name": "France"
      }
    ],
    "affectedStakeholders": [
      {
        "@type": "core:Person",
        "@id": "https://example.org/entities/person/bus-passengers",
        "name": "Bus passengers"
      },
      {
        "@type": "oecd:StakeholderGroup",
        "@id": "https://example.org/stakeholder-group/children",
        "name": "Children"
      }
    ],
    "businessFunction": [
      "oecd:Compliance",
      "oecd:Planning"
    ],
    "submitter": {
      "@type": "oecd:Submitter",
      "@id": "https://example.org/submitter/reporter",
      "role": "Industry Whistleblower",
      "affiliation": "Consumer Protection Agency",
      "stakeholderGroup": "I am an affected stakeholder",
      "relationToIncident": "None of the above, but have partial or substantial knowledge of the incident (e.g. first-hand knowledge, research etc.)"
    },
    "unintendedUse": false
  },
  {
    "@context": [
      "http://localhost:3000/api/schemas/v1/core/context.jsonld",
      "http://localhost:3001/api/schemas/v1/oecd/context.jsonld"
    ],
    "@type": "oecd:Incident",
    "@id": "https://oecd.ai/incident/OECD-2018-064",
    "incident_id": "OECD-2018-064",
    "title": "Facial Recognition System Falsely Identifies Protesters as Criminals",
    "description": "A law enforcement facial recognition system incorrectly matched peaceful protesters with criminal database entries, leading to wrongful detentions. The AI system showed higher error rates for certain ethnic groups and in crowded scenarios.",
    "date": "2018-11-19",
    "aiSystem": {
      "@type": "oecd:AISystem",
      "name": "Security/Surveillance Engine Pro",
      "version": "4.13.11",
      "relation": [
        "oecd:ContributingFactor",
        "oecd:HumanError"
      ]
    },
    "developer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/LinkedIn",
      "name": "LinkedIn"
    },
    "deployer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/Google",
      "name": "Google"
    },
    "severity": "oecd:SeriousIncident",
    "harmType": [
      "oecd:PhysicalHarm",
      "oecd:HumanRightsHarm",
      "oecd:ReputationalHarm"
    ],
    "harmQuantification": {
      "@type": "oecd:HarmQuantification",
      "affected_stakeholders": "76282 individuals"
    },
    "countries": [
      {
        "@type": "core:Country",
        "@id": "https://www.wikidata.org/wiki/Brazil",
        "name": "Brazil"
      }
    ],
    "affectedStakeholders": [
      {
        "@type": "core:Person",
        "@id": "https://example.org/entities/person/airplane-passengers",
        "name": "Airplane Passengers"
      },
      {
        "@type": "core:Person",
        "@id": "https://example.org/entities/person/job-applicants",
        "name": "Job applicants"
      },
      {
        "@type": "oecd:StakeholderGroup",
        "@id": "https://example.org/stakeholder-group/children",
        "name": "Children"
      }
    ],
    "businessFunction": [
      "oecd:Compliance"
    ],
    "submitter": {
      "@type": "oecd:Submitter",
      "@id": "https://example.org/submitter/reporter",
      "role": "Academic Researcher",
      "affiliation": "University Ethics Lab",
      "stakeholderGroup": "None of the above, but have partial or substantial knowledge of the incident",
      "relationToIncident": "None of the above, but have partial or substantial knowledge of the incident (e.g. first-hand knowledge, research etc.)"
    },
    "unintendedUse": false
  },
  {
    "@context": [
      "http://localhost:3000/api/schemas/v1/core/context.jsonld",
      "http://localhost:3001/api/schemas/v1/oecd/context.jsonld"
    ],
    "@type": "oecd:Incident",
    "@id": "https://oecd.ai/incident/OECD-2018-065",
    "incident_id": "OECD-2018-065",
    "title": "Facial Recognition System Falsely Identifies Protesters as Criminals",
    "description": "A law enforcement facial recognition system incorrectly matched peaceful protesters with criminal database entries, leading to wrongful detentions. The AI system showed higher error rates for certain ethnic groups and in crowded scenarios.",
    "date": "2018-12-01",
    "aiSystem": {
      "@type": "oecd:AISystem",
      "name": "Security/Surveillance System Pro",
      "version": "4.3.57",
      "relation": [
        "oecd:DirectCause",
        "oecd:ContributingFactor"
      ]
    },
    "developer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/LinkedIn",
      "name": "LinkedIn"
    },
    "deployer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/Boeing",
      "name": "Boeing"
    },
    "severity": "oecd:SeriousIncident",
    "harmType": [
      "oecd:PhysicalHarm",
      "oecd:HumanRightsHarm",
      "oecd:ReputationalHarm"
    ],
    "harmQuantification": {
      "@type": "oecd:HarmQuantification",
      "affected_stakeholders": "69076 individuals"
    },
    "countries": [
      {
        "@type": "core:Country",
        "@id": "https://www.wikidata.org/wiki/United_States",
        "name": "United States"
      },
      {
        "@type": "core:Country",
        "@id": "https://www.wikidata.org/wiki/France",
        "name": "France"
      }
    ],
    "affectedStakeholders": [
      {
        "@type": "oecd:StakeholderGroup",
        "@id": "https://example.org/stakeholder-group/students",
        "name": "Students"
      },
      {
        "@type": "core:Person",
        "@id": "https://example.org/entities/person/bus-passengers",
        "name": "Bus passengers"
      }
    ],
    "businessFunction": [
      "oecd:Compliance"
    ],
    "submitter": {
      "@type": "oecd:Submitter",
      "@id": "https://example.org/submitter/reporter",
      "role": "Safety Engineer",
      "affiliation": "Consumer Protection Agency",
      "stakeholderGroup": "I work or am affiliated to a public interest body or NGO",
      "relationToIncident": "None of the above, but have partial or substantial knowledge of the incident (e.g. first-hand knowledge, research etc.)"
    },
    "unintendedUse": false
  },
  {
    "@context": [
      "http://localhost:3000/api/schemas/v1/core/context.jsonld",
      "http://localhost:3001/api/schemas/v1/oecd/context.jsonld"
    ],
    "@type": "oecd:Incident",
    "@id": "https://oecd.ai/incident/OECD-2018-066",
    "incident_id": "OECD-2018-066",
    "title": "Agricultural AI Misidentifies Crops Leading to Herbicide Damage",
    "description": "An AI-powered crop monitoring and treatment system misidentified valuable crops as weeds, resulting in herbicide application that destroyed thousands of acres of produce. The computer vision model was not properly validated for the specific crop varieties.",
    "date": "2018-12-14",
    "aiSystem": {
      "@type": "oecd:AISystem",
      "name": "Autonomous Systems Engine",
      "version": "2.7.90",
      "relation": [
        "oecd:DirectCause"
      ]
    },
    "developer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/Navya_(company)",
      "name": "Navya"
    },
    "deployer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/New_Zealand",
      "name": "New Zealand"
    },
    "severity": "oecd:SeriousIncident",
    "harmType": [
      "oecd:EconomicHarm",
      "oecd:EnvironmentalHarm"
    ],
    "harmQuantification": {
      "@type": "oecd:HarmQuantification",
      "affected_stakeholders": "46911 individuals",
      "economic_losses": "$19.7 million"
    },
    "countries": [
      {
        "@type": "core:Country",
        "@id": "https://www.wikidata.org/wiki/Italy",
        "name": "Italy"
      },
      {
        "@type": "core:Country",
        "@id": "https://www.wikidata.org/wiki/France",
        "name": "France"
      }
    ],
    "affectedStakeholders": [
      {
        "@type": "core:Person",
        "@id": "https://example.org/entities/person/motorists",
        "name": "Motorists"
      }
    ],
    "businessFunction": [
      "oecd:Production",
      "oecd:OtherFunction"
    ],
    "submitter": {
      "@type": "oecd:Submitter",
      "@id": "https://example.org/submitter/reporter",
      "role": "Industry Whistleblower",
      "affiliation": "Digital Rights Organization",
      "stakeholderGroup": "None of the above, but have partial or substantial knowledge of the incident",
      "relationToIncident": "None of the above, but have partial or substantial knowledge of the incident (e.g. first-hand knowledge, research etc.)"
    },
    "unintendedUse": true
  },
  {
    "@context": [
      "http://localhost:3000/api/schemas/v1/core/context.jsonld",
      "http://localhost:3001/api/schemas/v1/oecd/context.jsonld"
    ],
    "@type": "oecd:Incident",
    "@id": "https://oecd.ai/incident/OECD-2018-067",
    "incident_id": "OECD-2018-067",
    "title": "Employee Monitoring AI Incorrectly Flags Remote Workers as Unproductive",
    "description": "An AI-powered employee productivity monitoring system incorrectly categorized focused work activities as idle time, leading to unfair performance reviews and terminations. The system failed to understand different working styles and break patterns.",
    "date": "2018-12-30",
    "aiSystem": {
      "@type": "oecd:AISystem",
      "name": "Workplace AI Engine Pro",
      "version": "4.16.50",
      "relation": [
        "oecd:DirectCause"
      ]
    },
    "developer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/Google",
      "name": "Google"
    },
    "deployer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/Various_organizations",
      "name": "Various organizations"
    },
    "severity": "oecd:SeriousIncident",
    "harmType": [
      "oecd:EconomicHarm",
      "oecd:PsychologicalHarm",
      "oecd:ReputationalHarm"
    ],
    "harmQuantification": {
      "@type": "oecd:HarmQuantification",
      "affected_stakeholders": "80080 individuals",
      "economic_losses": "$39.3 million",
      "psychological_impact": "Documented stress and anxiety in affected population"
    },
    "countries": [
      {
        "@type": "core:Country",
        "@id": "https://www.wikidata.org/wiki/Italy",
        "name": "Italy"
      }
    ],
    "affectedStakeholders": [
      {
        "@type": "core:Person",
        "@id": "https://example.org/entities/person/bus-passengers",
        "name": "Bus passengers"
      },
      {
        "@type": "oecd:StakeholderGroup",
        "@id": "https://example.org/stakeholder-group/children",
        "name": "Children"
      }
    ],
    "businessFunction": [
      "oecd:HRManagement",
      "oecd:QualityControl"
    ],
    "submitter": {
      "@type": "oecd:Submitter",
      "@id": "https://example.org/submitter/reporter",
      "role": "Safety Engineer",
      "affiliation": "Tech Accountability Project",
      "stakeholderGroup": "I represent a government or regulatory body",
      "relationToIncident": "None of the above, but have partial or substantial knowledge of the incident (e.g. first-hand knowledge, research etc.)"
    },
    "unintendedUse": false
  },
  {
    "@context": [
      "http://localhost:3000/api/schemas/v1/core/context.jsonld",
      "http://localhost:3001/api/schemas/v1/oecd/context.jsonld"
    ],
    "@type": "oecd:Incident",
    "@id": "https://oecd.ai/incident/OECD-2019-068",
    "incident_id": "OECD-2019-068",
    "title": "AI Interview System Shows Bias Against Non-Native Speakers",
    "description": "An automated video interview analysis system consistently gave lower scores to qualified candidates with accents or non-native speech patterns. The AI's speech recognition and sentiment analysis components showed significant bias.",
    "date": "2019-02-18",
    "aiSystem": {
      "@type": "oecd:AISystem",
      "name": "Workplace AI Engine",
      "version": "10.1.26",
      "relation": [
        "oecd:DirectCause",
        "oecd:ContributingFactor"
      ]
    },
    "developer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/Apple_Inc.",
      "name": "Apple"
    },
    "deployer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/Google",
      "name": "Google"
    },
    "severity": "oecd:SeriousIncident",
    "harmType": [
      "oecd:EconomicHarm",
      "oecd:HumanRightsHarm"
    ],
    "harmQuantification": {
      "@type": "oecd:HarmQuantification",
      "affected_stakeholders": "74738 patients"
    },
    "countries": [
      {
        "@type": "core:Country",
        "@id": "https://www.wikidata.org/wiki/Germany",
        "name": "Germany"
      },
      {
        "@type": "core:Country",
        "@id": "https://www.wikidata.org/wiki/France",
        "name": "France"
      }
    ],
    "affectedStakeholders": [
      {
        "@type": "core:Person",
        "@id": "https://example.org/entities/person/pedestrians",
        "name": "Pedestrians"
      },
      {
        "@type": "oecd:StakeholderGroup",
        "@id": "https://example.org/stakeholder-group/women",
        "name": "Women"
      },
      {
        "@type": "oecd:StakeholderGroup",
        "@id": "https://example.org/stakeholder-group/students",
        "name": "Students"
      }
    ],
    "businessFunction": [
      "oecd:HRManagement"
    ],
    "submitter": {
      "@type": "oecd:Submitter",
      "@id": "https://example.org/submitter/reporter",
      "role": "Industry Whistleblower",
      "affiliation": "AI Safety Coalition",
      "stakeholderGroup": "I work or am affiliated to a public interest body or NGO",
      "relationToIncident": "None of the above, but have partial or substantial knowledge of the incident (e.g. first-hand knowledge, research etc.)"
    },
    "unintendedUse": false
  },
  {
    "@context": [
      "http://localhost:3000/api/schemas/v1/core/context.jsonld",
      "http://localhost:3001/api/schemas/v1/oecd/context.jsonld"
    ],
    "@type": "oecd:Incident",
    "@id": "https://oecd.ai/incident/OECD-2019-069",
    "incident_id": "OECD-2019-069",
    "title": "AI Personal Assistant Shares Private Information in Group Settings",
    "description": "A voice-activated AI assistant failed to recognize multi-user environments and shared personal calendar entries, medical reminders, and financial information when responding to queries in group settings.",
    "date": "2019-03-15",
    "aiSystem": {
      "@type": "oecd:AISystem",
      "name": "Consumer AI System Pro",
      "version": "2.13.3",
      "relation": [
        "oecd:DirectCause",
        "oecd:FailureToAct"
      ]
    },
    "developer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/Google",
      "name": "Google"
    },
    "deployer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/Wikipedia",
      "name": "Wikipedia"
    },
    "severity": "oecd:SeriousIncident",
    "harmType": [
      "oecd:ReputationalHarm",
      "oecd:HumanRightsHarm"
    ],
    "harmQuantification": {
      "@type": "oecd:HarmQuantification",
      "affected_stakeholders": "5547 customers"
    },
    "countries": [
      {
        "@type": "core:Country",
        "@id": "https://www.wikidata.org/wiki/Sweden",
        "name": "Sweden"
      }
    ],
    "affectedStakeholders": [
      {
        "@type": "oecd:StakeholderGroup",
        "@id": "https://example.org/stakeholder-group/students",
        "name": "Students"
      }
    ],
    "businessFunction": [
      "oecd:CustomerService",
      "oecd:ICTManagement"
    ],
    "submitter": {
      "@type": "oecd:Submitter",
      "@id": "https://example.org/submitter/reporter",
      "role": "Industry Whistleblower",
      "affiliation": "Tech Accountability Project",
      "stakeholderGroup": "None of the above, but have partial or substantial knowledge of the incident",
      "relationToIncident": "None of the above, but have partial or substantial knowledge of the incident (e.g. first-hand knowledge, research etc.)"
    },
    "unintendedUse": true
  },
  {
    "@context": [
      "http://localhost:3000/api/schemas/v1/core/context.jsonld",
      "http://localhost:3001/api/schemas/v1/oecd/context.jsonld"
    ],
    "@type": "oecd:Incident",
    "@id": "https://oecd.ai/incident/OECD-2019-070",
    "incident_id": "OECD-2019-070",
    "title": "AI Interview System Shows Bias Against Non-Native Speakers",
    "description": "An automated video interview analysis system consistently gave lower scores to qualified candidates with accents or non-native speech patterns. The AI's speech recognition and sentiment analysis components showed significant bias.",
    "date": "2019-03-15",
    "aiSystem": {
      "@type": "oecd:AISystem",
      "name": "Workplace AI System Pro",
      "version": "6.17.60",
      "relation": [
        "oecd:ContributingFactor"
      ]
    },
    "developer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/Google",
      "name": "Google"
    },
    "deployer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/LinkedIn",
      "name": "LinkedIn"
    },
    "severity": "oecd:SeriousIncident",
    "harmType": [
      "oecd:EconomicHarm",
      "oecd:HumanRightsHarm"
    ],
    "harmQuantification": {
      "@type": "oecd:HarmQuantification",
      "affected_stakeholders": "43668 workers",
      "economic_losses": "$25.8 million"
    },
    "countries": [
      {
        "@type": "core:Country",
        "@id": "https://www.wikidata.org/wiki/Germany",
        "name": "Germany"
      },
      {
        "@type": "core:Country",
        "@id": "https://www.wikidata.org/wiki/Brazil",
        "name": "Brazil"
      }
    ],
    "affectedStakeholders": [
      {
        "@type": "core:Person",
        "@id": "https://example.org/entities/person/airplane-passengers",
        "name": "Airplane Passengers"
      }
    ],
    "businessFunction": [
      "oecd:HRManagement"
    ],
    "submitter": {
      "@type": "oecd:Submitter",
      "@id": "https://example.org/submitter/reporter",
      "role": "Government Auditor",
      "affiliation": "Tech Accountability Project",
      "stakeholderGroup": "I work or am affiliated to a public interest body or NGO",
      "relationToIncident": "None of the above, but have partial or substantial knowledge of the incident (e.g. first-hand knowledge, research etc.)"
    },
    "unintendedUse": false
  },
  {
    "@context": [
      "http://localhost:3000/api/schemas/v1/core/context.jsonld",
      "http://localhost:3001/api/schemas/v1/oecd/context.jsonld"
    ],
    "@type": "oecd:Incident",
    "@id": "https://oecd.ai/incident/OECD-2019-071",
    "incident_id": "OECD-2019-071",
    "title": "Predictive Policing Algorithm Creates Feedback Loops in Minority Neighborhoods",
    "description": "An AI system for predicting crime hotspots consistently directed more police presence to minority neighborhoods, creating a self-reinforcing cycle where increased police presence led to more reported incidents, further biasing the algorithm.",
    "date": "2019-04-17",
    "aiSystem": {
      "@type": "oecd:AISystem",
      "name": "Security/Surveillance Solution",
      "version": "9.18.14",
      "relation": [
        "oecd:ContributingFactor",
        "oecd:HumanError"
      ]
    },
    "developer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/Uber",
      "name": "Uber"
    },
    "deployer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/Tesla,_Inc.",
      "name": "Tesla"
    },
    "severity": "oecd:SeriousHazard",
    "harmType": [
      "oecd:HumanRightsHarm",
      "oecd:PsychologicalHarm"
    ],
    "harmQuantification": {
      "@type": "oecd:HarmQuantification",
      "affected_stakeholders": "5224 customers",
      "economic_losses": "$20.3 million",
      "psychological_impact": "Documented stress and anxiety in affected population"
    },
    "countries": [
      {
        "@type": "core:Country",
        "@id": "https://www.wikidata.org/wiki/Spain",
        "name": "Spain"
      },
      {
        "@type": "core:Country",
        "@id": "https://www.wikidata.org/wiki/France",
        "name": "France"
      }
    ],
    "affectedStakeholders": [
      {
        "@type": "oecd:StakeholderGroup",
        "@id": "https://example.org/stakeholder-group/patients",
        "name": "Patients"
      },
      {
        "@type": "core:Person",
        "@id": "https://example.org/entities/person/airplane-passengers",
        "name": "Airplane Passengers"
      }
    ],
    "businessFunction": [
      "oecd:Compliance",
      "oecd:Planning"
    ],
    "submitter": {
      "@type": "oecd:Submitter",
      "@id": "https://example.org/submitter/reporter",
      "role": "Consumer Advocate",
      "affiliation": "Tech Accountability Project",
      "stakeholderGroup": "I work or am affiliated to a public interest body or NGO",
      "relationToIncident": "None of the above, but have partial or substantial knowledge of the incident (e.g. first-hand knowledge, research etc.)"
    },
    "unintendedUse": false
  },
  {
    "@context": [
      "http://localhost:3000/api/schemas/v1/core/context.jsonld",
      "http://localhost:3001/api/schemas/v1/oecd/context.jsonld"
    ],
    "@type": "oecd:Incident",
    "@id": "https://oecd.ai/incident/OECD-2019-072",
    "incident_id": "OECD-2019-072",
    "title": "Smart Home AI Creates Dangerous Living Conditions for Elderly",
    "description": "An AI-powered smart home system learned incorrect patterns from an elderly resident with dementia, subsequently creating dangerous conditions by adjusting heating, lighting, and security settings inappropriately.",
    "date": "2019-05-03",
    "aiSystem": {
      "@type": "oecd:AISystem",
      "name": "Consumer AI System Pro",
      "version": "8.5.26",
      "relation": [
        "oecd:ContributingFactor",
        "oecd:HumanError"
      ]
    },
    "developer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/University_of_Washington",
      "name": "University of Washington"
    },
    "deployer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/Amazon_(company)",
      "name": "Amazon"
    },
    "severity": "oecd:SeriousHazard",
    "harmType": [
      "oecd:PhysicalHarm",
      "oecd:PsychologicalHarm"
    ],
    "harmQuantification": {
      "@type": "oecd:HarmQuantification",
      "affected_stakeholders": "30053 patients",
      "economic_losses": "$43.2 million",
      "psychological_impact": "Documented stress and anxiety in affected population"
    },
    "countries": [
      {
        "@type": "core:Country",
        "@id": "https://www.wikidata.org/wiki/Israel",
        "name": "Israel"
      }
    ],
    "affectedStakeholders": [
      {
        "@type": "core:Person",
        "@id": "https://example.org/entities/person/motorists",
        "name": "Motorists"
      }
    ],
    "businessFunction": [
      "oecd:CustomerService",
      "oecd:OtherFunction"
    ],
    "submitter": {
      "@type": "oecd:Submitter",
      "@id": "https://example.org/submitter/reporter",
      "role": "Academic Researcher",
      "affiliation": "Consumer Protection Agency",
      "stakeholderGroup": "None of the above, but have partial or substantial knowledge of the incident",
      "relationToIncident": "None of the above, but have partial or substantial knowledge of the incident (e.g. first-hand knowledge, research etc.)"
    },
    "unintendedUse": true
  },
  {
    "@context": [
      "http://localhost:3000/api/schemas/v1/core/context.jsonld",
      "http://localhost:3001/api/schemas/v1/oecd/context.jsonld"
    ],
    "@type": "oecd:Incident",
    "@id": "https://oecd.ai/incident/OECD-2019-073",
    "incident_id": "OECD-2019-073",
    "title": "Agricultural AI Misidentifies Crops Leading to Herbicide Damage",
    "description": "An AI-powered crop monitoring and treatment system misidentified valuable crops as weeds, resulting in herbicide application that destroyed thousands of acres of produce. The computer vision model was not properly validated for the specific crop varieties.",
    "date": "2019-05-07",
    "aiSystem": {
      "@type": "oecd:AISystem",
      "name": "Autonomous Systems Solution Pro",
      "version": "4.7.99",
      "relation": [
        "oecd:DirectCause"
      ]
    },
    "developer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/Delphi_Technologies",
      "name": "Delphi Technologies"
    },
    "deployer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/Boeing",
      "name": "Boeing"
    },
    "severity": "oecd:SeriousIncident",
    "harmType": [
      "oecd:EconomicHarm",
      "oecd:EnvironmentalHarm"
    ],
    "harmQuantification": {
      "@type": "oecd:HarmQuantification",
      "affected_stakeholders": "50128 patients",
      "economic_losses": "$32.8 million"
    },
    "countries": [
      {
        "@type": "core:Country",
        "@id": "https://www.wikidata.org/wiki/United_Kingdom",
        "name": "United Kingdom"
      },
      {
        "@type": "core:Country",
        "@id": "https://www.wikidata.org/wiki/France",
        "name": "France"
      }
    ],
    "affectedStakeholders": [
      {
        "@type": "oecd:StakeholderGroup",
        "@id": "https://example.org/stakeholder-group/consumers",
        "name": "Consumers"
      },
      {
        "@type": "oecd:StakeholderGroup",
        "@id": "https://example.org/stakeholder-group/minority-groups",
        "name": "Minority Groups"
      }
    ],
    "businessFunction": [
      "oecd:Production",
      "oecd:OtherFunction"
    ],
    "submitter": {
      "@type": "oecd:Submitter",
      "@id": "https://example.org/submitter/reporter",
      "role": "Data Scientist",
      "affiliation": "Digital Rights Organization",
      "stakeholderGroup": "None of the above, but have partial or substantial knowledge of the incident",
      "relationToIncident": "None of the above, but have partial or substantial knowledge of the incident (e.g. first-hand knowledge, research etc.)"
    },
    "unintendedUse": false
  },
  {
    "@context": [
      "http://localhost:3000/api/schemas/v1/core/context.jsonld",
      "http://localhost:3001/api/schemas/v1/oecd/context.jsonld"
    ],
    "@type": "oecd:Incident",
    "@id": "https://oecd.ai/incident/OECD-2019-074",
    "incident_id": "OECD-2019-074",
    "title": "Employee Monitoring AI Incorrectly Flags Remote Workers as Unproductive",
    "description": "An AI-powered employee productivity monitoring system incorrectly categorized focused work activities as idle time, leading to unfair performance reviews and terminations. The system failed to understand different working styles and break patterns.",
    "date": "2019-05-22",
    "aiSystem": {
      "@type": "oecd:AISystem",
      "name": "Workplace AI Platform Pro",
      "version": "5.7.8",
      "relation": [
        "oecd:DirectCause"
      ]
    },
    "developer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/Navya_(company)",
      "name": "Navya"
    },
    "deployer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/Uber",
      "name": "Uber"
    },
    "severity": "oecd:SeriousIncident",
    "harmType": [
      "oecd:EconomicHarm",
      "oecd:PsychologicalHarm",
      "oecd:ReputationalHarm"
    ],
    "harmQuantification": {
      "@type": "oecd:HarmQuantification",
      "affected_stakeholders": "1888 patients",
      "psychological_impact": "Documented stress and anxiety in affected population"
    },
    "countries": [
      {
        "@type": "core:Country",
        "@id": "https://www.wikidata.org/wiki/South_Korea",
        "name": "South Korea"
      }
    ],
    "affectedStakeholders": [
      {
        "@type": "core:Person",
        "@id": "https://example.org/entities/person/black-people",
        "name": "Black people"
      },
      {
        "@type": "oecd:StakeholderGroup",
        "@id": "https://example.org/stakeholder-group/women",
        "name": "Women"
      }
    ],
    "businessFunction": [
      "oecd:HRManagement",
      "oecd:QualityControl"
    ],
    "submitter": {
      "@type": "oecd:Submitter",
      "@id": "https://example.org/submitter/reporter",
      "role": "Industry Whistleblower",
      "affiliation": "AI Safety Coalition",
      "stakeholderGroup": "I work or am affiliated to a public interest body or NGO",
      "relationToIncident": "None of the above, but have partial or substantial knowledge of the incident (e.g. first-hand knowledge, research etc.)"
    },
    "unintendedUse": false
  },
  {
    "@context": [
      "http://localhost:3000/api/schemas/v1/core/context.jsonld",
      "http://localhost:3001/api/schemas/v1/oecd/context.jsonld"
    ],
    "@type": "oecd:Incident",
    "@id": "https://oecd.ai/incident/OECD-2019-075",
    "incident_id": "OECD-2019-075",
    "title": "AI Diagnostic System Misses Critical Symptoms in Emergency Department",
    "description": "An AI triage system in emergency departments failed to identify critical symptoms in patients presenting with atypical manifestations of serious conditions. The system's training data lacked diversity in symptom presentations across different demographics.",
    "date": "2019-06-04",
    "aiSystem": {
      "@type": "oecd:AISystem",
      "name": "Medical AI Platform Pro",
      "version": "3.13.77",
      "relation": [
        "oecd:DirectCause",
        "oecd:ContributingFactor"
      ]
    },
    "developer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/Google",
      "name": "Google"
    },
    "deployer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/Volkswagen",
      "name": "Volkswagen"
    },
    "severity": "oecd:SeriousHazard",
    "harmType": [
      "oecd:PhysicalHarm",
      "oecd:HumanRightsHarm"
    ],
    "harmQuantification": {
      "@type": "oecd:HarmQuantification",
      "affected_stakeholders": "17961 individuals",
      "economic_losses": "$21.0 million"
    },
    "countries": [
      {
        "@type": "core:Country",
        "@id": "https://www.wikidata.org/wiki/United_Kingdom",
        "name": "United Kingdom"
      }
    ],
    "affectedStakeholders": [
      {
        "@type": "oecd:StakeholderGroup",
        "@id": "https://example.org/stakeholder-group/children",
        "name": "Children"
      }
    ],
    "businessFunction": [
      "oecd:OtherFunction"
    ],
    "submitter": {
      "@type": "oecd:Submitter",
      "@id": "https://example.org/submitter/reporter",
      "role": "Safety Engineer",
      "affiliation": "Consumer Protection Agency",
      "stakeholderGroup": "I am an affected stakeholder",
      "relationToIncident": "None of the above, but have partial or substantial knowledge of the incident (e.g. first-hand knowledge, research etc.)"
    },
    "unintendedUse": false
  },
  {
    "@context": [
      "http://localhost:3000/api/schemas/v1/core/context.jsonld",
      "http://localhost:3001/api/schemas/v1/oecd/context.jsonld"
    ],
    "@type": "oecd:Incident",
    "@id": "https://oecd.ai/incident/OECD-2019-076",
    "incident_id": "OECD-2019-076",
    "title": "Algorithmic Trading System Triggers Market Manipulation Investigation",
    "description": "High-frequency trading algorithms were found to be creating artificial price movements through coordinated trades. The AI systems learned to exploit market microstructure in ways that resembled illegal manipulation.",
    "date": "2019-06-10",
    "aiSystem": {
      "@type": "oecd:AISystem",
      "name": "Financial AI Solution",
      "version": "7.10.62",
      "relation": [
        "oecd:ContributingFactor",
        "oecd:HumanError"
      ]
    },
    "developer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/Microsoft",
      "name": "Microsoft"
    },
    "deployer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/Delhi_Metro_Rail_Corporation",
      "name": "Delhi Metro Rail Corporation"
    },
    "severity": "oecd:SeriousHazard",
    "harmType": [
      "oecd:EconomicHarm",
      "oecd:PublicInterestHarm"
    ],
    "harmQuantification": {
      "@type": "oecd:HarmQuantification",
      "affected_stakeholders": "4145 workers",
      "economic_losses": "$38.9 million"
    },
    "countries": [
      {
        "@type": "core:Country",
        "@id": "https://www.wikidata.org/wiki/Norway",
        "name": "Norway"
      }
    ],
    "affectedStakeholders": [
      {
        "@type": "core:Person",
        "@id": "https://example.org/entities/person/black-people",
        "name": "Black people"
      }
    ],
    "businessFunction": [
      "oecd:OtherFunction"
    ],
    "submitter": {
      "@type": "oecd:Submitter",
      "@id": "https://example.org/submitter/reporter",
      "role": "Safety Engineer",
      "affiliation": "University Ethics Lab",
      "stakeholderGroup": "I work or am affiliated to a public interest body or NGO",
      "relationToIncident": "None of the above, but have partial or substantial knowledge of the incident (e.g. first-hand knowledge, research etc.)"
    },
    "unintendedUse": false
  },
  {
    "@context": [
      "http://localhost:3000/api/schemas/v1/core/context.jsonld",
      "http://localhost:3001/api/schemas/v1/oecd/context.jsonld"
    ],
    "@type": "oecd:Incident",
    "@id": "https://oecd.ai/incident/OECD-2019-077",
    "incident_id": "OECD-2019-077",
    "title": "Smart Home AI Creates Dangerous Living Conditions for Elderly",
    "description": "An AI-powered smart home system learned incorrect patterns from an elderly resident with dementia, subsequently creating dangerous conditions by adjusting heating, lighting, and security settings inappropriately.",
    "date": "2019-06-23",
    "aiSystem": {
      "@type": "oecd:AISystem",
      "name": "Consumer AI System Pro",
      "version": "3.1.28",
      "relation": [
        "oecd:DirectCause"
      ]
    },
    "developer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/Google",
      "name": "Google"
    },
    "deployer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/The_DAO",
      "name": "The DAO"
    },
    "severity": "oecd:SeriousHazard",
    "harmType": [
      "oecd:PhysicalHarm",
      "oecd:PsychologicalHarm"
    ],
    "harmQuantification": {
      "@type": "oecd:HarmQuantification",
      "affected_stakeholders": "91218 users",
      "economic_losses": "$37.9 million",
      "psychological_impact": "Documented stress and anxiety in affected population"
    },
    "countries": [
      {
        "@type": "core:Country",
        "@id": "https://www.wikidata.org/wiki/France",
        "name": "France"
      },
      {
        "@type": "core:Country",
        "@id": "https://www.wikidata.org/wiki/Brazil",
        "name": "Brazil"
      }
    ],
    "affectedStakeholders": [
      {
        "@type": "core:Person",
        "@id": "https://example.org/entities/person/job-applicants",
        "name": "Job applicants"
      },
      {
        "@type": "core:Person",
        "@id": "https://example.org/entities/person/black-people",
        "name": "Black people"
      }
    ],
    "businessFunction": [
      "oecd:CustomerService",
      "oecd:OtherFunction"
    ],
    "submitter": {
      "@type": "oecd:Submitter",
      "@id": "https://example.org/submitter/reporter",
      "role": "Data Scientist",
      "affiliation": "University Ethics Lab",
      "stakeholderGroup": "I am an affected stakeholder",
      "relationToIncident": "None of the above, but have partial or substantial knowledge of the incident (e.g. first-hand knowledge, research etc.)"
    },
    "unintendedUse": false
  },
  {
    "@context": [
      "http://localhost:3000/api/schemas/v1/core/context.jsonld",
      "http://localhost:3001/api/schemas/v1/oecd/context.jsonld"
    ],
    "@type": "oecd:Incident",
    "@id": "https://oecd.ai/incident/OECD-2019-078",
    "incident_id": "OECD-2019-078",
    "title": "Delivery Robot Swarm Blocks Emergency Vehicle Access",
    "description": "A fleet of autonomous delivery robots failed to coordinate their movements during an emergency, blocking paramedic access to a medical emergency. The swarm intelligence system lacked proper emergency vehicle detection and response protocols.",
    "date": "2019-07-03",
    "aiSystem": {
      "@type": "oecd:AISystem",
      "name": "Autonomous Systems Engine Pro",
      "version": "9.18.85",
      "relation": [
        "oecd:DirectCause",
        "oecd:ContributingFactor"
      ]
    },
    "developer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/Microsoft",
      "name": "Microsoft"
    },
    "deployer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/Nest_Labs",
      "name": "Nest Labs"
    },
    "severity": "oecd:SeriousHazard",
    "harmType": [
      "oecd:PhysicalHarm",
      "oecd:PublicInterestHarm"
    ],
    "harmQuantification": {
      "@type": "oecd:HarmQuantification",
      "affected_stakeholders": "114 patients"
    },
    "countries": [
      {
        "@type": "core:Country",
        "@id": "https://www.wikidata.org/wiki/Germany",
        "name": "Germany"
      },
      {
        "@type": "core:Country",
        "@id": "https://www.wikidata.org/wiki/Italy",
        "name": "Italy"
      }
    ],
    "affectedStakeholders": [
      {
        "@type": "oecd:StakeholderGroup",
        "@id": "https://example.org/stakeholder-group/children",
        "name": "Children"
      },
      {
        "@type": "core:Person",
        "@id": "https://example.org/entities/person/black-people",
        "name": "Black people"
      }
    ],
    "businessFunction": [
      "oecd:Logistics",
      "oecd:OtherFunction"
    ],
    "submitter": {
      "@type": "oecd:Submitter",
      "@id": "https://example.org/submitter/reporter",
      "role": "Government Auditor",
      "affiliation": "Consumer Protection Agency",
      "stakeholderGroup": "None of the above, but have partial or substantial knowledge of the incident",
      "relationToIncident": "None of the above, but have partial or substantial knowledge of the incident (e.g. first-hand knowledge, research etc.)"
    },
    "unintendedUse": false
  },
  {
    "@context": [
      "http://localhost:3000/api/schemas/v1/core/context.jsonld",
      "http://localhost:3001/api/schemas/v1/oecd/context.jsonld"
    ],
    "@type": "oecd:Incident",
    "@id": "https://oecd.ai/incident/OECD-2019-079",
    "incident_id": "OECD-2019-079",
    "title": "AI Personal Assistant Shares Private Information in Group Settings",
    "description": "A voice-activated AI assistant failed to recognize multi-user environments and shared personal calendar entries, medical reminders, and financial information when responding to queries in group settings.",
    "date": "2019-09-07",
    "aiSystem": {
      "@type": "oecd:AISystem",
      "name": "Consumer AI Engine Pro",
      "version": "5.16.58",
      "relation": [
        "oecd:ContributingFactor"
      ]
    },
    "developer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/YouTube",
      "name": "YouTube"
    },
    "deployer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/Various_organizations",
      "name": "Various organizations"
    },
    "severity": "oecd:SeriousIncident",
    "harmType": [
      "oecd:ReputationalHarm",
      "oecd:HumanRightsHarm"
    ],
    "harmQuantification": {
      "@type": "oecd:HarmQuantification",
      "affected_stakeholders": "67019 customers",
      "economic_losses": "$30.4 million"
    },
    "countries": [
      {
        "@type": "core:Country",
        "@id": "https://www.wikidata.org/wiki/United_States",
        "name": "United States"
      },
      {
        "@type": "core:Country",
        "@id": "https://www.wikidata.org/wiki/Mexico",
        "name": "Mexico"
      }
    ],
    "affectedStakeholders": [
      {
        "@type": "oecd:StakeholderGroup",
        "@id": "https://example.org/stakeholder-group/children",
        "name": "Children"
      }
    ],
    "businessFunction": [
      "oecd:CustomerService",
      "oecd:ICTManagement"
    ],
    "submitter": {
      "@type": "oecd:Submitter",
      "@id": "https://example.org/submitter/reporter",
      "role": "Consumer Advocate",
      "affiliation": "AI Safety Coalition",
      "stakeholderGroup": "None of the above, but have partial or substantial knowledge of the incident",
      "relationToIncident": "None of the above, but have partial or substantial knowledge of the incident (e.g. first-hand knowledge, research etc.)"
    },
    "unintendedUse": false
  },
  {
    "@context": [
      "http://localhost:3000/api/schemas/v1/core/context.jsonld",
      "http://localhost:3001/api/schemas/v1/oecd/context.jsonld"
    ],
    "@type": "oecd:Incident",
    "@id": "https://oecd.ai/incident/OECD-2019-080",
    "incident_id": "OECD-2019-080",
    "title": "Facial Recognition System Falsely Identifies Protesters as Criminals",
    "description": "A law enforcement facial recognition system incorrectly matched peaceful protesters with criminal database entries, leading to wrongful detentions. The AI system showed higher error rates for certain ethnic groups and in crowded scenarios.",
    "date": "2019-10-07",
    "aiSystem": {
      "@type": "oecd:AISystem",
      "name": "Security/Surveillance System",
      "version": "2.14.81",
      "relation": [
        "oecd:DirectCause",
        "oecd:FailureToAct"
      ]
    },
    "developer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/Google",
      "name": "Google"
    },
    "deployer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/United_States_Government",
      "name": "United States Government"
    },
    "severity": "oecd:SeriousIncident",
    "harmType": [
      "oecd:PhysicalHarm",
      "oecd:HumanRightsHarm",
      "oecd:ReputationalHarm"
    ],
    "harmQuantification": {
      "@type": "oecd:HarmQuantification",
      "affected_stakeholders": "19098 individuals",
      "economic_losses": "$49.4 million"
    },
    "countries": [
      {
        "@type": "core:Country",
        "@id": "https://www.wikidata.org/wiki/China",
        "name": "China"
      },
      {
        "@type": "core:Country",
        "@id": "https://www.wikidata.org/wiki/Canada",
        "name": "Canada"
      }
    ],
    "affectedStakeholders": [
      {
        "@type": "core:Person",
        "@id": "https://example.org/entities/person/bus-passengers",
        "name": "Bus passengers"
      },
      {
        "@type": "oecd:StakeholderGroup",
        "@id": "https://example.org/stakeholder-group/workers",
        "name": "Workers"
      },
      {
        "@type": "oecd:StakeholderGroup",
        "@id": "https://example.org/stakeholder-group/students",
        "name": "Students"
      }
    ],
    "businessFunction": [
      "oecd:Compliance"
    ],
    "submitter": {
      "@type": "oecd:Submitter",
      "@id": "https://example.org/submitter/reporter",
      "role": "Academic Researcher",
      "affiliation": "University Ethics Lab",
      "stakeholderGroup": "I work or am affiliated to a public interest body or NGO",
      "relationToIncident": "None of the above, but have partial or substantial knowledge of the incident (e.g. first-hand knowledge, research etc.)"
    },
    "unintendedUse": false
  },
  {
    "@context": [
      "http://localhost:3000/api/schemas/v1/core/context.jsonld",
      "http://localhost:3001/api/schemas/v1/oecd/context.jsonld"
    ],
    "@type": "oecd:Incident",
    "@id": "https://oecd.ai/incident/OECD-2019-081",
    "incident_id": "OECD-2019-081",
    "title": "Employee Monitoring AI Incorrectly Flags Remote Workers as Unproductive",
    "description": "An AI-powered employee productivity monitoring system incorrectly categorized focused work activities as idle time, leading to unfair performance reviews and terminations. The system failed to understand different working styles and break patterns.",
    "date": "2019-10-19",
    "aiSystem": {
      "@type": "oecd:AISystem",
      "name": "Workplace AI System",
      "version": "6.1.31",
      "relation": [
        "oecd:DirectCause",
        "oecd:FailureToAct"
      ]
    },
    "developer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/MIT_Media_Lab",
      "name": "MIT Media Lab"
    },
    "deployer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/Google",
      "name": "Google"
    },
    "severity": "oecd:SeriousIncident",
    "harmType": [
      "oecd:EconomicHarm",
      "oecd:PsychologicalHarm",
      "oecd:ReputationalHarm"
    ],
    "harmQuantification": {
      "@type": "oecd:HarmQuantification",
      "affected_stakeholders": "6439 individuals",
      "psychological_impact": "Documented stress and anxiety in affected population"
    },
    "countries": [
      {
        "@type": "core:Country",
        "@id": "https://www.wikidata.org/wiki/Mexico",
        "name": "Mexico"
      }
    ],
    "affectedStakeholders": [
      {
        "@type": "core:Person",
        "@id": "https://example.org/entities/person/bus-passengers",
        "name": "Bus passengers"
      },
      {
        "@type": "oecd:StakeholderGroup",
        "@id": "https://example.org/stakeholder-group/children",
        "name": "Children"
      }
    ],
    "businessFunction": [
      "oecd:HRManagement",
      "oecd:QualityControl"
    ],
    "submitter": {
      "@type": "oecd:Submitter",
      "@id": "https://example.org/submitter/reporter",
      "role": "Data Scientist",
      "affiliation": "Digital Rights Organization",
      "stakeholderGroup": "I am an affected stakeholder",
      "relationToIncident": "None of the above, but have partial or substantial knowledge of the incident (e.g. first-hand knowledge, research etc.)"
    },
    "unintendedUse": false
  },
  {
    "@context": [
      "http://localhost:3000/api/schemas/v1/core/context.jsonld",
      "http://localhost:3001/api/schemas/v1/oecd/context.jsonld"
    ],
    "@type": "oecd:Incident",
    "@id": "https://oecd.ai/incident/OECD-2019-082",
    "incident_id": "OECD-2019-082",
    "title": "Employee Monitoring AI Incorrectly Flags Remote Workers as Unproductive",
    "description": "An AI-powered employee productivity monitoring system incorrectly categorized focused work activities as idle time, leading to unfair performance reviews and terminations. The system failed to understand different working styles and break patterns.",
    "date": "2019-10-30",
    "aiSystem": {
      "@type": "oecd:AISystem",
      "name": "Workplace AI Platform Pro",
      "version": "7.18.81",
      "relation": [
        "oecd:DirectCause",
        "oecd:ContributingFactor"
      ]
    },
    "developer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/Boeing",
      "name": "Boeing"
    },
    "deployer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/United_States_Government",
      "name": "United States Government"
    },
    "severity": "oecd:SeriousIncident",
    "harmType": [
      "oecd:EconomicHarm",
      "oecd:PsychologicalHarm",
      "oecd:ReputationalHarm"
    ],
    "harmQuantification": {
      "@type": "oecd:HarmQuantification",
      "affected_stakeholders": "10137 individuals",
      "economic_losses": "$19.9 million",
      "psychological_impact": "Documented stress and anxiety in affected population"
    },
    "countries": [
      {
        "@type": "core:Country",
        "@id": "https://www.wikidata.org/wiki/France",
        "name": "France"
      },
      {
        "@type": "core:Country",
        "@id": "https://www.wikidata.org/wiki/Australia",
        "name": "Australia"
      }
    ],
    "affectedStakeholders": [
      {
        "@type": "oecd:StakeholderGroup",
        "@id": "https://example.org/stakeholder-group/patients",
        "name": "Patients"
      }
    ],
    "businessFunction": [
      "oecd:HRManagement",
      "oecd:QualityControl"
    ],
    "submitter": {
      "@type": "oecd:Submitter",
      "@id": "https://example.org/submitter/reporter",
      "role": "Consumer Advocate",
      "affiliation": "University Ethics Lab",
      "stakeholderGroup": "I represent a government or regulatory body",
      "relationToIncident": "None of the above, but have partial or substantial knowledge of the incident (e.g. first-hand knowledge, research etc.)"
    },
    "unintendedUse": false
  },
  {
    "@context": [
      "http://localhost:3000/api/schemas/v1/core/context.jsonld",
      "http://localhost:3001/api/schemas/v1/oecd/context.jsonld"
    ],
    "@type": "oecd:Incident",
    "@id": "https://oecd.ai/incident/OECD-2019-083",
    "incident_id": "OECD-2019-083",
    "title": "AI Personal Assistant Shares Private Information in Group Settings",
    "description": "A voice-activated AI assistant failed to recognize multi-user environments and shared personal calendar entries, medical reminders, and financial information when responding to queries in group settings.",
    "date": "2019-11-06",
    "aiSystem": {
      "@type": "oecd:AISystem",
      "name": "Consumer AI Solution Pro",
      "version": "1.15.54",
      "relation": [
        "oecd:DirectCause",
        "oecd:FailureToAct"
      ]
    },
    "developer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/Volkswagen",
      "name": "Volkswagen"
    },
    "deployer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/Various_organizations",
      "name": "Various organizations"
    },
    "severity": "oecd:SeriousIncident",
    "harmType": [
      "oecd:ReputationalHarm",
      "oecd:HumanRightsHarm"
    ],
    "harmQuantification": {
      "@type": "oecd:HarmQuantification",
      "affected_stakeholders": "5905 customers",
      "economic_losses": "$19.6 million"
    },
    "countries": [
      {
        "@type": "core:Country",
        "@id": "https://www.wikidata.org/wiki/Italy",
        "name": "Italy"
      }
    ],
    "affectedStakeholders": [
      {
        "@type": "oecd:StakeholderGroup",
        "@id": "https://example.org/stakeholder-group/students",
        "name": "Students"
      }
    ],
    "businessFunction": [
      "oecd:CustomerService",
      "oecd:ICTManagement"
    ],
    "submitter": {
      "@type": "oecd:Submitter",
      "@id": "https://example.org/submitter/reporter",
      "role": "Safety Engineer",
      "affiliation": "University Ethics Lab",
      "stakeholderGroup": "I work or am affiliated to a public interest body or NGO",
      "relationToIncident": "None of the above, but have partial or substantial knowledge of the incident (e.g. first-hand knowledge, research etc.)"
    },
    "unintendedUse": true
  },
  {
    "@context": [
      "http://localhost:3000/api/schemas/v1/core/context.jsonld",
      "http://localhost:3001/api/schemas/v1/oecd/context.jsonld"
    ],
    "@type": "oecd:Incident",
    "@id": "https://oecd.ai/incident/OECD-2019-084",
    "incident_id": "OECD-2019-084",
    "title": "Surgical Robot Malfunction During Minimally Invasive Procedure",
    "description": "An AI-assisted surgical robot experienced a control system failure during a procedure, requiring emergency conversion to traditional surgery. The AI's motion planning algorithms failed to account for unexpected tissue resistance.",
    "date": "2019-11-09",
    "aiSystem": {
      "@type": "oecd:AISystem",
      "name": "Medical AI Engine",
      "version": "1.12.50",
      "relation": [
        "oecd:DirectCause",
        "oecd:FailureToAct"
      ]
    },
    "developer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/St_George's_Hospital_Medical_School",
      "name": "St George's Hospital Medical School"
    },
    "deployer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/Northpointe",
      "name": "Northpointe"
    },
    "severity": "oecd:SeriousIncident",
    "harmType": [
      "oecd:PhysicalHarm"
    ],
    "harmQuantification": {
      "@type": "oecd:HarmQuantification",
      "affected_stakeholders": "25977 individuals"
    },
    "countries": [
      {
        "@type": "core:Country",
        "@id": "https://www.wikidata.org/wiki/Brazil",
        "name": "Brazil"
      },
      {
        "@type": "core:Country",
        "@id": "https://www.wikidata.org/wiki/France",
        "name": "France"
      }
    ],
    "affectedStakeholders": [
      {
        "@type": "core:Person",
        "@id": "https://example.org/entities/person/medical-residents",
        "name": "Medical Residents"
      }
    ],
    "businessFunction": [
      "oecd:OtherFunction"
    ],
    "submitter": {
      "@type": "oecd:Submitter",
      "@id": "https://example.org/submitter/reporter",
      "role": "Academic Researcher",
      "affiliation": "University Ethics Lab",
      "stakeholderGroup": "I work or am affiliated to a public interest body or NGO",
      "relationToIncident": "None of the above, but have partial or substantial knowledge of the incident (e.g. first-hand knowledge, research etc.)"
    },
    "unintendedUse": false
  },
  {
    "@context": [
      "http://localhost:3000/api/schemas/v1/core/context.jsonld",
      "http://localhost:3001/api/schemas/v1/oecd/context.jsonld"
    ],
    "@type": "oecd:Incident",
    "@id": "https://oecd.ai/incident/OECD-2019-085",
    "incident_id": "OECD-2019-085",
    "title": "AI Interview System Shows Bias Against Non-Native Speakers",
    "description": "An automated video interview analysis system consistently gave lower scores to qualified candidates with accents or non-native speech patterns. The AI's speech recognition and sentiment analysis components showed significant bias.",
    "date": "2019-11-20",
    "aiSystem": {
      "@type": "oecd:AISystem",
      "name": "Workplace AI System Pro",
      "version": "1.2.15",
      "relation": [
        "oecd:DirectCause",
        "oecd:FailureToAct"
      ]
    },
    "developer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/USC_Information_Sciences_Institute",
      "name": "USC Information Sciences Institute"
    },
    "deployer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/Starbucks",
      "name": "Starbucks"
    },
    "severity": "oecd:SeriousIncident",
    "harmType": [
      "oecd:EconomicHarm",
      "oecd:HumanRightsHarm"
    ],
    "harmQuantification": {
      "@type": "oecd:HarmQuantification",
      "affected_stakeholders": "18857 patients"
    },
    "countries": [
      {
        "@type": "core:Country",
        "@id": "https://www.wikidata.org/wiki/Japan",
        "name": "Japan"
      },
      {
        "@type": "core:Country",
        "@id": "https://www.wikidata.org/wiki/Italy",
        "name": "Italy"
      }
    ],
    "affectedStakeholders": [
      {
        "@type": "oecd:StakeholderGroup",
        "@id": "https://example.org/stakeholder-group/patients",
        "name": "Patients"
      }
    ],
    "businessFunction": [
      "oecd:HRManagement"
    ],
    "submitter": {
      "@type": "oecd:Submitter",
      "@id": "https://example.org/submitter/reporter",
      "role": "Government Auditor",
      "affiliation": "Digital Rights Organization",
      "stakeholderGroup": "None of the above, but have partial or substantial knowledge of the incident",
      "relationToIncident": "None of the above, but have partial or substantial knowledge of the incident (e.g. first-hand knowledge, research etc.)"
    },
    "unintendedUse": true
  },
  {
    "@context": [
      "http://localhost:3000/api/schemas/v1/core/context.jsonld",
      "http://localhost:3001/api/schemas/v1/oecd/context.jsonld"
    ],
    "@type": "oecd:Incident",
    "@id": "https://oecd.ai/incident/OECD-2019-086",
    "incident_id": "OECD-2019-086",
    "title": "AI Diagnostic System Misses Critical Symptoms in Emergency Department",
    "description": "An AI triage system in emergency departments failed to identify critical symptoms in patients presenting with atypical manifestations of serious conditions. The system's training data lacked diversity in symptom presentations across different demographics.",
    "date": "2019-12-21",
    "aiSystem": {
      "@type": "oecd:AISystem",
      "name": "Medical AI Engine",
      "version": "6.14.69",
      "relation": [
        "oecd:ContributingFactor",
        "oecd:HumanError"
      ]
    },
    "developer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/Volkswagen",
      "name": "Volkswagen"
    },
    "deployer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/New_Zealand",
      "name": "New Zealand"
    },
    "severity": "oecd:SeriousHazard",
    "harmType": [
      "oecd:PhysicalHarm",
      "oecd:HumanRightsHarm"
    ],
    "harmQuantification": {
      "@type": "oecd:HarmQuantification",
      "affected_stakeholders": "19831 individuals"
    },
    "countries": [
      {
        "@type": "core:Country",
        "@id": "https://www.wikidata.org/wiki/Spain",
        "name": "Spain"
      },
      {
        "@type": "core:Country",
        "@id": "https://www.wikidata.org/wiki/Australia",
        "name": "Australia"
      }
    ],
    "affectedStakeholders": [
      {
        "@type": "core:Person",
        "@id": "https://example.org/entities/person/airplane-passengers",
        "name": "Airplane Passengers"
      },
      {
        "@type": "core:Person",
        "@id": "https://example.org/entities/person/pedestrians",
        "name": "Pedestrians"
      },
      {
        "@type": "oecd:StakeholderGroup",
        "@id": "https://example.org/stakeholder-group/minority-groups",
        "name": "Minority Groups"
      }
    ],
    "businessFunction": [
      "oecd:OtherFunction"
    ],
    "submitter": {
      "@type": "oecd:Submitter",
      "@id": "https://example.org/submitter/reporter",
      "role": "Safety Engineer",
      "affiliation": "Digital Rights Organization",
      "stakeholderGroup": "I work or am affiliated to a public interest body or NGO",
      "relationToIncident": "None of the above, but have partial or substantial knowledge of the incident (e.g. first-hand knowledge, research etc.)"
    },
    "unintendedUse": false
  },
  {
    "@context": [
      "http://localhost:3000/api/schemas/v1/core/context.jsonld",
      "http://localhost:3001/api/schemas/v1/oecd/context.jsonld"
    ],
    "@type": "oecd:Incident",
    "@id": "https://oecd.ai/incident/OECD-2019-087",
    "incident_id": "OECD-2019-087",
    "title": "AI Personal Assistant Shares Private Information in Group Settings",
    "description": "A voice-activated AI assistant failed to recognize multi-user environments and shared personal calendar entries, medical reminders, and financial information when responding to queries in group settings.",
    "date": "2019-12-21",
    "aiSystem": {
      "@type": "oecd:AISystem",
      "name": "Consumer AI Solution Pro",
      "version": "10.7.36",
      "relation": [
        "oecd:DirectCause",
        "oecd:ContributingFactor"
      ]
    },
    "developer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/YouTube",
      "name": "YouTube"
    },
    "deployer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/Hospitals",
      "name": "Hospitals"
    },
    "severity": "oecd:SeriousIncident",
    "harmType": [
      "oecd:ReputationalHarm",
      "oecd:HumanRightsHarm"
    ],
    "harmQuantification": {
      "@type": "oecd:HarmQuantification",
      "affected_stakeholders": "34247 workers",
      "economic_losses": "$13.5 million"
    },
    "countries": [
      {
        "@type": "core:Country",
        "@id": "https://www.wikidata.org/wiki/Brazil",
        "name": "Brazil"
      }
    ],
    "affectedStakeholders": [
      {
        "@type": "oecd:StakeholderGroup",
        "@id": "https://example.org/stakeholder-group/children",
        "name": "Children"
      },
      {
        "@type": "core:Person",
        "@id": "https://example.org/entities/person/medical-residents",
        "name": "Medical Residents"
      }
    ],
    "businessFunction": [
      "oecd:CustomerService",
      "oecd:ICTManagement"
    ],
    "submitter": {
      "@type": "oecd:Submitter",
      "@id": "https://example.org/submitter/reporter",
      "role": "Industry Whistleblower",
      "affiliation": "Tech Accountability Project",
      "stakeholderGroup": "None of the above, but have partial or substantial knowledge of the incident",
      "relationToIncident": "None of the above, but have partial or substantial knowledge of the incident (e.g. first-hand knowledge, research etc.)"
    },
    "unintendedUse": false
  },
  {
    "@context": [
      "http://localhost:3000/api/schemas/v1/core/context.jsonld",
      "http://localhost:3001/api/schemas/v1/oecd/context.jsonld"
    ],
    "@type": "oecd:Incident",
    "@id": "https://oecd.ai/incident/OECD-2019-088",
    "incident_id": "OECD-2019-088",
    "title": "Delivery Robot Swarm Blocks Emergency Vehicle Access",
    "description": "A fleet of autonomous delivery robots failed to coordinate their movements during an emergency, blocking paramedic access to a medical emergency. The swarm intelligence system lacked proper emergency vehicle detection and response protocols.",
    "date": "2019-12-26",
    "aiSystem": {
      "@type": "oecd:AISystem",
      "name": "Autonomous Systems Engine",
      "version": "4.6.28",
      "relation": [
        "oecd:DirectCause",
        "oecd:FailureToAct"
      ]
    },
    "developer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/Northpointe",
      "name": "Northpointe"
    },
    "deployer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/Volkswagen",
      "name": "Volkswagen"
    },
    "severity": "oecd:SeriousHazard",
    "harmType": [
      "oecd:PhysicalHarm",
      "oecd:PublicInterestHarm"
    ],
    "harmQuantification": {
      "@type": "oecd:HarmQuantification",
      "affected_stakeholders": "95542 users",
      "economic_losses": "$39.6 million"
    },
    "countries": [
      {
        "@type": "core:Country",
        "@id": "https://www.wikidata.org/wiki/Netherlands",
        "name": "Netherlands"
      }
    ],
    "affectedStakeholders": [
      {
        "@type": "core:Person",
        "@id": "https://example.org/entities/person/motorists",
        "name": "Motorists"
      },
      {
        "@type": "core:Person",
        "@id": "https://example.org/entities/person/medical-residents",
        "name": "Medical Residents"
      },
      {
        "@type": "oecd:StakeholderGroup",
        "@id": "https://example.org/stakeholder-group/children",
        "name": "Children"
      }
    ],
    "businessFunction": [
      "oecd:Logistics",
      "oecd:OtherFunction"
    ],
    "submitter": {
      "@type": "oecd:Submitter",
      "@id": "https://example.org/submitter/reporter",
      "role": "Consumer Advocate",
      "affiliation": "AI Safety Coalition",
      "stakeholderGroup": "None of the above, but have partial or substantial knowledge of the incident",
      "relationToIncident": "None of the above, but have partial or substantial knowledge of the incident (e.g. first-hand knowledge, research etc.)"
    },
    "unintendedUse": false
  },
  {
    "@context": [
      "http://localhost:3000/api/schemas/v1/core/context.jsonld",
      "http://localhost:3001/api/schemas/v1/oecd/context.jsonld"
    ],
    "@type": "oecd:Incident",
    "@id": "https://oecd.ai/incident/OECD-2020-089",
    "incident_id": "OECD-2020-089",
    "title": "AI Interview System Shows Bias Against Non-Native Speakers",
    "description": "An automated video interview analysis system consistently gave lower scores to qualified candidates with accents or non-native speech patterns. The AI's speech recognition and sentiment analysis components showed significant bias.",
    "date": "2020-01-20",
    "aiSystem": {
      "@type": "oecd:AISystem",
      "name": "Workplace AI Engine Pro",
      "version": "2.11.76",
      "relation": [
        "oecd:DirectCause",
        "oecd:ContributingFactor"
      ]
    },
    "developer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/Doctors",
      "name": "Doctors"
    },
    "deployer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/New_York_city_Dept._of_Education",
      "name": "New York city Dept. of Education"
    },
    "severity": "oecd:SeriousIncident",
    "harmType": [
      "oecd:EconomicHarm",
      "oecd:HumanRightsHarm"
    ],
    "harmQuantification": {
      "@type": "oecd:HarmQuantification",
      "affected_stakeholders": "88110 customers",
      "economic_losses": "$6.5 million"
    },
    "countries": [
      {
        "@type": "core:Country",
        "@id": "https://www.wikidata.org/wiki/France",
        "name": "France"
      },
      {
        "@type": "core:Country",
        "@id": "https://www.wikidata.org/wiki/China",
        "name": "China"
      }
    ],
    "affectedStakeholders": [
      {
        "@type": "oecd:StakeholderGroup",
        "@id": "https://example.org/stakeholder-group/minority-groups",
        "name": "Minority Groups"
      },
      {
        "@type": "core:Person",
        "@id": "https://example.org/entities/person/medical-residents",
        "name": "Medical Residents"
      }
    ],
    "businessFunction": [
      "oecd:HRManagement"
    ],
    "submitter": {
      "@type": "oecd:Submitter",
      "@id": "https://example.org/submitter/reporter",
      "role": "Data Scientist",
      "affiliation": "AI Safety Coalition",
      "stakeholderGroup": "None of the above, but have partial or substantial knowledge of the incident",
      "relationToIncident": "None of the above, but have partial or substantial knowledge of the incident (e.g. first-hand knowledge, research etc.)"
    },
    "unintendedUse": false
  },
  {
    "@context": [
      "http://localhost:3000/api/schemas/v1/core/context.jsonld",
      "http://localhost:3001/api/schemas/v1/oecd/context.jsonld"
    ],
    "@type": "oecd:Incident",
    "@id": "https://oecd.ai/incident/OECD-2020-090",
    "incident_id": "OECD-2020-090",
    "title": "AI System Failure Related to AI translation is jeopardizing Afghan asylum claims",
    "description": "An AI system failure occurred with similar characteristics to the documented incident involving US Citizenship and Immigration Services. The system exhibited comparable failure modes resulting in harm to affected stakeholders.",
    "date": "2020-02-16",
    "aiSystem": {
      "@type": "oecd:AISystem",
      "name": "Intelligent Solution",
      "version": "3.0",
      "relation": [
        "oecd:DirectCause"
      ]
    },
    "developer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/US_Citizenship_and_Immigration_Services",
      "name": "US Citizenship and Immigration Services"
    },
    "deployer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/US_Citizenship_and_Immigration_Services",
      "name": "US Citizenship and Immigration Services"
    },
    "severity": "oecd:SeriousIncident",
    "harmType": [
      "oecd:OtherHarm"
    ],
    "harmQuantification": {
      "@type": "oecd:HarmQuantification",
      "affected_stakeholders": "17196 individuals"
    },
    "countries": [
      {
        "@type": "core:Country",
        "@id": "https://www.wikidata.org/wiki/Mexico",
        "name": "Mexico"
      }
    ],
    "affectedStakeholders": [
      {
        "@type": "core:Person",
        "@id": "https://example.org/entities/person/pashto-speaking-asylum-seekers",
        "name": "Pashto-speaking asylum seekers"
      },
      {
        "@type": "core:Person",
        "@id": "https://example.org/entities/person/dari-speaking-asylum-seekers",
        "name": "Dari-speaking asylum seekers"
      },
      {
        "@type": "core:Person",
        "@id": "https://example.org/entities/person/anonymous-pashto-speaking-refugee",
        "name": "anonymous Pashto-speaking refugee"
      }
    ],
    "businessFunction": [
      "oecd:QualityControl",
      "oecd:Compliance"
    ],
    "submitter": {
      "@type": "oecd:Submitter",
      "@id": "https://example.org/submitter/submitter",
      "role": "Government Inspector",
      "affiliation": "AI Safety Institute",
      "stakeholderGroup": "I represent a government or regulatory body",
      "relationToIncident": "I am an affected stakeholder"
    },
    "unintendedUse": false,
    "sameAs": "https://incidentdatabase.ai/cite/532"
  },
  {
    "@context": [
      "http://localhost:3000/api/schemas/v1/core/context.jsonld",
      "http://localhost:3001/api/schemas/v1/oecd/context.jsonld"
    ],
    "@type": "oecd:Incident",
    "@id": "https://oecd.ai/incident/OECD-2020-091",
    "incident_id": "OECD-2020-091",
    "title": "Predictive Policing Algorithm Creates Feedback Loops in Minority Neighborhoods",
    "description": "An AI system for predicting crime hotspots consistently directed more police presence to minority neighborhoods, creating a self-reinforcing cycle where increased police presence led to more reported incidents, further biasing the algorithm.",
    "date": "2020-02-18",
    "aiSystem": {
      "@type": "oecd:AISystem",
      "name": "Security/Surveillance Engine Pro",
      "version": "8.19.6",
      "relation": [
        "oecd:DirectCause",
        "oecd:FailureToAct"
      ]
    },
    "developer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/Tesla,_Inc.",
      "name": "Tesla"
    },
    "deployer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/Apple_Inc.",
      "name": "Apple"
    },
    "severity": "oecd:SeriousHazard",
    "harmType": [
      "oecd:HumanRightsHarm",
      "oecd:PsychologicalHarm"
    ],
    "harmQuantification": {
      "@type": "oecd:HarmQuantification",
      "affected_stakeholders": "79586 individuals",
      "economic_losses": "$28.0 million",
      "psychological_impact": "Documented stress and anxiety in affected population"
    },
    "countries": [
      {
        "@type": "core:Country",
        "@id": "https://www.wikidata.org/wiki/India",
        "name": "India"
      },
      {
        "@type": "core:Country",
        "@id": "https://www.wikidata.org/wiki/Sweden",
        "name": "Sweden"
      }
    ],
    "affectedStakeholders": [
      {
        "@type": "oecd:StakeholderGroup",
        "@id": "https://example.org/stakeholder-group/workers",
        "name": "Workers"
      },
      {
        "@type": "core:Person",
        "@id": "https://example.org/entities/person/pedestrians",
        "name": "Pedestrians"
      }
    ],
    "businessFunction": [
      "oecd:Compliance",
      "oecd:Planning"
    ],
    "submitter": {
      "@type": "oecd:Submitter",
      "@id": "https://example.org/submitter/reporter",
      "role": "Academic Researcher",
      "affiliation": "Consumer Protection Agency",
      "stakeholderGroup": "None of the above, but have partial or substantial knowledge of the incident",
      "relationToIncident": "None of the above, but have partial or substantial knowledge of the incident (e.g. first-hand knowledge, research etc.)"
    },
    "unintendedUse": false
  },
  {
    "@context": [
      "http://localhost:3000/api/schemas/v1/core/context.jsonld",
      "http://localhost:3001/api/schemas/v1/oecd/context.jsonld"
    ],
    "@type": "oecd:Incident",
    "@id": "https://oecd.ai/incident/OECD-2020-092",
    "incident_id": "OECD-2020-092",
    "title": "Agricultural AI Misidentifies Crops Leading to Herbicide Damage",
    "description": "An AI-powered crop monitoring and treatment system misidentified valuable crops as weeds, resulting in herbicide application that destroyed thousands of acres of produce. The computer vision model was not properly validated for the specific crop varieties.",
    "date": "2020-02-20",
    "aiSystem": {
      "@type": "oecd:AISystem",
      "name": "Autonomous Systems Engine",
      "version": "1.18.2",
      "relation": [
        "oecd:DirectCause",
        "oecd:FailureToAct"
      ]
    },
    "developer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/Amazon_(company)",
      "name": "Amazon"
    },
    "deployer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/Tesla,_Inc.",
      "name": "Tesla"
    },
    "severity": "oecd:SeriousIncident",
    "harmType": [
      "oecd:EconomicHarm",
      "oecd:EnvironmentalHarm"
    ],
    "harmQuantification": {
      "@type": "oecd:HarmQuantification",
      "affected_stakeholders": "72261 workers",
      "economic_losses": "$47.9 million"
    },
    "countries": [
      {
        "@type": "core:Country",
        "@id": "https://www.wikidata.org/wiki/United_States",
        "name": "United States"
      },
      {
        "@type": "core:Country",
        "@id": "https://www.wikidata.org/wiki/Sweden",
        "name": "Sweden"
      }
    ],
    "affectedStakeholders": [
      {
        "@type": "oecd:StakeholderGroup",
        "@id": "https://example.org/stakeholder-group/patients",
        "name": "Patients"
      },
      {
        "@type": "core:Person",
        "@id": "https://example.org/entities/person/pedestrians",
        "name": "Pedestrians"
      },
      {
        "@type": "core:Person",
        "@id": "https://example.org/entities/person/airplane-passengers",
        "name": "Airplane Passengers"
      }
    ],
    "businessFunction": [
      "oecd:Production",
      "oecd:OtherFunction"
    ],
    "submitter": {
      "@type": "oecd:Submitter",
      "@id": "https://example.org/submitter/reporter",
      "role": "Industry Whistleblower",
      "affiliation": "Digital Rights Organization",
      "stakeholderGroup": "None of the above, but have partial or substantial knowledge of the incident",
      "relationToIncident": "None of the above, but have partial or substantial knowledge of the incident (e.g. first-hand knowledge, research etc.)"
    },
    "unintendedUse": true
  },
  {
    "@context": [
      "http://localhost:3000/api/schemas/v1/core/context.jsonld",
      "http://localhost:3001/api/schemas/v1/oecd/context.jsonld"
    ],
    "@type": "oecd:Incident",
    "@id": "https://oecd.ai/incident/OECD-2020-093",
    "incident_id": "OECD-2020-093",
    "title": "Agricultural AI Misidentifies Crops Leading to Herbicide Damage",
    "description": "An AI-powered crop monitoring and treatment system misidentified valuable crops as weeds, resulting in herbicide application that destroyed thousands of acres of produce. The computer vision model was not properly validated for the specific crop varieties.",
    "date": "2020-02-22",
    "aiSystem": {
      "@type": "oecd:AISystem",
      "name": "Autonomous Systems System",
      "version": "8.4.33",
      "relation": [
        "oecd:DirectCause"
      ]
    },
    "developer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/Apple_Inc.",
      "name": "Apple"
    },
    "deployer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/Apple_Inc.",
      "name": "Apple"
    },
    "severity": "oecd:SeriousIncident",
    "harmType": [
      "oecd:EconomicHarm",
      "oecd:EnvironmentalHarm"
    ],
    "harmQuantification": {
      "@type": "oecd:HarmQuantification",
      "affected_stakeholders": "63027 customers",
      "economic_losses": "$2.9 million"
    },
    "countries": [
      {
        "@type": "core:Country",
        "@id": "https://www.wikidata.org/wiki/Singapore",
        "name": "Singapore"
      }
    ],
    "affectedStakeholders": [
      {
        "@type": "oecd:StakeholderGroup",
        "@id": "https://example.org/stakeholder-group/minority-groups",
        "name": "Minority Groups"
      }
    ],
    "businessFunction": [
      "oecd:Production",
      "oecd:OtherFunction"
    ],
    "submitter": {
      "@type": "oecd:Submitter",
      "@id": "https://example.org/submitter/reporter",
      "role": "Safety Engineer",
      "affiliation": "Tech Accountability Project",
      "stakeholderGroup": "I represent a government or regulatory body",
      "relationToIncident": "None of the above, but have partial or substantial knowledge of the incident (e.g. first-hand knowledge, research etc.)"
    },
    "unintendedUse": false
  },
  {
    "@context": [
      "http://localhost:3000/api/schemas/v1/core/context.jsonld",
      "http://localhost:3001/api/schemas/v1/oecd/context.jsonld"
    ],
    "@type": "oecd:Incident",
    "@id": "https://oecd.ai/incident/OECD-2020-094",
    "incident_id": "OECD-2020-094",
    "title": "AI Interview System Shows Bias Against Non-Native Speakers",
    "description": "An automated video interview analysis system consistently gave lower scores to qualified candidates with accents or non-native speech patterns. The AI's speech recognition and sentiment analysis components showed significant bias.",
    "date": "2020-02-28",
    "aiSystem": {
      "@type": "oecd:AISystem",
      "name": "Workplace AI Platform Pro",
      "version": "1.5.47",
      "relation": [
        "oecd:DirectCause"
      ]
    },
    "developer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/Apple_Inc.",
      "name": "Apple"
    },
    "deployer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/New_York_city_Dept._of_Education",
      "name": "New York city Dept. of Education"
    },
    "severity": "oecd:SeriousIncident",
    "harmType": [
      "oecd:EconomicHarm",
      "oecd:HumanRightsHarm"
    ],
    "harmQuantification": {
      "@type": "oecd:HarmQuantification",
      "affected_stakeholders": "87988 patients"
    },
    "countries": [
      {
        "@type": "core:Country",
        "@id": "https://www.wikidata.org/wiki/Singapore",
        "name": "Singapore"
      },
      {
        "@type": "core:Country",
        "@id": "https://www.wikidata.org/wiki/India",
        "name": "India"
      }
    ],
    "affectedStakeholders": [
      {
        "@type": "oecd:StakeholderGroup",
        "@id": "https://example.org/stakeholder-group/women",
        "name": "Women"
      },
      {
        "@type": "core:Person",
        "@id": "https://example.org/entities/person/pedestrians",
        "name": "Pedestrians"
      }
    ],
    "businessFunction": [
      "oecd:HRManagement"
    ],
    "submitter": {
      "@type": "oecd:Submitter",
      "@id": "https://example.org/submitter/reporter",
      "role": "Government Auditor",
      "affiliation": "Consumer Protection Agency",
      "stakeholderGroup": "I work or am affiliated to a public interest body or NGO",
      "relationToIncident": "None of the above, but have partial or substantial knowledge of the incident (e.g. first-hand knowledge, research etc.)"
    },
    "unintendedUse": false
  },
  {
    "@context": [
      "http://localhost:3000/api/schemas/v1/core/context.jsonld",
      "http://localhost:3001/api/schemas/v1/oecd/context.jsonld"
    ],
    "@type": "oecd:Incident",
    "@id": "https://oecd.ai/incident/OECD-2020-095",
    "incident_id": "OECD-2020-095",
    "title": "AI System Failure Related to Networking Platform Giggle Employs AI to Determine Users’ Gender, Allegedly Excluding Transgender Women",
    "description": "An AI system failure occurred with similar characteristics to the documented incident involving Giggle. The system exhibited comparable failure modes resulting in harm to affected stakeholders.",
    "date": "2020-03-27",
    "aiSystem": {
      "@type": "oecd:AISystem",
      "name": "Smart Solution",
      "version": "3.9",
      "relation": [
        "oecd:DirectCause"
      ]
    },
    "developer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/Giggle",
      "name": "Giggle"
    },
    "deployer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/Giggle",
      "name": "Giggle"
    },
    "severity": "oecd:SeriousIncident",
    "harmType": [
      "oecd:OtherHarm"
    ],
    "harmQuantification": {
      "@type": "oecd:HarmQuantification",
      "affected_stakeholders": "36706 individuals",
      "economic_losses": "$10 million"
    },
    "countries": [
      {
        "@type": "core:Country",
        "@id": "https://www.wikidata.org/wiki/Netherlands",
        "name": "Netherlands"
      }
    ],
    "affectedStakeholders": [
      {
        "@type": "oecd:StakeholderGroup",
        "@id": "https://example.org/stakeholder-group/women-of-color",
        "name": "women of color"
      },
      {
        "@type": "oecd:StakeholderGroup",
        "@id": "https://example.org/stakeholder-group/trans-women",
        "name": "trans women"
      }
    ],
    "businessFunction": [
      "oecd:Marketing",
      "oecd:ICTManagement"
    ],
    "submitter": {
      "@type": "oecd:Submitter",
      "@id": "https://example.org/submitter/submitter",
      "role": "AI Safety Researcher",
      "affiliation": "Government Oversight Committee",
      "stakeholderGroup": "I represent a government or regulatory body",
      "relationToIncident": "None of the above, but have partial or substantial knowledge of the incident (e.g. first-hand knowledge, research etc.)"
    },
    "unintendedUse": true,
    "sameAs": "https://incidentdatabase.ai/cite/166"
  },
  {
    "@context": [
      "http://localhost:3000/api/schemas/v1/core/context.jsonld",
      "http://localhost:3001/api/schemas/v1/oecd/context.jsonld"
    ],
    "@type": "oecd:Incident",
    "@id": "https://oecd.ai/incident/OECD-2020-096",
    "incident_id": "OECD-2020-096",
    "title": "Agricultural AI Misidentifies Crops Leading to Herbicide Damage",
    "description": "An AI-powered crop monitoring and treatment system misidentified valuable crops as weeds, resulting in herbicide application that destroyed thousands of acres of produce. The computer vision model was not properly validated for the specific crop varieties.",
    "date": "2020-03-27",
    "aiSystem": {
      "@type": "oecd:AISystem",
      "name": "Autonomous Systems System",
      "version": "8.17.92",
      "relation": [
        "oecd:DirectCause"
      ]
    },
    "developer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/Apple_Inc.",
      "name": "Apple"
    },
    "deployer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/Boeing",
      "name": "Boeing"
    },
    "severity": "oecd:SeriousIncident",
    "harmType": [
      "oecd:EconomicHarm",
      "oecd:EnvironmentalHarm"
    ],
    "harmQuantification": {
      "@type": "oecd:HarmQuantification",
      "affected_stakeholders": "87468 workers",
      "economic_losses": "$43.2 million"
    },
    "countries": [
      {
        "@type": "core:Country",
        "@id": "https://www.wikidata.org/wiki/Spain",
        "name": "Spain"
      }
    ],
    "affectedStakeholders": [
      {
        "@type": "oecd:StakeholderGroup",
        "@id": "https://example.org/stakeholder-group/students",
        "name": "Students"
      },
      {
        "@type": "oecd:StakeholderGroup",
        "@id": "https://example.org/stakeholder-group/women",
        "name": "Women"
      }
    ],
    "businessFunction": [
      "oecd:Production",
      "oecd:OtherFunction"
    ],
    "submitter": {
      "@type": "oecd:Submitter",
      "@id": "https://example.org/submitter/reporter",
      "role": "Consumer Advocate",
      "affiliation": "Consumer Protection Agency",
      "stakeholderGroup": "I represent a government or regulatory body",
      "relationToIncident": "None of the above, but have partial or substantial knowledge of the incident (e.g. first-hand knowledge, research etc.)"
    },
    "unintendedUse": false
  },
  {
    "@context": [
      "http://localhost:3000/api/schemas/v1/core/context.jsonld",
      "http://localhost:3001/api/schemas/v1/oecd/context.jsonld"
    ],
    "@type": "oecd:Incident",
    "@id": "https://oecd.ai/incident/OECD-2020-097",
    "incident_id": "OECD-2020-097",
    "title": "Predictive Policing Algorithm Creates Feedback Loops in Minority Neighborhoods",
    "description": "An AI system for predicting crime hotspots consistently directed more police presence to minority neighborhoods, creating a self-reinforcing cycle where increased police presence led to more reported incidents, further biasing the algorithm.",
    "date": "2020-04-02",
    "aiSystem": {
      "@type": "oecd:AISystem",
      "name": "Security/Surveillance Platform",
      "version": "9.11.66",
      "relation": [
        "oecd:ContributingFactor"
      ]
    },
    "developer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/Frontier_Development",
      "name": "Frontier Development"
    },
    "deployer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/Delhi_Metro_Rail_Corporation",
      "name": "Delhi Metro Rail Corporation"
    },
    "severity": "oecd:SeriousHazard",
    "harmType": [
      "oecd:HumanRightsHarm",
      "oecd:PsychologicalHarm"
    ],
    "harmQuantification": {
      "@type": "oecd:HarmQuantification",
      "affected_stakeholders": "48882 customers",
      "economic_losses": "$43.4 million",
      "psychological_impact": "Documented stress and anxiety in affected population"
    },
    "countries": [
      {
        "@type": "core:Country",
        "@id": "https://www.wikidata.org/wiki/Australia",
        "name": "Australia"
      }
    ],
    "affectedStakeholders": [
      {
        "@type": "core:Person",
        "@id": "https://example.org/entities/person/bus-passengers",
        "name": "Bus passengers"
      },
      {
        "@type": "oecd:StakeholderGroup",
        "@id": "https://example.org/stakeholder-group/children",
        "name": "Children"
      }
    ],
    "businessFunction": [
      "oecd:Compliance",
      "oecd:Planning"
    ],
    "submitter": {
      "@type": "oecd:Submitter",
      "@id": "https://example.org/submitter/reporter",
      "role": "Industry Whistleblower",
      "affiliation": "Consumer Protection Agency",
      "stakeholderGroup": "I am an affected stakeholder",
      "relationToIncident": "None of the above, but have partial or substantial knowledge of the incident (e.g. first-hand knowledge, research etc.)"
    },
    "unintendedUse": true
  },
  {
    "@context": [
      "http://localhost:3000/api/schemas/v1/core/context.jsonld",
      "http://localhost:3001/api/schemas/v1/oecd/context.jsonld"
    ],
    "@type": "oecd:Incident",
    "@id": "https://oecd.ai/incident/OECD-2020-098",
    "incident_id": "OECD-2020-098",
    "title": "AI Diagnostic System Misses Critical Symptoms in Emergency Department",
    "description": "An AI triage system in emergency departments failed to identify critical symptoms in patients presenting with atypical manifestations of serious conditions. The system's training data lacked diversity in symptom presentations across different demographics.",
    "date": "2020-04-16",
    "aiSystem": {
      "@type": "oecd:AISystem",
      "name": "Medical AI Engine",
      "version": "5.13.68",
      "relation": [
        "oecd:ContributingFactor",
        "oecd:HumanError"
      ]
    },
    "developer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/Volkswagen",
      "name": "Volkswagen"
    },
    "deployer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/LinkedIn",
      "name": "LinkedIn"
    },
    "severity": "oecd:SeriousHazard",
    "harmType": [
      "oecd:PhysicalHarm",
      "oecd:HumanRightsHarm"
    ],
    "harmQuantification": {
      "@type": "oecd:HarmQuantification",
      "affected_stakeholders": "45941 users"
    },
    "countries": [
      {
        "@type": "core:Country",
        "@id": "https://www.wikidata.org/wiki/Brazil",
        "name": "Brazil"
      },
      {
        "@type": "core:Country",
        "@id": "https://www.wikidata.org/wiki/France",
        "name": "France"
      }
    ],
    "affectedStakeholders": [
      {
        "@type": "core:Person",
        "@id": "https://example.org/entities/person/medical-residents",
        "name": "Medical Residents"
      },
      {
        "@type": "core:Person",
        "@id": "https://example.org/entities/person/motorists",
        "name": "Motorists"
      },
      {
        "@type": "core:Person",
        "@id": "https://example.org/entities/person/black-people",
        "name": "Black people"
      }
    ],
    "businessFunction": [
      "oecd:OtherFunction"
    ],
    "submitter": {
      "@type": "oecd:Submitter",
      "@id": "https://example.org/submitter/reporter",
      "role": "Industry Whistleblower",
      "affiliation": "Digital Rights Organization",
      "stakeholderGroup": "I am an affected stakeholder",
      "relationToIncident": "None of the above, but have partial or substantial knowledge of the incident (e.g. first-hand knowledge, research etc.)"
    },
    "unintendedUse": false
  },
  {
    "@context": [
      "http://localhost:3000/api/schemas/v1/core/context.jsonld",
      "http://localhost:3001/api/schemas/v1/oecd/context.jsonld"
    ],
    "@type": "oecd:Incident",
    "@id": "https://oecd.ai/incident/OECD-2020-099",
    "incident_id": "OECD-2020-099",
    "title": "AI Diagnostic System Misses Critical Symptoms in Emergency Department",
    "description": "An AI triage system in emergency departments failed to identify critical symptoms in patients presenting with atypical manifestations of serious conditions. The system's training data lacked diversity in symptom presentations across different demographics.",
    "date": "2020-05-10",
    "aiSystem": {
      "@type": "oecd:AISystem",
      "name": "Medical AI Solution Pro",
      "version": "7.11.53",
      "relation": [
        "oecd:DirectCause",
        "oecd:ContributingFactor"
      ]
    },
    "developer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/Apple_Inc.",
      "name": "Apple"
    },
    "deployer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/Uber",
      "name": "Uber"
    },
    "severity": "oecd:SeriousHazard",
    "harmType": [
      "oecd:PhysicalHarm",
      "oecd:HumanRightsHarm"
    ],
    "harmQuantification": {
      "@type": "oecd:HarmQuantification",
      "affected_stakeholders": "3239 individuals"
    },
    "countries": [
      {
        "@type": "core:Country",
        "@id": "https://www.wikidata.org/wiki/Brazil",
        "name": "Brazil"
      }
    ],
    "affectedStakeholders": [
      {
        "@type": "core:Person",
        "@id": "https://example.org/entities/person/pedestrians",
        "name": "Pedestrians"
      }
    ],
    "businessFunction": [
      "oecd:OtherFunction"
    ],
    "submitter": {
      "@type": "oecd:Submitter",
      "@id": "https://example.org/submitter/reporter",
      "role": "Data Scientist",
      "affiliation": "Digital Rights Organization",
      "stakeholderGroup": "I am an affected stakeholder",
      "relationToIncident": "None of the above, but have partial or substantial knowledge of the incident (e.g. first-hand knowledge, research etc.)"
    },
    "unintendedUse": false
  },
  {
    "@context": [
      "http://localhost:3000/api/schemas/v1/core/context.jsonld",
      "http://localhost:3001/api/schemas/v1/oecd/context.jsonld"
    ],
    "@type": "oecd:Incident",
    "@id": "https://oecd.ai/incident/OECD-2020-100",
    "incident_id": "OECD-2020-100",
    "title": "Delivery Robot Swarm Blocks Emergency Vehicle Access",
    "description": "A fleet of autonomous delivery robots failed to coordinate their movements during an emergency, blocking paramedic access to a medical emergency. The swarm intelligence system lacked proper emergency vehicle detection and response protocols.",
    "date": "2020-05-22",
    "aiSystem": {
      "@type": "oecd:AISystem",
      "name": "Autonomous Systems System",
      "version": "2.1.36",
      "relation": [
        "oecd:DirectCause"
      ]
    },
    "developer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/University_of_Washington",
      "name": "University of Washington"
    },
    "deployer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/Microsoft",
      "name": "Microsoft"
    },
    "severity": "oecd:SeriousHazard",
    "harmType": [
      "oecd:PhysicalHarm",
      "oecd:PublicInterestHarm"
    ],
    "harmQuantification": {
      "@type": "oecd:HarmQuantification",
      "affected_stakeholders": "40187 individuals",
      "economic_losses": "$41.9 million"
    },
    "countries": [
      {
        "@type": "core:Country",
        "@id": "https://www.wikidata.org/wiki/Israel",
        "name": "Israel"
      }
    ],
    "affectedStakeholders": [
      {
        "@type": "oecd:StakeholderGroup",
        "@id": "https://example.org/stakeholder-group/consumers",
        "name": "Consumers"
      },
      {
        "@type": "oecd:StakeholderGroup",
        "@id": "https://example.org/stakeholder-group/children",
        "name": "Children"
      }
    ],
    "businessFunction": [
      "oecd:Logistics",
      "oecd:OtherFunction"
    ],
    "submitter": {
      "@type": "oecd:Submitter",
      "@id": "https://example.org/submitter/reporter",
      "role": "Consumer Advocate",
      "affiliation": "University Ethics Lab",
      "stakeholderGroup": "None of the above, but have partial or substantial knowledge of the incident",
      "relationToIncident": "None of the above, but have partial or substantial knowledge of the incident (e.g. first-hand knowledge, research etc.)"
    },
    "unintendedUse": false
  },
  {
    "@context": [
      "http://localhost:3000/api/schemas/v1/core/context.jsonld",
      "http://localhost:3001/api/schemas/v1/oecd/context.jsonld"
    ],
    "@type": "oecd:Incident",
    "@id": "https://oecd.ai/incident/OECD-2020-101",
    "incident_id": "OECD-2020-101",
    "title": "Facial Recognition System Falsely Identifies Protesters as Criminals",
    "description": "A law enforcement facial recognition system incorrectly matched peaceful protesters with criminal database entries, leading to wrongful detentions. The AI system showed higher error rates for certain ethnic groups and in crowded scenarios.",
    "date": "2020-05-25",
    "aiSystem": {
      "@type": "oecd:AISystem",
      "name": "Security/Surveillance Platform",
      "version": "9.18.49",
      "relation": [
        "oecd:DirectCause"
      ]
    },
    "developer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/Wikipedia",
      "name": "Wikipedia"
    },
    "deployer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/Google",
      "name": "Google"
    },
    "severity": "oecd:SeriousIncident",
    "harmType": [
      "oecd:PhysicalHarm",
      "oecd:HumanRightsHarm",
      "oecd:ReputationalHarm"
    ],
    "harmQuantification": {
      "@type": "oecd:HarmQuantification",
      "affected_stakeholders": "35916 patients",
      "economic_losses": "$6.9 million"
    },
    "countries": [
      {
        "@type": "core:Country",
        "@id": "https://www.wikidata.org/wiki/India",
        "name": "India"
      }
    ],
    "affectedStakeholders": [
      {
        "@type": "core:Person",
        "@id": "https://example.org/entities/person/pedestrians",
        "name": "Pedestrians"
      },
      {
        "@type": "oecd:StakeholderGroup",
        "@id": "https://example.org/stakeholder-group/children",
        "name": "Children"
      }
    ],
    "businessFunction": [
      "oecd:Compliance"
    ],
    "submitter": {
      "@type": "oecd:Submitter",
      "@id": "https://example.org/submitter/reporter",
      "role": "Safety Engineer",
      "affiliation": "Tech Accountability Project",
      "stakeholderGroup": "I represent a government or regulatory body",
      "relationToIncident": "None of the above, but have partial or substantial knowledge of the incident (e.g. first-hand knowledge, research etc.)"
    },
    "unintendedUse": false
  },
  {
    "@context": [
      "http://localhost:3000/api/schemas/v1/core/context.jsonld",
      "http://localhost:3001/api/schemas/v1/oecd/context.jsonld"
    ],
    "@type": "oecd:Incident",
    "@id": "https://oecd.ai/incident/OECD-2020-102",
    "incident_id": "OECD-2020-102",
    "title": "Surgical Robot Malfunction During Minimally Invasive Procedure",
    "description": "An AI-assisted surgical robot experienced a control system failure during a procedure, requiring emergency conversion to traditional surgery. The AI's motion planning algorithms failed to account for unexpected tissue resistance.",
    "date": "2020-06-15",
    "aiSystem": {
      "@type": "oecd:AISystem",
      "name": "Medical AI System",
      "version": "5.1.46",
      "relation": [
        "oecd:DirectCause"
      ]
    },
    "developer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/Apple_Inc.",
      "name": "Apple"
    },
    "deployer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/Tesla,_Inc.",
      "name": "Tesla"
    },
    "severity": "oecd:SeriousIncident",
    "harmType": [
      "oecd:PhysicalHarm"
    ],
    "harmQuantification": {
      "@type": "oecd:HarmQuantification",
      "affected_stakeholders": "34480 individuals",
      "economic_losses": "$3.2 million"
    },
    "countries": [
      {
        "@type": "core:Country",
        "@id": "https://www.wikidata.org/wiki/France",
        "name": "France"
      }
    ],
    "affectedStakeholders": [
      {
        "@type": "oecd:StakeholderGroup",
        "@id": "https://example.org/stakeholder-group/students",
        "name": "Students"
      },
      {
        "@type": "core:Person",
        "@id": "https://example.org/entities/person/airplane-passengers",
        "name": "Airplane Passengers"
      }
    ],
    "businessFunction": [
      "oecd:OtherFunction"
    ],
    "submitter": {
      "@type": "oecd:Submitter",
      "@id": "https://example.org/submitter/reporter",
      "role": "Safety Engineer",
      "affiliation": "AI Safety Coalition",
      "stakeholderGroup": "None of the above, but have partial or substantial knowledge of the incident",
      "relationToIncident": "None of the above, but have partial or substantial knowledge of the incident (e.g. first-hand knowledge, research etc.)"
    },
    "unintendedUse": false
  },
  {
    "@context": [
      "http://localhost:3000/api/schemas/v1/core/context.jsonld",
      "http://localhost:3001/api/schemas/v1/oecd/context.jsonld"
    ],
    "@type": "oecd:Incident",
    "@id": "https://oecd.ai/incident/OECD-2020-103",
    "incident_id": "OECD-2020-103",
    "title": "AI Diagnostic System Misses Critical Symptoms in Emergency Department",
    "description": "An AI triage system in emergency departments failed to identify critical symptoms in patients presenting with atypical manifestations of serious conditions. The system's training data lacked diversity in symptom presentations across different demographics.",
    "date": "2020-07-05",
    "aiSystem": {
      "@type": "oecd:AISystem",
      "name": "Medical AI Platform Pro",
      "version": "7.14.37",
      "relation": [
        "oecd:DirectCause",
        "oecd:FailureToAct"
      ]
    },
    "developer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/Apple_Inc.",
      "name": "Apple"
    },
    "deployer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/Delhi_Metro_Rail_Corporation",
      "name": "Delhi Metro Rail Corporation"
    },
    "severity": "oecd:SeriousHazard",
    "harmType": [
      "oecd:PhysicalHarm",
      "oecd:HumanRightsHarm"
    ],
    "harmQuantification": {
      "@type": "oecd:HarmQuantification",
      "affected_stakeholders": "48242 patients"
    },
    "countries": [
      {
        "@type": "core:Country",
        "@id": "https://www.wikidata.org/wiki/Netherlands",
        "name": "Netherlands"
      }
    ],
    "affectedStakeholders": [
      {
        "@type": "oecd:StakeholderGroup",
        "@id": "https://example.org/stakeholder-group/workers",
        "name": "Workers"
      }
    ],
    "businessFunction": [
      "oecd:OtherFunction"
    ],
    "submitter": {
      "@type": "oecd:Submitter",
      "@id": "https://example.org/submitter/reporter",
      "role": "Industry Whistleblower",
      "affiliation": "Tech Accountability Project",
      "stakeholderGroup": "I work or am affiliated to a public interest body or NGO",
      "relationToIncident": "None of the above, but have partial or substantial knowledge of the incident (e.g. first-hand knowledge, research etc.)"
    },
    "unintendedUse": false
  },
  {
    "@context": [
      "http://localhost:3000/api/schemas/v1/core/context.jsonld",
      "http://localhost:3001/api/schemas/v1/oecd/context.jsonld"
    ],
    "@type": "oecd:Incident",
    "@id": "https://oecd.ai/incident/OECD-2020-104",
    "incident_id": "OECD-2020-104",
    "title": "AI Credit Scoring System Discriminates Against Recent Immigrants",
    "description": "An automated credit scoring system systematically assigned lower credit scores to recent immigrants despite strong financial indicators. The AI model heavily weighted credit history length, creating unfair barriers to financial services.",
    "date": "2020-07-15",
    "aiSystem": {
      "@type": "oecd:AISystem",
      "name": "Financial AI Engine Pro",
      "version": "9.13.44",
      "relation": [
        "oecd:DirectCause"
      ]
    },
    "developer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/Frontier_Development",
      "name": "Frontier Development"
    },
    "deployer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/Various_organizations",
      "name": "Various organizations"
    },
    "severity": "oecd:SeriousIncident",
    "harmType": [
      "oecd:EconomicHarm",
      "oecd:HumanRightsHarm"
    ],
    "harmQuantification": {
      "@type": "oecd:HarmQuantification",
      "affected_stakeholders": "1310 individuals"
    },
    "countries": [
      {
        "@type": "core:Country",
        "@id": "https://www.wikidata.org/wiki/South_Korea",
        "name": "South Korea"
      },
      {
        "@type": "core:Country",
        "@id": "https://www.wikidata.org/wiki/United_States",
        "name": "United States"
      }
    ],
    "affectedStakeholders": [
      {
        "@type": "oecd:StakeholderGroup",
        "@id": "https://example.org/stakeholder-group/minority-groups",
        "name": "Minority Groups"
      },
      {
        "@type": "core:Person",
        "@id": "https://example.org/entities/person/medical-residents",
        "name": "Medical Residents"
      }
    ],
    "businessFunction": [
      "oecd:OtherFunction"
    ],
    "submitter": {
      "@type": "oecd:Submitter",
      "@id": "https://example.org/submitter/reporter",
      "role": "Data Scientist",
      "affiliation": "Consumer Protection Agency",
      "stakeholderGroup": "I work or am affiliated to a public interest body or NGO",
      "relationToIncident": "None of the above, but have partial or substantial knowledge of the incident (e.g. first-hand knowledge, research etc.)"
    },
    "unintendedUse": false
  },
  {
    "@context": [
      "http://localhost:3000/api/schemas/v1/core/context.jsonld",
      "http://localhost:3001/api/schemas/v1/oecd/context.jsonld"
    ],
    "@type": "oecd:Incident",
    "@id": "https://oecd.ai/incident/OECD-2020-105",
    "incident_id": "OECD-2020-105",
    "title": "AI Interview System Shows Bias Against Non-Native Speakers",
    "description": "An automated video interview analysis system consistently gave lower scores to qualified candidates with accents or non-native speech patterns. The AI's speech recognition and sentiment analysis components showed significant bias.",
    "date": "2020-07-18",
    "aiSystem": {
      "@type": "oecd:AISystem",
      "name": "Workplace AI Engine Pro",
      "version": "9.13.17",
      "relation": [
        "oecd:DirectCause",
        "oecd:FailureToAct"
      ]
    },
    "developer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/Google",
      "name": "Google"
    },
    "deployer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/Google",
      "name": "Google"
    },
    "severity": "oecd:SeriousIncident",
    "harmType": [
      "oecd:EconomicHarm",
      "oecd:HumanRightsHarm"
    ],
    "harmQuantification": {
      "@type": "oecd:HarmQuantification",
      "affected_stakeholders": "64515 workers"
    },
    "countries": [
      {
        "@type": "core:Country",
        "@id": "https://www.wikidata.org/wiki/Norway",
        "name": "Norway"
      },
      {
        "@type": "core:Country",
        "@id": "https://www.wikidata.org/wiki/Sweden",
        "name": "Sweden"
      }
    ],
    "affectedStakeholders": [
      {
        "@type": "core:Person",
        "@id": "https://example.org/entities/person/medical-residents",
        "name": "Medical Residents"
      },
      {
        "@type": "core:Person",
        "@id": "https://example.org/entities/person/bus-passengers",
        "name": "Bus passengers"
      },
      {
        "@type": "oecd:StakeholderGroup",
        "@id": "https://example.org/stakeholder-group/consumers",
        "name": "Consumers"
      }
    ],
    "businessFunction": [
      "oecd:HRManagement"
    ],
    "submitter": {
      "@type": "oecd:Submitter",
      "@id": "https://example.org/submitter/reporter",
      "role": "Government Auditor",
      "affiliation": "AI Safety Coalition",
      "stakeholderGroup": "None of the above, but have partial or substantial knowledge of the incident",
      "relationToIncident": "None of the above, but have partial or substantial knowledge of the incident (e.g. first-hand knowledge, research etc.)"
    },
    "unintendedUse": false
  },
  {
    "@context": [
      "http://localhost:3000/api/schemas/v1/core/context.jsonld",
      "http://localhost:3001/api/schemas/v1/oecd/context.jsonld"
    ],
    "@type": "oecd:Incident",
    "@id": "https://oecd.ai/incident/OECD-2020-106",
    "incident_id": "OECD-2020-106",
    "title": "AI System Failure Related to Networking Platform Giggle Employs AI to Determine Users’ Gender, Allegedly Excluding Transgender Women",
    "description": "An AI system failure occurred with similar characteristics to the documented incident involving Giggle. The system exhibited comparable failure modes resulting in harm to affected stakeholders.",
    "date": "2020-09-27",
    "aiSystem": {
      "@type": "oecd:AISystem",
      "name": "Smart System",
      "version": "1.4",
      "relation": [
        "oecd:DirectCause"
      ]
    },
    "developer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/Giggle",
      "name": "Giggle"
    },
    "deployer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/Giggle",
      "name": "Giggle"
    },
    "severity": "oecd:SeriousIncident",
    "harmType": [
      "oecd:OtherHarm"
    ],
    "harmQuantification": {
      "@type": "oecd:HarmQuantification",
      "affected_stakeholders": "23312 individuals",
      "economic_losses": "$2 million"
    },
    "countries": [
      {
        "@type": "core:Country",
        "@id": "https://www.wikidata.org/wiki/United_States",
        "name": "United States"
      }
    ],
    "affectedStakeholders": [
      {
        "@type": "oecd:StakeholderGroup",
        "@id": "https://example.org/stakeholder-group/women-of-color",
        "name": "women of color"
      },
      {
        "@type": "oecd:StakeholderGroup",
        "@id": "https://example.org/stakeholder-group/trans-women",
        "name": "trans women"
      }
    ],
    "businessFunction": [
      "oecd:Logistics",
      "oecd:Maintenance"
    ],
    "submitter": {
      "@type": "oecd:Submitter",
      "@id": "https://example.org/submitter/submitter",
      "role": "AI Safety Researcher",
      "affiliation": "Digital Rights Foundation",
      "stakeholderGroup": "I represent a government or regulatory body",
      "relationToIncident": "I am a user of the related AI system"
    },
    "unintendedUse": true,
    "sameAs": "https://incidentdatabase.ai/cite/166"
  },
  {
    "@context": [
      "http://localhost:3000/api/schemas/v1/core/context.jsonld",
      "http://localhost:3001/api/schemas/v1/oecd/context.jsonld"
    ],
    "@type": "oecd:Incident",
    "@id": "https://oecd.ai/incident/OECD-2020-107",
    "incident_id": "OECD-2020-107",
    "title": "AI System Failure Related to Networking Platform Giggle Employs AI to Determine Users’ Gender, Allegedly Excluding Transgender Women",
    "description": "An AI system failure occurred with similar characteristics to the documented incident involving Giggle. The system exhibited comparable failure modes resulting in harm to affected stakeholders.",
    "date": "2020-10-04",
    "aiSystem": {
      "@type": "oecd:AISystem",
      "name": "Intelligent System",
      "version": "2.4",
      "relation": [
        "oecd:DirectCause"
      ]
    },
    "developer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/Giggle",
      "name": "Giggle"
    },
    "deployer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/Giggle",
      "name": "Giggle"
    },
    "severity": "oecd:SeriousIncident",
    "harmType": [
      "oecd:OtherHarm"
    ],
    "harmQuantification": {
      "@type": "oecd:HarmQuantification",
      "affected_stakeholders": "30416 individuals",
      "economic_losses": "$4 million"
    },
    "countries": [
      {
        "@type": "core:Country",
        "@id": "https://www.wikidata.org/wiki/China",
        "name": "China"
      }
    ],
    "affectedStakeholders": [
      {
        "@type": "oecd:StakeholderGroup",
        "@id": "https://example.org/stakeholder-group/women-of-color",
        "name": "women of color"
      },
      {
        "@type": "oecd:StakeholderGroup",
        "@id": "https://example.org/stakeholder-group/trans-women",
        "name": "trans women"
      }
    ],
    "businessFunction": [
      "oecd:Production"
    ],
    "submitter": {
      "@type": "oecd:Submitter",
      "@id": "https://example.org/submitter/submitter",
      "role": "Industry Analyst",
      "affiliation": "University Research Lab",
      "stakeholderGroup": "I work or am affiliated to a public interest body or NGO",
      "relationToIncident": "None of the above, but have partial or substantial knowledge of the incident (e.g. first-hand knowledge, research etc.)"
    },
    "unintendedUse": false,
    "sameAs": "https://incidentdatabase.ai/cite/166"
  },
  {
    "@context": [
      "http://localhost:3000/api/schemas/v1/core/context.jsonld",
      "http://localhost:3001/api/schemas/v1/oecd/context.jsonld"
    ],
    "@type": "oecd:Incident",
    "@id": "https://oecd.ai/incident/OECD-2020-108",
    "incident_id": "OECD-2020-108",
    "title": "AI Diagnostic System Misses Critical Symptoms in Emergency Department",
    "description": "An AI triage system in emergency departments failed to identify critical symptoms in patients presenting with atypical manifestations of serious conditions. The system's training data lacked diversity in symptom presentations across different demographics.",
    "date": "2020-10-04",
    "aiSystem": {
      "@type": "oecd:AISystem",
      "name": "Medical AI Engine",
      "version": "5.18.41",
      "relation": [
        "oecd:DirectCause"
      ]
    },
    "developer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/Starbucks",
      "name": "Starbucks"
    },
    "deployer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/Northpointe",
      "name": "Northpointe"
    },
    "severity": "oecd:SeriousHazard",
    "harmType": [
      "oecd:PhysicalHarm",
      "oecd:HumanRightsHarm"
    ],
    "harmQuantification": {
      "@type": "oecd:HarmQuantification",
      "affected_stakeholders": "59118 workers",
      "economic_losses": "$20.1 million"
    },
    "countries": [
      {
        "@type": "core:Country",
        "@id": "https://www.wikidata.org/wiki/France",
        "name": "France"
      },
      {
        "@type": "core:Country",
        "@id": "https://www.wikidata.org/wiki/Canada",
        "name": "Canada"
      }
    ],
    "affectedStakeholders": [
      {
        "@type": "oecd:StakeholderGroup",
        "@id": "https://example.org/stakeholder-group/patients",
        "name": "Patients"
      }
    ],
    "businessFunction": [
      "oecd:OtherFunction"
    ],
    "submitter": {
      "@type": "oecd:Submitter",
      "@id": "https://example.org/submitter/reporter",
      "role": "Industry Whistleblower",
      "affiliation": "University Ethics Lab",
      "stakeholderGroup": "None of the above, but have partial or substantial knowledge of the incident",
      "relationToIncident": "None of the above, but have partial or substantial knowledge of the incident (e.g. first-hand knowledge, research etc.)"
    },
    "unintendedUse": true
  },
  {
    "@context": [
      "http://localhost:3000/api/schemas/v1/core/context.jsonld",
      "http://localhost:3001/api/schemas/v1/oecd/context.jsonld"
    ],
    "@type": "oecd:Incident",
    "@id": "https://oecd.ai/incident/OECD-2020-109",
    "incident_id": "OECD-2020-109",
    "title": "Employee Monitoring AI Incorrectly Flags Remote Workers as Unproductive",
    "description": "An AI-powered employee productivity monitoring system incorrectly categorized focused work activities as idle time, leading to unfair performance reviews and terminations. The system failed to understand different working styles and break patterns.",
    "date": "2020-10-21",
    "aiSystem": {
      "@type": "oecd:AISystem",
      "name": "Workplace AI Solution Pro",
      "version": "5.6.54",
      "relation": [
        "oecd:DirectCause"
      ]
    },
    "developer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/Wikipedia",
      "name": "Wikipedia"
    },
    "deployer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/Navya_(company)",
      "name": "Navya"
    },
    "severity": "oecd:SeriousIncident",
    "harmType": [
      "oecd:EconomicHarm",
      "oecd:PsychologicalHarm",
      "oecd:ReputationalHarm"
    ],
    "harmQuantification": {
      "@type": "oecd:HarmQuantification",
      "affected_stakeholders": "87375 patients",
      "economic_losses": "$29.0 million",
      "psychological_impact": "Documented stress and anxiety in affected population"
    },
    "countries": [
      {
        "@type": "core:Country",
        "@id": "https://www.wikidata.org/wiki/Brazil",
        "name": "Brazil"
      }
    ],
    "affectedStakeholders": [
      {
        "@type": "oecd:StakeholderGroup",
        "@id": "https://example.org/stakeholder-group/minority-groups",
        "name": "Minority Groups"
      },
      {
        "@type": "oecd:StakeholderGroup",
        "@id": "https://example.org/stakeholder-group/patients",
        "name": "Patients"
      }
    ],
    "businessFunction": [
      "oecd:HRManagement",
      "oecd:QualityControl"
    ],
    "submitter": {
      "@type": "oecd:Submitter",
      "@id": "https://example.org/submitter/reporter",
      "role": "Industry Whistleblower",
      "affiliation": "Digital Rights Organization",
      "stakeholderGroup": "I am an affected stakeholder",
      "relationToIncident": "None of the above, but have partial or substantial knowledge of the incident (e.g. first-hand knowledge, research etc.)"
    },
    "unintendedUse": false
  },
  {
    "@context": [
      "http://localhost:3000/api/schemas/v1/core/context.jsonld",
      "http://localhost:3001/api/schemas/v1/oecd/context.jsonld"
    ],
    "@type": "oecd:Incident",
    "@id": "https://oecd.ai/incident/OECD-2020-110",
    "incident_id": "OECD-2020-110",
    "title": "AI Diagnostic System Misses Critical Symptoms in Emergency Department",
    "description": "An AI triage system in emergency departments failed to identify critical symptoms in patients presenting with atypical manifestations of serious conditions. The system's training data lacked diversity in symptom presentations across different demographics.",
    "date": "2020-11-04",
    "aiSystem": {
      "@type": "oecd:AISystem",
      "name": "Medical AI Solution Pro",
      "version": "3.3.10",
      "relation": [
        "oecd:DirectCause",
        "oecd:ContributingFactor"
      ]
    },
    "developer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/Microsoft",
      "name": "Microsoft"
    },
    "deployer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/Equivant",
      "name": "Equivant"
    },
    "severity": "oecd:SeriousHazard",
    "harmType": [
      "oecd:PhysicalHarm",
      "oecd:HumanRightsHarm"
    ],
    "harmQuantification": {
      "@type": "oecd:HarmQuantification",
      "affected_stakeholders": "10326 workers",
      "economic_losses": "$49.8 million"
    },
    "countries": [
      {
        "@type": "core:Country",
        "@id": "https://www.wikidata.org/wiki/Germany",
        "name": "Germany"
      }
    ],
    "affectedStakeholders": [
      {
        "@type": "oecd:StakeholderGroup",
        "@id": "https://example.org/stakeholder-group/patients",
        "name": "Patients"
      }
    ],
    "businessFunction": [
      "oecd:OtherFunction"
    ],
    "submitter": {
      "@type": "oecd:Submitter",
      "@id": "https://example.org/submitter/reporter",
      "role": "Data Scientist",
      "affiliation": "Consumer Protection Agency",
      "stakeholderGroup": "I work or am affiliated to a public interest body or NGO",
      "relationToIncident": "None of the above, but have partial or substantial knowledge of the incident (e.g. first-hand knowledge, research etc.)"
    },
    "unintendedUse": false
  },
  {
    "@context": [
      "http://localhost:3000/api/schemas/v1/core/context.jsonld",
      "http://localhost:3001/api/schemas/v1/oecd/context.jsonld"
    ],
    "@type": "oecd:Incident",
    "@id": "https://oecd.ai/incident/OECD-2020-111",
    "incident_id": "OECD-2020-111",
    "title": "Surgical Robot Malfunction During Minimally Invasive Procedure",
    "description": "An AI-assisted surgical robot experienced a control system failure during a procedure, requiring emergency conversion to traditional surgery. The AI's motion planning algorithms failed to account for unexpected tissue resistance.",
    "date": "2020-11-14",
    "aiSystem": {
      "@type": "oecd:AISystem",
      "name": "Medical AI Solution Pro",
      "version": "8.2.83",
      "relation": [
        "oecd:ContributingFactor",
        "oecd:HumanError"
      ]
    },
    "developer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/LinkedIn",
      "name": "LinkedIn"
    },
    "deployer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/Various_organizations",
      "name": "Various organizations"
    },
    "severity": "oecd:SeriousIncident",
    "harmType": [
      "oecd:PhysicalHarm"
    ],
    "harmQuantification": {
      "@type": "oecd:HarmQuantification",
      "affected_stakeholders": "40497 customers",
      "economic_losses": "$0.3 million"
    },
    "countries": [
      {
        "@type": "core:Country",
        "@id": "https://www.wikidata.org/wiki/United_States",
        "name": "United States"
      }
    ],
    "affectedStakeholders": [
      {
        "@type": "oecd:StakeholderGroup",
        "@id": "https://example.org/stakeholder-group/minority-groups",
        "name": "Minority Groups"
      }
    ],
    "businessFunction": [
      "oecd:OtherFunction"
    ],
    "submitter": {
      "@type": "oecd:Submitter",
      "@id": "https://example.org/submitter/reporter",
      "role": "Industry Whistleblower",
      "affiliation": "Tech Accountability Project",
      "stakeholderGroup": "None of the above, but have partial or substantial knowledge of the incident",
      "relationToIncident": "None of the above, but have partial or substantial knowledge of the incident (e.g. first-hand knowledge, research etc.)"
    },
    "unintendedUse": true
  },
  {
    "@context": [
      "http://localhost:3000/api/schemas/v1/core/context.jsonld",
      "http://localhost:3001/api/schemas/v1/oecd/context.jsonld"
    ],
    "@type": "oecd:Incident",
    "@id": "https://oecd.ai/incident/OECD-2020-112",
    "incident_id": "OECD-2020-112",
    "title": "Algorithmic Trading System Triggers Market Manipulation Investigation",
    "description": "High-frequency trading algorithms were found to be creating artificial price movements through coordinated trades. The AI systems learned to exploit market microstructure in ways that resembled illegal manipulation.",
    "date": "2020-11-25",
    "aiSystem": {
      "@type": "oecd:AISystem",
      "name": "Financial AI System",
      "version": "10.3.34",
      "relation": [
        "oecd:ContributingFactor",
        "oecd:HumanError"
      ]
    },
    "developer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/LinkedIn",
      "name": "LinkedIn"
    },
    "deployer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/Delphi_Technologies",
      "name": "Delphi Technologies"
    },
    "severity": "oecd:SeriousHazard",
    "harmType": [
      "oecd:EconomicHarm",
      "oecd:PublicInterestHarm"
    ],
    "harmQuantification": {
      "@type": "oecd:HarmQuantification",
      "affected_stakeholders": "12008 customers",
      "economic_losses": "$31.5 million"
    },
    "countries": [
      {
        "@type": "core:Country",
        "@id": "https://www.wikidata.org/wiki/South_Korea",
        "name": "South Korea"
      },
      {
        "@type": "core:Country",
        "@id": "https://www.wikidata.org/wiki/Australia",
        "name": "Australia"
      }
    ],
    "affectedStakeholders": [
      {
        "@type": "oecd:StakeholderGroup",
        "@id": "https://example.org/stakeholder-group/minority-groups",
        "name": "Minority Groups"
      }
    ],
    "businessFunction": [
      "oecd:OtherFunction"
    ],
    "submitter": {
      "@type": "oecd:Submitter",
      "@id": "https://example.org/submitter/reporter",
      "role": "Data Scientist",
      "affiliation": "Consumer Protection Agency",
      "stakeholderGroup": "None of the above, but have partial or substantial knowledge of the incident",
      "relationToIncident": "None of the above, but have partial or substantial knowledge of the incident (e.g. first-hand knowledge, research etc.)"
    },
    "unintendedUse": false
  },
  {
    "@context": [
      "http://localhost:3000/api/schemas/v1/core/context.jsonld",
      "http://localhost:3001/api/schemas/v1/oecd/context.jsonld"
    ],
    "@type": "oecd:Incident",
    "@id": "https://oecd.ai/incident/OECD-2020-113",
    "incident_id": "OECD-2020-113",
    "title": "Facial Recognition System Falsely Identifies Protesters as Criminals",
    "description": "A law enforcement facial recognition system incorrectly matched peaceful protesters with criminal database entries, leading to wrongful detentions. The AI system showed higher error rates for certain ethnic groups and in crowded scenarios.",
    "date": "2020-12-17",
    "aiSystem": {
      "@type": "oecd:AISystem",
      "name": "Security/Surveillance Solution Pro",
      "version": "7.8.73",
      "relation": [
        "oecd:ContributingFactor",
        "oecd:HumanError"
      ]
    },
    "developer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/The_DAO",
      "name": "The DAO"
    },
    "deployer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/Apple_Inc.",
      "name": "Apple"
    },
    "severity": "oecd:SeriousIncident",
    "harmType": [
      "oecd:PhysicalHarm",
      "oecd:HumanRightsHarm",
      "oecd:ReputationalHarm"
    ],
    "harmQuantification": {
      "@type": "oecd:HarmQuantification",
      "affected_stakeholders": "42879 individuals",
      "economic_losses": "$36.1 million"
    },
    "countries": [
      {
        "@type": "core:Country",
        "@id": "https://www.wikidata.org/wiki/Australia",
        "name": "Australia"
      },
      {
        "@type": "core:Country",
        "@id": "https://www.wikidata.org/wiki/India",
        "name": "India"
      }
    ],
    "affectedStakeholders": [
      {
        "@type": "oecd:StakeholderGroup",
        "@id": "https://example.org/stakeholder-group/patients",
        "name": "Patients"
      },
      {
        "@type": "oecd:StakeholderGroup",
        "@id": "https://example.org/stakeholder-group/children",
        "name": "Children"
      },
      {
        "@type": "core:Person",
        "@id": "https://example.org/entities/person/black-people",
        "name": "Black people"
      }
    ],
    "businessFunction": [
      "oecd:Compliance"
    ],
    "submitter": {
      "@type": "oecd:Submitter",
      "@id": "https://example.org/submitter/reporter",
      "role": "Industry Whistleblower",
      "affiliation": "AI Safety Coalition",
      "stakeholderGroup": "I work or am affiliated to a public interest body or NGO",
      "relationToIncident": "None of the above, but have partial or substantial knowledge of the incident (e.g. first-hand knowledge, research etc.)"
    },
    "unintendedUse": false
  },
  {
    "@context": [
      "http://localhost:3000/api/schemas/v1/core/context.jsonld",
      "http://localhost:3001/api/schemas/v1/oecd/context.jsonld"
    ],
    "@type": "oecd:Incident",
    "@id": "https://oecd.ai/incident/OECD-2020-114",
    "incident_id": "OECD-2020-114",
    "title": "AI Credit Scoring System Discriminates Against Recent Immigrants",
    "description": "An automated credit scoring system systematically assigned lower credit scores to recent immigrants despite strong financial indicators. The AI model heavily weighted credit history length, creating unfair barriers to financial services.",
    "date": "2020-12-28",
    "aiSystem": {
      "@type": "oecd:AISystem",
      "name": "Financial AI Engine Pro",
      "version": "3.17.36",
      "relation": [
        "oecd:DirectCause"
      ]
    },
    "developer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/Youth_Laboratories",
      "name": "Youth Laboratories"
    },
    "deployer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/Microsoft",
      "name": "Microsoft"
    },
    "severity": "oecd:SeriousIncident",
    "harmType": [
      "oecd:EconomicHarm",
      "oecd:HumanRightsHarm"
    ],
    "harmQuantification": {
      "@type": "oecd:HarmQuantification",
      "affected_stakeholders": "39590 workers",
      "economic_losses": "$7.1 million"
    },
    "countries": [
      {
        "@type": "core:Country",
        "@id": "https://www.wikidata.org/wiki/Netherlands",
        "name": "Netherlands"
      },
      {
        "@type": "core:Country",
        "@id": "https://www.wikidata.org/wiki/Israel",
        "name": "Israel"
      }
    ],
    "affectedStakeholders": [
      {
        "@type": "oecd:StakeholderGroup",
        "@id": "https://example.org/stakeholder-group/children",
        "name": "Children"
      },
      {
        "@type": "core:Person",
        "@id": "https://example.org/entities/person/black-people",
        "name": "Black people"
      },
      {
        "@type": "oecd:StakeholderGroup",
        "@id": "https://example.org/stakeholder-group/women",
        "name": "Women"
      }
    ],
    "businessFunction": [
      "oecd:OtherFunction"
    ],
    "submitter": {
      "@type": "oecd:Submitter",
      "@id": "https://example.org/submitter/reporter",
      "role": "Consumer Advocate",
      "affiliation": "Consumer Protection Agency",
      "stakeholderGroup": "I work or am affiliated to a public interest body or NGO",
      "relationToIncident": "None of the above, but have partial or substantial knowledge of the incident (e.g. first-hand knowledge, research etc.)"
    },
    "unintendedUse": false
  },
  {
    "@context": [
      "http://localhost:3000/api/schemas/v1/core/context.jsonld",
      "http://localhost:3001/api/schemas/v1/oecd/context.jsonld"
    ],
    "@type": "oecd:Incident",
    "@id": "https://oecd.ai/incident/OECD-2021-115",
    "incident_id": "OECD-2021-115",
    "title": "AI System Failure Related to AI translation is jeopardizing Afghan asylum claims",
    "description": "An AI system failure occurred with similar characteristics to the documented incident involving US Citizenship and Immigration Services. The system exhibited comparable failure modes resulting in harm to affected stakeholders.",
    "date": "2021-01-17",
    "aiSystem": {
      "@type": "oecd:AISystem",
      "name": "AI Engine",
      "version": "5.8",
      "relation": [
        "oecd:DirectCause"
      ]
    },
    "developer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/US_Citizenship_and_Immigration_Services",
      "name": "US Citizenship and Immigration Services"
    },
    "deployer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/US_Citizenship_and_Immigration_Services",
      "name": "US Citizenship and Immigration Services"
    },
    "severity": "oecd:SeriousIncident",
    "harmType": [
      "oecd:OtherHarm"
    ],
    "harmQuantification": {
      "@type": "oecd:HarmQuantification",
      "affected_stakeholders": "16621 individuals"
    },
    "countries": [
      {
        "@type": "core:Country",
        "@id": "https://www.wikidata.org/wiki/Brazil",
        "name": "Brazil"
      },
      {
        "@type": "core:Country",
        "@id": "https://www.wikidata.org/wiki/Canada",
        "name": "Canada"
      },
      {
        "@type": "core:Country",
        "@id": "https://www.wikidata.org/wiki/Germany",
        "name": "Germany"
      }
    ],
    "affectedStakeholders": [
      {
        "@type": "core:Person",
        "@id": "https://example.org/entities/person/pashto-speaking-asylum-seekers",
        "name": "Pashto-speaking asylum seekers"
      },
      {
        "@type": "core:Person",
        "@id": "https://example.org/entities/person/dari-speaking-asylum-seekers",
        "name": "Dari-speaking asylum seekers"
      },
      {
        "@type": "core:Person",
        "@id": "https://example.org/entities/person/anonymous-pashto-speaking-refugee",
        "name": "anonymous Pashto-speaking refugee"
      }
    ],
    "businessFunction": [
      "oecd:Planning",
      "oecd:HRManagement"
    ],
    "submitter": {
      "@type": "oecd:Submitter",
      "@id": "https://example.org/submitter/submitter",
      "role": "Ethics Officer",
      "affiliation": "Tech Policy Center",
      "stakeholderGroup": "I represent a government or regulatory body",
      "relationToIncident": "I am an affected stakeholder"
    },
    "unintendedUse": true,
    "sameAs": "https://incidentdatabase.ai/cite/532"
  },
  {
    "@context": [
      "http://localhost:3000/api/schemas/v1/core/context.jsonld",
      "http://localhost:3001/api/schemas/v1/oecd/context.jsonld"
    ],
    "@type": "oecd:Incident",
    "@id": "https://oecd.ai/incident/OECD-2021-116",
    "incident_id": "OECD-2021-116",
    "title": "AI Diagnostic System Misses Critical Symptoms in Emergency Department",
    "description": "An AI triage system in emergency departments failed to identify critical symptoms in patients presenting with atypical manifestations of serious conditions. The system's training data lacked diversity in symptom presentations across different demographics.",
    "date": "2021-02-09",
    "aiSystem": {
      "@type": "oecd:AISystem",
      "name": "Medical AI Solution",
      "version": "4.0.68",
      "relation": [
        "oecd:DirectCause"
      ]
    },
    "developer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/University_of_Washington",
      "name": "University of Washington"
    },
    "deployer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/LinkedIn",
      "name": "LinkedIn"
    },
    "severity": "oecd:SeriousHazard",
    "harmType": [
      "oecd:PhysicalHarm",
      "oecd:HumanRightsHarm"
    ],
    "harmQuantification": {
      "@type": "oecd:HarmQuantification",
      "affected_stakeholders": "50023 users",
      "economic_losses": "$2.5 million"
    },
    "countries": [
      {
        "@type": "core:Country",
        "@id": "https://www.wikidata.org/wiki/Sweden",
        "name": "Sweden"
      },
      {
        "@type": "core:Country",
        "@id": "https://www.wikidata.org/wiki/Norway",
        "name": "Norway"
      }
    ],
    "affectedStakeholders": [
      {
        "@type": "oecd:StakeholderGroup",
        "@id": "https://example.org/stakeholder-group/students",
        "name": "Students"
      }
    ],
    "businessFunction": [
      "oecd:OtherFunction"
    ],
    "submitter": {
      "@type": "oecd:Submitter",
      "@id": "https://example.org/submitter/reporter",
      "role": "Safety Engineer",
      "affiliation": "Consumer Protection Agency",
      "stakeholderGroup": "I represent a government or regulatory body",
      "relationToIncident": "None of the above, but have partial or substantial knowledge of the incident (e.g. first-hand knowledge, research etc.)"
    },
    "unintendedUse": true
  },
  {
    "@context": [
      "http://localhost:3000/api/schemas/v1/core/context.jsonld",
      "http://localhost:3001/api/schemas/v1/oecd/context.jsonld"
    ],
    "@type": "oecd:Incident",
    "@id": "https://oecd.ai/incident/OECD-2021-117",
    "incident_id": "OECD-2021-117",
    "title": "Facial Recognition System Falsely Identifies Protesters as Criminals",
    "description": "A law enforcement facial recognition system incorrectly matched peaceful protesters with criminal database entries, leading to wrongful detentions. The AI system showed higher error rates for certain ethnic groups and in crowded scenarios.",
    "date": "2021-02-18",
    "aiSystem": {
      "@type": "oecd:AISystem",
      "name": "Security/Surveillance System",
      "version": "7.1.19",
      "relation": [
        "oecd:ContributingFactor",
        "oecd:HumanError"
      ]
    },
    "developer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/Northpointe",
      "name": "Northpointe"
    },
    "deployer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/The_DAO",
      "name": "The DAO"
    },
    "severity": "oecd:SeriousIncident",
    "harmType": [
      "oecd:PhysicalHarm",
      "oecd:HumanRightsHarm",
      "oecd:ReputationalHarm"
    ],
    "harmQuantification": {
      "@type": "oecd:HarmQuantification",
      "affected_stakeholders": "87990 users",
      "economic_losses": "$33.3 million"
    },
    "countries": [
      {
        "@type": "core:Country",
        "@id": "https://www.wikidata.org/wiki/Germany",
        "name": "Germany"
      },
      {
        "@type": "core:Country",
        "@id": "https://www.wikidata.org/wiki/Italy",
        "name": "Italy"
      }
    ],
    "affectedStakeholders": [
      {
        "@type": "oecd:StakeholderGroup",
        "@id": "https://example.org/stakeholder-group/students",
        "name": "Students"
      },
      {
        "@type": "core:Person",
        "@id": "https://example.org/entities/person/medical-residents",
        "name": "Medical Residents"
      }
    ],
    "businessFunction": [
      "oecd:Compliance"
    ],
    "submitter": {
      "@type": "oecd:Submitter",
      "@id": "https://example.org/submitter/reporter",
      "role": "Consumer Advocate",
      "affiliation": "Consumer Protection Agency",
      "stakeholderGroup": "I work or am affiliated to a public interest body or NGO",
      "relationToIncident": "None of the above, but have partial or substantial knowledge of the incident (e.g. first-hand knowledge, research etc.)"
    },
    "unintendedUse": false
  },
  {
    "@context": [
      "http://localhost:3000/api/schemas/v1/core/context.jsonld",
      "http://localhost:3001/api/schemas/v1/oecd/context.jsonld"
    ],
    "@type": "oecd:Incident",
    "@id": "https://oecd.ai/incident/OECD-2021-118",
    "incident_id": "OECD-2021-118",
    "title": "AI System Failure Related to AI translation is jeopardizing Afghan asylum claims",
    "description": "An AI system failure occurred with similar characteristics to the documented incident involving US Citizenship and Immigration Services. The system exhibited comparable failure modes resulting in harm to affected stakeholders.",
    "date": "2021-02-26",
    "aiSystem": {
      "@type": "oecd:AISystem",
      "name": "Smart System",
      "version": "3.9",
      "relation": [
        "oecd:DirectCause"
      ]
    },
    "developer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/US_Citizenship_and_Immigration_Services",
      "name": "US Citizenship and Immigration Services"
    },
    "deployer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/US_Citizenship_and_Immigration_Services",
      "name": "US Citizenship and Immigration Services"
    },
    "severity": "oecd:SeriousIncident",
    "harmType": [
      "oecd:OtherHarm"
    ],
    "harmQuantification": {
      "@type": "oecd:HarmQuantification",
      "affected_stakeholders": "5496 individuals",
      "economic_losses": "$9 million"
    },
    "countries": [
      {
        "@type": "core:Country",
        "@id": "https://www.wikidata.org/wiki/France",
        "name": "France"
      },
      {
        "@type": "core:Country",
        "@id": "https://www.wikidata.org/wiki/Israel",
        "name": "Israel"
      }
    ],
    "affectedStakeholders": [
      {
        "@type": "core:Person",
        "@id": "https://example.org/entities/person/pashto-speaking-asylum-seekers",
        "name": "Pashto-speaking asylum seekers"
      },
      {
        "@type": "core:Person",
        "@id": "https://example.org/entities/person/dari-speaking-asylum-seekers",
        "name": "Dari-speaking asylum seekers"
      },
      {
        "@type": "core:Person",
        "@id": "https://example.org/entities/person/anonymous-pashto-speaking-refugee",
        "name": "anonymous Pashto-speaking refugee"
      }
    ],
    "businessFunction": [
      "oecd:Planning",
      "oecd:Procurement"
    ],
    "submitter": {
      "@type": "oecd:Submitter",
      "@id": "https://example.org/submitter/submitter",
      "role": "Government Inspector",
      "affiliation": "Tech Policy Center",
      "stakeholderGroup": "I represent a government or regulatory body",
      "relationToIncident": "I am an affected stakeholder"
    },
    "unintendedUse": false,
    "sameAs": "https://incidentdatabase.ai/cite/532"
  },
  {
    "@context": [
      "http://localhost:3000/api/schemas/v1/core/context.jsonld",
      "http://localhost:3001/api/schemas/v1/oecd/context.jsonld"
    ],
    "@type": "oecd:Incident",
    "@id": "https://oecd.ai/incident/OECD-2021-119",
    "incident_id": "OECD-2021-119",
    "title": "Facial Recognition System Falsely Identifies Protesters as Criminals",
    "description": "A law enforcement facial recognition system incorrectly matched peaceful protesters with criminal database entries, leading to wrongful detentions. The AI system showed higher error rates for certain ethnic groups and in crowded scenarios.",
    "date": "2021-03-08",
    "aiSystem": {
      "@type": "oecd:AISystem",
      "name": "Security/Surveillance Platform Pro",
      "version": "1.11.84",
      "relation": [
        "oecd:DirectCause",
        "oecd:ContributingFactor"
      ]
    },
    "developer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/Boeing",
      "name": "Boeing"
    },
    "deployer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/Microsoft",
      "name": "Microsoft"
    },
    "severity": "oecd:SeriousIncident",
    "harmType": [
      "oecd:PhysicalHarm",
      "oecd:HumanRightsHarm",
      "oecd:ReputationalHarm"
    ],
    "harmQuantification": {
      "@type": "oecd:HarmQuantification",
      "affected_stakeholders": "9924 customers",
      "economic_losses": "$2.5 million"
    },
    "countries": [
      {
        "@type": "core:Country",
        "@id": "https://www.wikidata.org/wiki/Singapore",
        "name": "Singapore"
      }
    ],
    "affectedStakeholders": [
      {
        "@type": "core:Person",
        "@id": "https://example.org/entities/person/airplane-passengers",
        "name": "Airplane Passengers"
      }
    ],
    "businessFunction": [
      "oecd:Compliance"
    ],
    "submitter": {
      "@type": "oecd:Submitter",
      "@id": "https://example.org/submitter/reporter",
      "role": "Data Scientist",
      "affiliation": "Digital Rights Organization",
      "stakeholderGroup": "I work or am affiliated to a public interest body or NGO",
      "relationToIncident": "None of the above, but have partial or substantial knowledge of the incident (e.g. first-hand knowledge, research etc.)"
    },
    "unintendedUse": false
  },
  {
    "@context": [
      "http://localhost:3000/api/schemas/v1/core/context.jsonld",
      "http://localhost:3001/api/schemas/v1/oecd/context.jsonld"
    ],
    "@type": "oecd:Incident",
    "@id": "https://oecd.ai/incident/OECD-2021-120",
    "incident_id": "OECD-2021-120",
    "title": "Delivery Robot Swarm Blocks Emergency Vehicle Access",
    "description": "A fleet of autonomous delivery robots failed to coordinate their movements during an emergency, blocking paramedic access to a medical emergency. The swarm intelligence system lacked proper emergency vehicle detection and response protocols.",
    "date": "2021-03-13",
    "aiSystem": {
      "@type": "oecd:AISystem",
      "name": "Autonomous Systems System Pro",
      "version": "8.5.11",
      "relation": [
        "oecd:DirectCause",
        "oecd:ContributingFactor"
      ]
    },
    "developer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/Wikipedia",
      "name": "Wikipedia"
    },
    "deployer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/Volkswagen",
      "name": "Volkswagen"
    },
    "severity": "oecd:SeriousHazard",
    "harmType": [
      "oecd:PhysicalHarm",
      "oecd:PublicInterestHarm"
    ],
    "harmQuantification": {
      "@type": "oecd:HarmQuantification",
      "affected_stakeholders": "12437 patients",
      "economic_losses": "$14.2 million"
    },
    "countries": [
      {
        "@type": "core:Country",
        "@id": "https://www.wikidata.org/wiki/South_Korea",
        "name": "South Korea"
      }
    ],
    "affectedStakeholders": [
      {
        "@type": "oecd:StakeholderGroup",
        "@id": "https://example.org/stakeholder-group/children",
        "name": "Children"
      },
      {
        "@type": "oecd:StakeholderGroup",
        "@id": "https://example.org/stakeholder-group/women",
        "name": "Women"
      }
    ],
    "businessFunction": [
      "oecd:Logistics",
      "oecd:OtherFunction"
    ],
    "submitter": {
      "@type": "oecd:Submitter",
      "@id": "https://example.org/submitter/reporter",
      "role": "Industry Whistleblower",
      "affiliation": "Consumer Protection Agency",
      "stakeholderGroup": "None of the above, but have partial or substantial knowledge of the incident",
      "relationToIncident": "None of the above, but have partial or substantial knowledge of the incident (e.g. first-hand knowledge, research etc.)"
    },
    "unintendedUse": false
  },
  {
    "@context": [
      "http://localhost:3000/api/schemas/v1/core/context.jsonld",
      "http://localhost:3001/api/schemas/v1/oecd/context.jsonld"
    ],
    "@type": "oecd:Incident",
    "@id": "https://oecd.ai/incident/OECD-2021-121",
    "incident_id": "OECD-2021-121",
    "title": "Delivery Robot Swarm Blocks Emergency Vehicle Access",
    "description": "A fleet of autonomous delivery robots failed to coordinate their movements during an emergency, blocking paramedic access to a medical emergency. The swarm intelligence system lacked proper emergency vehicle detection and response protocols.",
    "date": "2021-05-09",
    "aiSystem": {
      "@type": "oecd:AISystem",
      "name": "Autonomous Systems Solution",
      "version": "9.12.17",
      "relation": [
        "oecd:DirectCause"
      ]
    },
    "developer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/The_DAO",
      "name": "The DAO"
    },
    "deployer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/YouTube",
      "name": "YouTube"
    },
    "severity": "oecd:SeriousHazard",
    "harmType": [
      "oecd:PhysicalHarm",
      "oecd:PublicInterestHarm"
    ],
    "harmQuantification": {
      "@type": "oecd:HarmQuantification",
      "affected_stakeholders": "29968 patients"
    },
    "countries": [
      {
        "@type": "core:Country",
        "@id": "https://www.wikidata.org/wiki/France",
        "name": "France"
      }
    ],
    "affectedStakeholders": [
      {
        "@type": "core:Person",
        "@id": "https://example.org/entities/person/medical-residents",
        "name": "Medical Residents"
      },
      {
        "@type": "oecd:StakeholderGroup",
        "@id": "https://example.org/stakeholder-group/women",
        "name": "Women"
      },
      {
        "@type": "core:Person",
        "@id": "https://example.org/entities/person/black-people",
        "name": "Black people"
      }
    ],
    "businessFunction": [
      "oecd:Logistics",
      "oecd:OtherFunction"
    ],
    "submitter": {
      "@type": "oecd:Submitter",
      "@id": "https://example.org/submitter/reporter",
      "role": "Industry Whistleblower",
      "affiliation": "University Ethics Lab",
      "stakeholderGroup": "None of the above, but have partial or substantial knowledge of the incident",
      "relationToIncident": "None of the above, but have partial or substantial knowledge of the incident (e.g. first-hand knowledge, research etc.)"
    },
    "unintendedUse": false
  },
  {
    "@context": [
      "http://localhost:3000/api/schemas/v1/core/context.jsonld",
      "http://localhost:3001/api/schemas/v1/oecd/context.jsonld"
    ],
    "@type": "oecd:Incident",
    "@id": "https://oecd.ai/incident/OECD-2021-122",
    "incident_id": "OECD-2021-122",
    "title": "AI System Failure Related to AI translation is jeopardizing Afghan asylum claims",
    "description": "An AI system failure occurred with similar characteristics to the documented incident involving US Citizenship and Immigration Services. The system exhibited comparable failure modes resulting in harm to affected stakeholders.",
    "date": "2021-05-14",
    "aiSystem": {
      "@type": "oecd:AISystem",
      "name": "Smart Platform",
      "version": "1.8",
      "relation": [
        "oecd:DirectCause"
      ]
    },
    "developer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/US_Citizenship_and_Immigration_Services",
      "name": "US Citizenship and Immigration Services"
    },
    "deployer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/US_Citizenship_and_Immigration_Services",
      "name": "US Citizenship and Immigration Services"
    },
    "severity": "oecd:SeriousIncident",
    "harmType": [
      "oecd:OtherHarm"
    ],
    "harmQuantification": {
      "@type": "oecd:HarmQuantification",
      "affected_stakeholders": "6006 individuals"
    },
    "countries": [
      {
        "@type": "core:Country",
        "@id": "https://www.wikidata.org/wiki/Sweden",
        "name": "Sweden"
      },
      {
        "@type": "core:Country",
        "@id": "https://www.wikidata.org/wiki/Brazil",
        "name": "Brazil"
      }
    ],
    "affectedStakeholders": [
      {
        "@type": "core:Person",
        "@id": "https://example.org/entities/person/pashto-speaking-asylum-seekers",
        "name": "Pashto-speaking asylum seekers"
      },
      {
        "@type": "core:Person",
        "@id": "https://example.org/entities/person/dari-speaking-asylum-seekers",
        "name": "Dari-speaking asylum seekers"
      },
      {
        "@type": "core:Person",
        "@id": "https://example.org/entities/person/anonymous-pashto-speaking-refugee",
        "name": "anonymous Pashto-speaking refugee"
      }
    ],
    "businessFunction": [
      "oecd:Marketing",
      "oecd:Production"
    ],
    "submitter": {
      "@type": "oecd:Submitter",
      "@id": "https://example.org/submitter/submitter",
      "role": "Academic Researcher",
      "affiliation": "University Research Lab",
      "stakeholderGroup": "None of the above, but have partial or substantial knowledge of the incident",
      "relationToIncident": "I am an affected stakeholder"
    },
    "unintendedUse": false,
    "sameAs": "https://incidentdatabase.ai/cite/532"
  },
  {
    "@context": [
      "http://localhost:3000/api/schemas/v1/core/context.jsonld",
      "http://localhost:3001/api/schemas/v1/oecd/context.jsonld"
    ],
    "@type": "oecd:Incident",
    "@id": "https://oecd.ai/incident/OECD-2021-123",
    "incident_id": "OECD-2021-123",
    "title": "Surgical Robot Malfunction During Minimally Invasive Procedure",
    "description": "An AI-assisted surgical robot experienced a control system failure during a procedure, requiring emergency conversion to traditional surgery. The AI's motion planning algorithms failed to account for unexpected tissue resistance.",
    "date": "2021-05-31",
    "aiSystem": {
      "@type": "oecd:AISystem",
      "name": "Medical AI System",
      "version": "5.6.25",
      "relation": [
        "oecd:DirectCause"
      ]
    },
    "developer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/Microsoft",
      "name": "Microsoft"
    },
    "deployer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/Google",
      "name": "Google"
    },
    "severity": "oecd:SeriousIncident",
    "harmType": [
      "oecd:PhysicalHarm"
    ],
    "harmQuantification": {
      "@type": "oecd:HarmQuantification",
      "affected_stakeholders": "74208 workers"
    },
    "countries": [
      {
        "@type": "core:Country",
        "@id": "https://www.wikidata.org/wiki/South_Korea",
        "name": "South Korea"
      }
    ],
    "affectedStakeholders": [
      {
        "@type": "core:Person",
        "@id": "https://example.org/entities/person/bus-passengers",
        "name": "Bus passengers"
      }
    ],
    "businessFunction": [
      "oecd:OtherFunction"
    ],
    "submitter": {
      "@type": "oecd:Submitter",
      "@id": "https://example.org/submitter/reporter",
      "role": "Government Auditor",
      "affiliation": "AI Safety Coalition",
      "stakeholderGroup": "I am an affected stakeholder",
      "relationToIncident": "None of the above, but have partial or substantial knowledge of the incident (e.g. first-hand knowledge, research etc.)"
    },
    "unintendedUse": true
  },
  {
    "@context": [
      "http://localhost:3000/api/schemas/v1/core/context.jsonld",
      "http://localhost:3001/api/schemas/v1/oecd/context.jsonld"
    ],
    "@type": "oecd:Incident",
    "@id": "https://oecd.ai/incident/OECD-2021-124",
    "incident_id": "OECD-2021-124",
    "title": "AI Personal Assistant Shares Private Information in Group Settings",
    "description": "A voice-activated AI assistant failed to recognize multi-user environments and shared personal calendar entries, medical reminders, and financial information when responding to queries in group settings.",
    "date": "2021-06-14",
    "aiSystem": {
      "@type": "oecd:AISystem",
      "name": "Consumer AI Platform Pro",
      "version": "9.13.86",
      "relation": [
        "oecd:ContributingFactor",
        "oecd:HumanError"
      ]
    },
    "developer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/MIT_Media_Lab",
      "name": "MIT Media Lab"
    },
    "deployer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/Boeing",
      "name": "Boeing"
    },
    "severity": "oecd:SeriousIncident",
    "harmType": [
      "oecd:ReputationalHarm",
      "oecd:HumanRightsHarm"
    ],
    "harmQuantification": {
      "@type": "oecd:HarmQuantification",
      "affected_stakeholders": "16621 individuals",
      "economic_losses": "$27.2 million"
    },
    "countries": [
      {
        "@type": "core:Country",
        "@id": "https://www.wikidata.org/wiki/Brazil",
        "name": "Brazil"
      }
    ],
    "affectedStakeholders": [
      {
        "@type": "core:Person",
        "@id": "https://example.org/entities/person/pedestrians",
        "name": "Pedestrians"
      },
      {
        "@type": "oecd:StakeholderGroup",
        "@id": "https://example.org/stakeholder-group/patients",
        "name": "Patients"
      }
    ],
    "businessFunction": [
      "oecd:CustomerService",
      "oecd:ICTManagement"
    ],
    "submitter": {
      "@type": "oecd:Submitter",
      "@id": "https://example.org/submitter/reporter",
      "role": "Safety Engineer",
      "affiliation": "Consumer Protection Agency",
      "stakeholderGroup": "I represent a government or regulatory body",
      "relationToIncident": "None of the above, but have partial or substantial knowledge of the incident (e.g. first-hand knowledge, research etc.)"
    },
    "unintendedUse": false
  },
  {
    "@context": [
      "http://localhost:3000/api/schemas/v1/core/context.jsonld",
      "http://localhost:3001/api/schemas/v1/oecd/context.jsonld"
    ],
    "@type": "oecd:Incident",
    "@id": "https://oecd.ai/incident/OECD-2021-125",
    "incident_id": "OECD-2021-125",
    "title": "Smart Home AI Creates Dangerous Living Conditions for Elderly",
    "description": "An AI-powered smart home system learned incorrect patterns from an elderly resident with dementia, subsequently creating dangerous conditions by adjusting heating, lighting, and security settings inappropriately.",
    "date": "2021-06-24",
    "aiSystem": {
      "@type": "oecd:AISystem",
      "name": "Consumer AI Solution Pro",
      "version": "8.10.40",
      "relation": [
        "oecd:DirectCause",
        "oecd:FailureToAct"
      ]
    },
    "developer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/Apple_Inc.",
      "name": "Apple"
    },
    "deployer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/Apple_Inc.",
      "name": "Apple"
    },
    "severity": "oecd:SeriousHazard",
    "harmType": [
      "oecd:PhysicalHarm",
      "oecd:PsychologicalHarm"
    ],
    "harmQuantification": {
      "@type": "oecd:HarmQuantification",
      "affected_stakeholders": "11566 patients",
      "psychological_impact": "Documented stress and anxiety in affected population"
    },
    "countries": [
      {
        "@type": "core:Country",
        "@id": "https://www.wikidata.org/wiki/France",
        "name": "France"
      },
      {
        "@type": "core:Country",
        "@id": "https://www.wikidata.org/wiki/Singapore",
        "name": "Singapore"
      }
    ],
    "affectedStakeholders": [
      {
        "@type": "core:Person",
        "@id": "https://example.org/entities/person/pedestrians",
        "name": "Pedestrians"
      },
      {
        "@type": "core:Person",
        "@id": "https://example.org/entities/person/motorists",
        "name": "Motorists"
      },
      {
        "@type": "oecd:StakeholderGroup",
        "@id": "https://example.org/stakeholder-group/consumers",
        "name": "Consumers"
      }
    ],
    "businessFunction": [
      "oecd:CustomerService",
      "oecd:OtherFunction"
    ],
    "submitter": {
      "@type": "oecd:Submitter",
      "@id": "https://example.org/submitter/reporter",
      "role": "Academic Researcher",
      "affiliation": "AI Safety Coalition",
      "stakeholderGroup": "I am an affected stakeholder",
      "relationToIncident": "None of the above, but have partial or substantial knowledge of the incident (e.g. first-hand knowledge, research etc.)"
    },
    "unintendedUse": false
  },
  {
    "@context": [
      "http://localhost:3000/api/schemas/v1/core/context.jsonld",
      "http://localhost:3001/api/schemas/v1/oecd/context.jsonld"
    ],
    "@type": "oecd:Incident",
    "@id": "https://oecd.ai/incident/OECD-2021-126",
    "incident_id": "OECD-2021-126",
    "title": "Surgical Robot Malfunction During Minimally Invasive Procedure",
    "description": "An AI-assisted surgical robot experienced a control system failure during a procedure, requiring emergency conversion to traditional surgery. The AI's motion planning algorithms failed to account for unexpected tissue resistance.",
    "date": "2021-07-08",
    "aiSystem": {
      "@type": "oecd:AISystem",
      "name": "Medical AI Engine",
      "version": "10.16.31",
      "relation": [
        "oecd:DirectCause",
        "oecd:ContributingFactor"
      ]
    },
    "developer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/The_DAO",
      "name": "The DAO"
    },
    "deployer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/Wikipedia",
      "name": "Wikipedia"
    },
    "severity": "oecd:SeriousIncident",
    "harmType": [
      "oecd:PhysicalHarm"
    ],
    "harmQuantification": {
      "@type": "oecd:HarmQuantification",
      "affected_stakeholders": "79363 users"
    },
    "countries": [
      {
        "@type": "core:Country",
        "@id": "https://www.wikidata.org/wiki/China",
        "name": "China"
      },
      {
        "@type": "core:Country",
        "@id": "https://www.wikidata.org/wiki/Germany",
        "name": "Germany"
      }
    ],
    "affectedStakeholders": [
      {
        "@type": "oecd:StakeholderGroup",
        "@id": "https://example.org/stakeholder-group/workers",
        "name": "Workers"
      }
    ],
    "businessFunction": [
      "oecd:OtherFunction"
    ],
    "submitter": {
      "@type": "oecd:Submitter",
      "@id": "https://example.org/submitter/reporter",
      "role": "Data Scientist",
      "affiliation": "AI Safety Coalition",
      "stakeholderGroup": "None of the above, but have partial or substantial knowledge of the incident",
      "relationToIncident": "None of the above, but have partial or substantial knowledge of the incident (e.g. first-hand knowledge, research etc.)"
    },
    "unintendedUse": true
  },
  {
    "@context": [
      "http://localhost:3000/api/schemas/v1/core/context.jsonld",
      "http://localhost:3001/api/schemas/v1/oecd/context.jsonld"
    ],
    "@type": "oecd:Incident",
    "@id": "https://oecd.ai/incident/OECD-2021-127",
    "incident_id": "OECD-2021-127",
    "title": "Algorithmic Trading System Triggers Market Manipulation Investigation",
    "description": "High-frequency trading algorithms were found to be creating artificial price movements through coordinated trades. The AI systems learned to exploit market microstructure in ways that resembled illegal manipulation.",
    "date": "2021-08-03",
    "aiSystem": {
      "@type": "oecd:AISystem",
      "name": "Financial AI Engine Pro",
      "version": "5.16.30",
      "relation": [
        "oecd:ContributingFactor",
        "oecd:HumanError"
      ]
    },
    "developer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/Starbucks",
      "name": "Starbucks"
    },
    "deployer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/Apple_Inc.",
      "name": "Apple"
    },
    "severity": "oecd:SeriousHazard",
    "harmType": [
      "oecd:EconomicHarm",
      "oecd:PublicInterestHarm"
    ],
    "harmQuantification": {
      "@type": "oecd:HarmQuantification",
      "affected_stakeholders": "57818 patients"
    },
    "countries": [
      {
        "@type": "core:Country",
        "@id": "https://www.wikidata.org/wiki/Singapore",
        "name": "Singapore"
      }
    ],
    "affectedStakeholders": [
      {
        "@type": "oecd:StakeholderGroup",
        "@id": "https://example.org/stakeholder-group/children",
        "name": "Children"
      },
      {
        "@type": "oecd:StakeholderGroup",
        "@id": "https://example.org/stakeholder-group/patients",
        "name": "Patients"
      },
      {
        "@type": "oecd:StakeholderGroup",
        "@id": "https://example.org/stakeholder-group/minority-groups",
        "name": "Minority Groups"
      }
    ],
    "businessFunction": [
      "oecd:OtherFunction"
    ],
    "submitter": {
      "@type": "oecd:Submitter",
      "@id": "https://example.org/submitter/reporter",
      "role": "Industry Whistleblower",
      "affiliation": "University Ethics Lab",
      "stakeholderGroup": "I am an affected stakeholder",
      "relationToIncident": "None of the above, but have partial or substantial knowledge of the incident (e.g. first-hand knowledge, research etc.)"
    },
    "unintendedUse": false
  },
  {
    "@context": [
      "http://localhost:3000/api/schemas/v1/core/context.jsonld",
      "http://localhost:3001/api/schemas/v1/oecd/context.jsonld"
    ],
    "@type": "oecd:Incident",
    "@id": "https://oecd.ai/incident/OECD-2021-128",
    "incident_id": "OECD-2021-128",
    "title": "Smart Home AI Creates Dangerous Living Conditions for Elderly",
    "description": "An AI-powered smart home system learned incorrect patterns from an elderly resident with dementia, subsequently creating dangerous conditions by adjusting heating, lighting, and security settings inappropriately.",
    "date": "2021-08-23",
    "aiSystem": {
      "@type": "oecd:AISystem",
      "name": "Consumer AI Solution",
      "version": "1.5.16",
      "relation": [
        "oecd:DirectCause"
      ]
    },
    "developer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/Tesla,_Inc.",
      "name": "Tesla"
    },
    "deployer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/Volkswagen",
      "name": "Volkswagen"
    },
    "severity": "oecd:SeriousHazard",
    "harmType": [
      "oecd:PhysicalHarm",
      "oecd:PsychologicalHarm"
    ],
    "harmQuantification": {
      "@type": "oecd:HarmQuantification",
      "affected_stakeholders": "774 patients",
      "economic_losses": "$10.3 million",
      "psychological_impact": "Documented stress and anxiety in affected population"
    },
    "countries": [
      {
        "@type": "core:Country",
        "@id": "https://www.wikidata.org/wiki/India",
        "name": "India"
      },
      {
        "@type": "core:Country",
        "@id": "https://www.wikidata.org/wiki/Australia",
        "name": "Australia"
      }
    ],
    "affectedStakeholders": [
      {
        "@type": "core:Person",
        "@id": "https://example.org/entities/person/motorists",
        "name": "Motorists"
      },
      {
        "@type": "oecd:StakeholderGroup",
        "@id": "https://example.org/stakeholder-group/minority-groups",
        "name": "Minority Groups"
      }
    ],
    "businessFunction": [
      "oecd:CustomerService",
      "oecd:OtherFunction"
    ],
    "submitter": {
      "@type": "oecd:Submitter",
      "@id": "https://example.org/submitter/reporter",
      "role": "Industry Whistleblower",
      "affiliation": "AI Safety Coalition",
      "stakeholderGroup": "I work or am affiliated to a public interest body or NGO",
      "relationToIncident": "None of the above, but have partial or substantial knowledge of the incident (e.g. first-hand knowledge, research etc.)"
    },
    "unintendedUse": false
  },
  {
    "@context": [
      "http://localhost:3000/api/schemas/v1/core/context.jsonld",
      "http://localhost:3001/api/schemas/v1/oecd/context.jsonld"
    ],
    "@type": "oecd:Incident",
    "@id": "https://oecd.ai/incident/OECD-2021-129",
    "incident_id": "OECD-2021-129",
    "title": "Predictive Policing Algorithm Creates Feedback Loops in Minority Neighborhoods",
    "description": "An AI system for predicting crime hotspots consistently directed more police presence to minority neighborhoods, creating a self-reinforcing cycle where increased police presence led to more reported incidents, further biasing the algorithm.",
    "date": "2021-09-13",
    "aiSystem": {
      "@type": "oecd:AISystem",
      "name": "Security/Surveillance Solution",
      "version": "10.5.9",
      "relation": [
        "oecd:DirectCause"
      ]
    },
    "developer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/MIT_Media_Lab",
      "name": "MIT Media Lab"
    },
    "deployer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/Navya_(company)",
      "name": "Navya"
    },
    "severity": "oecd:SeriousHazard",
    "harmType": [
      "oecd:HumanRightsHarm",
      "oecd:PsychologicalHarm"
    ],
    "harmQuantification": {
      "@type": "oecd:HarmQuantification",
      "affected_stakeholders": "31795 individuals",
      "economic_losses": "$40.4 million",
      "psychological_impact": "Documented stress and anxiety in affected population"
    },
    "countries": [
      {
        "@type": "core:Country",
        "@id": "https://www.wikidata.org/wiki/France",
        "name": "France"
      },
      {
        "@type": "core:Country",
        "@id": "https://www.wikidata.org/wiki/Brazil",
        "name": "Brazil"
      }
    ],
    "affectedStakeholders": [
      {
        "@type": "core:Person",
        "@id": "https://example.org/entities/person/job-applicants",
        "name": "Job applicants"
      },
      {
        "@type": "core:Person",
        "@id": "https://example.org/entities/person/airplane-passengers",
        "name": "Airplane Passengers"
      }
    ],
    "businessFunction": [
      "oecd:Compliance",
      "oecd:Planning"
    ],
    "submitter": {
      "@type": "oecd:Submitter",
      "@id": "https://example.org/submitter/reporter",
      "role": "Data Scientist",
      "affiliation": "Digital Rights Organization",
      "stakeholderGroup": "I work or am affiliated to a public interest body or NGO",
      "relationToIncident": "None of the above, but have partial or substantial knowledge of the incident (e.g. first-hand knowledge, research etc.)"
    },
    "unintendedUse": false
  },
  {
    "@context": [
      "http://localhost:3000/api/schemas/v1/core/context.jsonld",
      "http://localhost:3001/api/schemas/v1/oecd/context.jsonld"
    ],
    "@type": "oecd:Incident",
    "@id": "https://oecd.ai/incident/OECD-2021-130",
    "incident_id": "OECD-2021-130",
    "title": "AI System Failure Related to Black Uber Eats Driver Allegedly Subjected to Excessive Photo Checks and Dismissed via FRT Results",
    "description": "An AI system failure occurred with similar characteristics to the documented incident involving Uber Eats. The system exhibited comparable failure modes resulting in harm to affected stakeholders.",
    "date": "2021-10-23",
    "aiSystem": {
      "@type": "oecd:AISystem",
      "name": "Smart Platform",
      "version": "4.4",
      "relation": [
        "oecd:DirectCause"
      ]
    },
    "developer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/Uber_Eats",
      "name": "Uber Eats"
    },
    "deployer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/Uber_Eats",
      "name": "Uber Eats"
    },
    "severity": "oecd:SeriousIncident",
    "harmType": [
      "oecd:OtherHarm"
    ],
    "harmQuantification": {
      "@type": "oecd:HarmQuantification",
      "affected_stakeholders": "43743 individuals"
    },
    "countries": [
      {
        "@type": "core:Country",
        "@id": "https://www.wikidata.org/wiki/Canada",
        "name": "Canada"
      },
      {
        "@type": "core:Country",
        "@id": "https://www.wikidata.org/wiki/Italy",
        "name": "Italy"
      },
      {
        "@type": "core:Country",
        "@id": "https://www.wikidata.org/wiki/United_States",
        "name": "United States"
      }
    ],
    "affectedStakeholders": [
      {
        "@type": "core:Person",
        "@id": "https://example.org/entities/person/uber-eats-black-delivery-drivers",
        "name": "Uber Eats Black delivery drivers"
      },
      {
        "@type": "core:Person",
        "@id": "https://example.org/entities/person/pa-edrissa-manjang",
        "name": "Pa Edrissa Manjang"
      }
    ],
    "businessFunction": [
      "oecd:HRManagement",
      "oecd:Marketing"
    ],
    "submitter": {
      "@type": "oecd:Submitter",
      "@id": "https://example.org/submitter/submitter",
      "role": "Industry Analyst",
      "affiliation": "University Research Lab",
      "stakeholderGroup": "None of the above, but have partial or substantial knowledge of the incident",
      "relationToIncident": "I am a user of the related AI system"
    },
    "unintendedUse": true,
    "sameAs": "https://incidentdatabase.ai/cite/265"
  },
  {
    "@context": [
      "http://localhost:3000/api/schemas/v1/core/context.jsonld",
      "http://localhost:3001/api/schemas/v1/oecd/context.jsonld"
    ],
    "@type": "oecd:Incident",
    "@id": "https://oecd.ai/incident/OECD-2021-131",
    "incident_id": "OECD-2021-131",
    "title": "AI Diagnostic System Misses Critical Symptoms in Emergency Department",
    "description": "An AI triage system in emergency departments failed to identify critical symptoms in patients presenting with atypical manifestations of serious conditions. The system's training data lacked diversity in symptom presentations across different demographics.",
    "date": "2021-12-08",
    "aiSystem": {
      "@type": "oecd:AISystem",
      "name": "Medical AI System",
      "version": "10.2.17",
      "relation": [
        "oecd:ContributingFactor",
        "oecd:HumanError"
      ]
    },
    "developer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/Apple_Inc.",
      "name": "Apple"
    },
    "deployer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/LinkedIn",
      "name": "LinkedIn"
    },
    "severity": "oecd:SeriousHazard",
    "harmType": [
      "oecd:PhysicalHarm",
      "oecd:HumanRightsHarm"
    ],
    "harmQuantification": {
      "@type": "oecd:HarmQuantification",
      "affected_stakeholders": "23712 customers"
    },
    "countries": [
      {
        "@type": "core:Country",
        "@id": "https://www.wikidata.org/wiki/Norway",
        "name": "Norway"
      }
    ],
    "affectedStakeholders": [
      {
        "@type": "oecd:StakeholderGroup",
        "@id": "https://example.org/stakeholder-group/patients",
        "name": "Patients"
      },
      {
        "@type": "oecd:StakeholderGroup",
        "@id": "https://example.org/stakeholder-group/consumers",
        "name": "Consumers"
      }
    ],
    "businessFunction": [
      "oecd:OtherFunction"
    ],
    "submitter": {
      "@type": "oecd:Submitter",
      "@id": "https://example.org/submitter/reporter",
      "role": "Government Auditor",
      "affiliation": "Digital Rights Organization",
      "stakeholderGroup": "I work or am affiliated to a public interest body or NGO",
      "relationToIncident": "None of the above, but have partial or substantial knowledge of the incident (e.g. first-hand knowledge, research etc.)"
    },
    "unintendedUse": false
  },
  {
    "@context": [
      "http://localhost:3000/api/schemas/v1/core/context.jsonld",
      "http://localhost:3001/api/schemas/v1/oecd/context.jsonld"
    ],
    "@type": "oecd:Incident",
    "@id": "https://oecd.ai/incident/OECD-2021-132",
    "incident_id": "OECD-2021-132",
    "title": "AI System Failure Related to Black Uber Eats Driver Allegedly Subjected to Excessive Photo Checks and Dismissed via FRT Results",
    "description": "An AI system failure occurred with similar characteristics to the documented incident involving Uber Eats. The system exhibited comparable failure modes resulting in harm to affected stakeholders.",
    "date": "2021-12-24",
    "aiSystem": {
      "@type": "oecd:AISystem",
      "name": "Smart Solution",
      "version": "2.8",
      "relation": [
        "oecd:DirectCause"
      ]
    },
    "developer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/Uber_Eats",
      "name": "Uber Eats"
    },
    "deployer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/Uber_Eats",
      "name": "Uber Eats"
    },
    "severity": "oecd:SeriousIncident",
    "harmType": [
      "oecd:OtherHarm"
    ],
    "harmQuantification": {
      "@type": "oecd:HarmQuantification",
      "affected_stakeholders": "7975 individuals",
      "economic_losses": "$6 million"
    },
    "countries": [
      {
        "@type": "core:Country",
        "@id": "https://www.wikidata.org/wiki/Norway",
        "name": "Norway"
      }
    ],
    "affectedStakeholders": [
      {
        "@type": "core:Person",
        "@id": "https://example.org/entities/person/uber-eats-black-delivery-drivers",
        "name": "Uber Eats Black delivery drivers"
      },
      {
        "@type": "core:Person",
        "@id": "https://example.org/entities/person/pa-edrissa-manjang",
        "name": "Pa Edrissa Manjang"
      }
    ],
    "businessFunction": [
      "oecd:Sales",
      "oecd:Procurement"
    ],
    "submitter": {
      "@type": "oecd:Submitter",
      "@id": "https://example.org/submitter/submitter",
      "role": "AI Safety Researcher",
      "affiliation": "Government Oversight Committee",
      "stakeholderGroup": "I represent a government or regulatory body",
      "relationToIncident": "I am an affected stakeholder"
    },
    "unintendedUse": false,
    "sameAs": "https://incidentdatabase.ai/cite/265"
  },
  {
    "@context": [
      "http://localhost:3000/api/schemas/v1/core/context.jsonld",
      "http://localhost:3001/api/schemas/v1/oecd/context.jsonld"
    ],
    "@type": "oecd:Incident",
    "@id": "https://oecd.ai/incident/OECD-2022-133",
    "incident_id": "OECD-2022-133",
    "title": "Surgical Robot Malfunction During Minimally Invasive Procedure",
    "description": "An AI-assisted surgical robot experienced a control system failure during a procedure, requiring emergency conversion to traditional surgery. The AI's motion planning algorithms failed to account for unexpected tissue resistance.",
    "date": "2022-02-07",
    "aiSystem": {
      "@type": "oecd:AISystem",
      "name": "Medical AI Engine Pro",
      "version": "9.12.16",
      "relation": [
        "oecd:ContributingFactor",
        "oecd:HumanError"
      ]
    },
    "developer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/University_of_Washington",
      "name": "University of Washington"
    },
    "deployer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/Apple_Inc.",
      "name": "Apple"
    },
    "severity": "oecd:SeriousIncident",
    "harmType": [
      "oecd:PhysicalHarm"
    ],
    "harmQuantification": {
      "@type": "oecd:HarmQuantification",
      "affected_stakeholders": "16711 patients"
    },
    "countries": [
      {
        "@type": "core:Country",
        "@id": "https://www.wikidata.org/wiki/Mexico",
        "name": "Mexico"
      }
    ],
    "affectedStakeholders": [
      {
        "@type": "core:Person",
        "@id": "https://example.org/entities/person/medical-residents",
        "name": "Medical Residents"
      },
      {
        "@type": "core:Person",
        "@id": "https://example.org/entities/person/job-applicants",
        "name": "Job applicants"
      },
      {
        "@type": "core:Person",
        "@id": "https://example.org/entities/person/motorists",
        "name": "Motorists"
      }
    ],
    "businessFunction": [
      "oecd:OtherFunction"
    ],
    "submitter": {
      "@type": "oecd:Submitter",
      "@id": "https://example.org/submitter/reporter",
      "role": "Safety Engineer",
      "affiliation": "University Ethics Lab",
      "stakeholderGroup": "I work or am affiliated to a public interest body or NGO",
      "relationToIncident": "None of the above, but have partial or substantial knowledge of the incident (e.g. first-hand knowledge, research etc.)"
    },
    "unintendedUse": false
  },
  {
    "@context": [
      "http://localhost:3000/api/schemas/v1/core/context.jsonld",
      "http://localhost:3001/api/schemas/v1/oecd/context.jsonld"
    ],
    "@type": "oecd:Incident",
    "@id": "https://oecd.ai/incident/OECD-2022-134",
    "incident_id": "OECD-2022-134",
    "title": "AI Credit Scoring System Discriminates Against Recent Immigrants",
    "description": "An automated credit scoring system systematically assigned lower credit scores to recent immigrants despite strong financial indicators. The AI model heavily weighted credit history length, creating unfair barriers to financial services.",
    "date": "2022-02-11",
    "aiSystem": {
      "@type": "oecd:AISystem",
      "name": "Financial AI System",
      "version": "7.18.55",
      "relation": [
        "oecd:ContributingFactor",
        "oecd:HumanError"
      ]
    },
    "developer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/Google",
      "name": "Google"
    },
    "deployer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/Boeing",
      "name": "Boeing"
    },
    "severity": "oecd:SeriousIncident",
    "harmType": [
      "oecd:EconomicHarm",
      "oecd:HumanRightsHarm"
    ],
    "harmQuantification": {
      "@type": "oecd:HarmQuantification",
      "affected_stakeholders": "17353 individuals"
    },
    "countries": [
      {
        "@type": "core:Country",
        "@id": "https://www.wikidata.org/wiki/Netherlands",
        "name": "Netherlands"
      }
    ],
    "affectedStakeholders": [
      {
        "@type": "oecd:StakeholderGroup",
        "@id": "https://example.org/stakeholder-group/minority-groups",
        "name": "Minority Groups"
      },
      {
        "@type": "oecd:StakeholderGroup",
        "@id": "https://example.org/stakeholder-group/consumers",
        "name": "Consumers"
      },
      {
        "@type": "oecd:StakeholderGroup",
        "@id": "https://example.org/stakeholder-group/workers",
        "name": "Workers"
      }
    ],
    "businessFunction": [
      "oecd:OtherFunction"
    ],
    "submitter": {
      "@type": "oecd:Submitter",
      "@id": "https://example.org/submitter/reporter",
      "role": "Academic Researcher",
      "affiliation": "Consumer Protection Agency",
      "stakeholderGroup": "I represent a government or regulatory body",
      "relationToIncident": "None of the above, but have partial or substantial knowledge of the incident (e.g. first-hand knowledge, research etc.)"
    },
    "unintendedUse": false
  },
  {
    "@context": [
      "http://localhost:3000/api/schemas/v1/core/context.jsonld",
      "http://localhost:3001/api/schemas/v1/oecd/context.jsonld"
    ],
    "@type": "oecd:Incident",
    "@id": "https://oecd.ai/incident/OECD-2022-135",
    "incident_id": "OECD-2022-135",
    "title": "AI System Failure Related to AI translation is jeopardizing Afghan asylum claims",
    "description": "An AI system failure occurred with similar characteristics to the documented incident involving US Citizenship and Immigration Services. The system exhibited comparable failure modes resulting in harm to affected stakeholders.",
    "date": "2022-02-17",
    "aiSystem": {
      "@type": "oecd:AISystem",
      "name": "Intelligent Engine",
      "version": "4.1",
      "relation": [
        "oecd:DirectCause"
      ]
    },
    "developer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/US_Citizenship_and_Immigration_Services",
      "name": "US Citizenship and Immigration Services"
    },
    "deployer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/US_Citizenship_and_Immigration_Services",
      "name": "US Citizenship and Immigration Services"
    },
    "severity": "oecd:SeriousIncident",
    "harmType": [
      "oecd:OtherHarm"
    ],
    "harmQuantification": {
      "@type": "oecd:HarmQuantification",
      "affected_stakeholders": "15416 individuals"
    },
    "countries": [
      {
        "@type": "core:Country",
        "@id": "https://www.wikidata.org/wiki/Netherlands",
        "name": "Netherlands"
      }
    ],
    "affectedStakeholders": [
      {
        "@type": "core:Person",
        "@id": "https://example.org/entities/person/pashto-speaking-asylum-seekers",
        "name": "Pashto-speaking asylum seekers"
      },
      {
        "@type": "core:Person",
        "@id": "https://example.org/entities/person/dari-speaking-asylum-seekers",
        "name": "Dari-speaking asylum seekers"
      },
      {
        "@type": "core:Person",
        "@id": "https://example.org/entities/person/anonymous-pashto-speaking-refugee",
        "name": "anonymous Pashto-speaking refugee"
      }
    ],
    "businessFunction": [
      "oecd:QualityControl"
    ],
    "submitter": {
      "@type": "oecd:Submitter",
      "@id": "https://example.org/submitter/submitter",
      "role": "AI Safety Researcher",
      "affiliation": "AI Safety Institute",
      "stakeholderGroup": "I represent a government or regulatory body",
      "relationToIncident": "I am an affected stakeholder"
    },
    "unintendedUse": true,
    "sameAs": "https://incidentdatabase.ai/cite/532"
  },
  {
    "@context": [
      "http://localhost:3000/api/schemas/v1/core/context.jsonld",
      "http://localhost:3001/api/schemas/v1/oecd/context.jsonld"
    ],
    "@type": "oecd:Incident",
    "@id": "https://oecd.ai/incident/OECD-2022-136",
    "incident_id": "OECD-2022-136",
    "title": "Predictive Policing Algorithm Creates Feedback Loops in Minority Neighborhoods",
    "description": "An AI system for predicting crime hotspots consistently directed more police presence to minority neighborhoods, creating a self-reinforcing cycle where increased police presence led to more reported incidents, further biasing the algorithm.",
    "date": "2022-02-21",
    "aiSystem": {
      "@type": "oecd:AISystem",
      "name": "Security/Surveillance System Pro",
      "version": "2.9.49",
      "relation": [
        "oecd:DirectCause"
      ]
    },
    "developer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/USC_Information_Sciences_Institute",
      "name": "USC Information Sciences Institute"
    },
    "deployer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/Google",
      "name": "Google"
    },
    "severity": "oecd:SeriousHazard",
    "harmType": [
      "oecd:HumanRightsHarm",
      "oecd:PsychologicalHarm"
    ],
    "harmQuantification": {
      "@type": "oecd:HarmQuantification",
      "affected_stakeholders": "16004 patients",
      "economic_losses": "$11.8 million",
      "psychological_impact": "Documented stress and anxiety in affected population"
    },
    "countries": [
      {
        "@type": "core:Country",
        "@id": "https://www.wikidata.org/wiki/United_Kingdom",
        "name": "United Kingdom"
      },
      {
        "@type": "core:Country",
        "@id": "https://www.wikidata.org/wiki/France",
        "name": "France"
      }
    ],
    "affectedStakeholders": [
      {
        "@type": "oecd:StakeholderGroup",
        "@id": "https://example.org/stakeholder-group/minority-groups",
        "name": "Minority Groups"
      }
    ],
    "businessFunction": [
      "oecd:Compliance",
      "oecd:Planning"
    ],
    "submitter": {
      "@type": "oecd:Submitter",
      "@id": "https://example.org/submitter/reporter",
      "role": "Consumer Advocate",
      "affiliation": "Tech Accountability Project",
      "stakeholderGroup": "I work or am affiliated to a public interest body or NGO",
      "relationToIncident": "None of the above, but have partial or substantial knowledge of the incident (e.g. first-hand knowledge, research etc.)"
    },
    "unintendedUse": false
  },
  {
    "@context": [
      "http://localhost:3000/api/schemas/v1/core/context.jsonld",
      "http://localhost:3001/api/schemas/v1/oecd/context.jsonld"
    ],
    "@type": "oecd:Incident",
    "@id": "https://oecd.ai/incident/OECD-2022-137",
    "incident_id": "OECD-2022-137",
    "title": "Smart Home AI Creates Dangerous Living Conditions for Elderly",
    "description": "An AI-powered smart home system learned incorrect patterns from an elderly resident with dementia, subsequently creating dangerous conditions by adjusting heating, lighting, and security settings inappropriately.",
    "date": "2022-03-03",
    "aiSystem": {
      "@type": "oecd:AISystem",
      "name": "Consumer AI Engine",
      "version": "6.2.30",
      "relation": [
        "oecd:DirectCause",
        "oecd:FailureToAct"
      ]
    },
    "developer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/Nest_Labs",
      "name": "Nest Labs"
    },
    "deployer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/Delhi_Metro_Rail_Corporation",
      "name": "Delhi Metro Rail Corporation"
    },
    "severity": "oecd:SeriousHazard",
    "harmType": [
      "oecd:PhysicalHarm",
      "oecd:PsychologicalHarm"
    ],
    "harmQuantification": {
      "@type": "oecd:HarmQuantification",
      "affected_stakeholders": "76725 workers",
      "psychological_impact": "Documented stress and anxiety in affected population"
    },
    "countries": [
      {
        "@type": "core:Country",
        "@id": "https://www.wikidata.org/wiki/United_States",
        "name": "United States"
      },
      {
        "@type": "core:Country",
        "@id": "https://www.wikidata.org/wiki/India",
        "name": "India"
      }
    ],
    "affectedStakeholders": [
      {
        "@type": "core:Person",
        "@id": "https://example.org/entities/person/black-people",
        "name": "Black people"
      }
    ],
    "businessFunction": [
      "oecd:CustomerService",
      "oecd:OtherFunction"
    ],
    "submitter": {
      "@type": "oecd:Submitter",
      "@id": "https://example.org/submitter/reporter",
      "role": "Academic Researcher",
      "affiliation": "Consumer Protection Agency",
      "stakeholderGroup": "I work or am affiliated to a public interest body or NGO",
      "relationToIncident": "None of the above, but have partial or substantial knowledge of the incident (e.g. first-hand knowledge, research etc.)"
    },
    "unintendedUse": false
  },
  {
    "@context": [
      "http://localhost:3000/api/schemas/v1/core/context.jsonld",
      "http://localhost:3001/api/schemas/v1/oecd/context.jsonld"
    ],
    "@type": "oecd:Incident",
    "@id": "https://oecd.ai/incident/OECD-2022-138",
    "incident_id": "OECD-2022-138",
    "title": "AI System Failure Related to Starship’s Autonomous Food Delivery Robot Allegedly Stranded at Railroad Crossing in Oregon, Run over by Freight Train",
    "description": "An AI system failure occurred with similar characteristics to the documented incident involving Oregon State University. The system exhibited comparable failure modes resulting in harm to affected stakeholders.",
    "date": "2022-03-05",
    "aiSystem": {
      "@type": "oecd:AISystem",
      "name": "Automated Solution",
      "version": "2.5",
      "relation": [
        "oecd:DirectCause"
      ]
    },
    "developer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/Oregon_State_University",
      "name": "Oregon State University"
    },
    "deployer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/Oregon_State_University",
      "name": "Oregon State University"
    },
    "severity": "oecd:SeriousIncident",
    "harmType": [
      "oecd:OtherHarm"
    ],
    "harmQuantification": {
      "@type": "oecd:HarmQuantification",
      "affected_stakeholders": "48388 individuals"
    },
    "countries": [
      {
        "@type": "core:Country",
        "@id": "https://www.wikidata.org/wiki/Netherlands",
        "name": "Netherlands"
      },
      {
        "@type": "core:Country",
        "@id": "https://www.wikidata.org/wiki/France",
        "name": "France"
      }
    ],
    "affectedStakeholders": [
      {
        "@type": "core:Person",
        "@id": "https://example.org/entities/person/oregon-state-university",
        "name": "Oregon State University"
      },
      {
        "@type": "core:Person",
        "@id": "https://example.org/entities/person/freight-train-crew",
        "name": "freight train crew"
      }
    ],
    "businessFunction": [
      "oecd:Marketing"
    ],
    "submitter": {
      "@type": "oecd:Submitter",
      "@id": "https://example.org/submitter/submitter",
      "role": "AI Safety Researcher",
      "affiliation": "Tech Policy Center",
      "stakeholderGroup": "None of the above, but have partial or substantial knowledge of the incident",
      "relationToIncident": "I am an affected stakeholder"
    },
    "unintendedUse": true,
    "sameAs": "https://incidentdatabase.ai/cite/176"
  },
  {
    "@context": [
      "http://localhost:3000/api/schemas/v1/core/context.jsonld",
      "http://localhost:3001/api/schemas/v1/oecd/context.jsonld"
    ],
    "@type": "oecd:Incident",
    "@id": "https://oecd.ai/incident/OECD-2022-139",
    "incident_id": "OECD-2022-139",
    "title": "AI Diagnostic System Misses Critical Symptoms in Emergency Department",
    "description": "An AI triage system in emergency departments failed to identify critical symptoms in patients presenting with atypical manifestations of serious conditions. The system's training data lacked diversity in symptom presentations across different demographics.",
    "date": "2022-03-14",
    "aiSystem": {
      "@type": "oecd:AISystem",
      "name": "Medical AI System Pro",
      "version": "10.10.36",
      "relation": [
        "oecd:DirectCause",
        "oecd:FailureToAct"
      ]
    },
    "developer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/Keolis",
      "name": "Keolis North America"
    },
    "deployer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/Google",
      "name": "Google"
    },
    "severity": "oecd:SeriousHazard",
    "harmType": [
      "oecd:PhysicalHarm",
      "oecd:HumanRightsHarm"
    ],
    "harmQuantification": {
      "@type": "oecd:HarmQuantification",
      "affected_stakeholders": "63327 individuals",
      "economic_losses": "$3.0 million"
    },
    "countries": [
      {
        "@type": "core:Country",
        "@id": "https://www.wikidata.org/wiki/Canada",
        "name": "Canada"
      },
      {
        "@type": "core:Country",
        "@id": "https://www.wikidata.org/wiki/Singapore",
        "name": "Singapore"
      }
    ],
    "affectedStakeholders": [
      {
        "@type": "core:Person",
        "@id": "https://example.org/entities/person/motorists",
        "name": "Motorists"
      },
      {
        "@type": "oecd:StakeholderGroup",
        "@id": "https://example.org/stakeholder-group/consumers",
        "name": "Consumers"
      },
      {
        "@type": "core:Person",
        "@id": "https://example.org/entities/person/bus-passengers",
        "name": "Bus passengers"
      }
    ],
    "businessFunction": [
      "oecd:OtherFunction"
    ],
    "submitter": {
      "@type": "oecd:Submitter",
      "@id": "https://example.org/submitter/reporter",
      "role": "Government Auditor",
      "affiliation": "University Ethics Lab",
      "stakeholderGroup": "I work or am affiliated to a public interest body or NGO",
      "relationToIncident": "None of the above, but have partial or substantial knowledge of the incident (e.g. first-hand knowledge, research etc.)"
    },
    "unintendedUse": false
  },
  {
    "@context": [
      "http://localhost:3000/api/schemas/v1/core/context.jsonld",
      "http://localhost:3001/api/schemas/v1/oecd/context.jsonld"
    ],
    "@type": "oecd:Incident",
    "@id": "https://oecd.ai/incident/OECD-2022-140",
    "incident_id": "OECD-2022-140",
    "title": "AI System Failure Related to Fake LinkedIn Profiles Created Using GAN Photos",
    "description": "An AI system failure occurred with similar characteristics to the documented incident involving unknown. The system exhibited comparable failure modes resulting in harm to affected stakeholders.",
    "date": "2022-04-02",
    "aiSystem": {
      "@type": "oecd:AISystem",
      "name": "AI Solution",
      "version": "1.1",
      "relation": [
        "oecd:DirectCause"
      ]
    },
    "developer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/unknown",
      "name": "unknown"
    },
    "deployer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/unknown",
      "name": "unknown"
    },
    "severity": "oecd:SeriousIncident",
    "harmType": [
      "oecd:OtherHarm"
    ],
    "harmQuantification": {
      "@type": "oecd:HarmQuantification",
      "affected_stakeholders": "7005 individuals"
    },
    "countries": [
      {
        "@type": "core:Country",
        "@id": "https://www.wikidata.org/wiki/Sweden",
        "name": "Sweden"
      },
      {
        "@type": "core:Country",
        "@id": "https://www.wikidata.org/wiki/United_States",
        "name": "United States"
      },
      {
        "@type": "core:Country",
        "@id": "https://www.wikidata.org/wiki/United_Kingdom",
        "name": "United Kingdom"
      }
    ],
    "affectedStakeholders": [
      {
        "@type": "oecd:StakeholderGroup",
        "@id": "https://example.org/stakeholder-group/linkedin-users",
        "name": "LinkedIn users"
      }
    ],
    "businessFunction": [
      "oecd:ResearchDevelopment",
      "oecd:HRManagement"
    ],
    "submitter": {
      "@type": "oecd:Submitter",
      "@id": "https://example.org/submitter/submitter",
      "role": "Government Inspector",
      "affiliation": "Tech Policy Center",
      "stakeholderGroup": "None of the above, but have partial or substantial knowledge of the incident",
      "relationToIncident": "I am an affected stakeholder"
    },
    "unintendedUse": true,
    "sameAs": "https://incidentdatabase.ai/cite/174"
  },
  {
    "@context": [
      "http://localhost:3000/api/schemas/v1/core/context.jsonld",
      "http://localhost:3001/api/schemas/v1/oecd/context.jsonld"
    ],
    "@type": "oecd:Incident",
    "@id": "https://oecd.ai/incident/OECD-2022-141",
    "incident_id": "OECD-2022-141",
    "title": "AI Diagnostic System Misses Critical Symptoms in Emergency Department",
    "description": "An AI triage system in emergency departments failed to identify critical symptoms in patients presenting with atypical manifestations of serious conditions. The system's training data lacked diversity in symptom presentations across different demographics.",
    "date": "2022-04-02",
    "aiSystem": {
      "@type": "oecd:AISystem",
      "name": "Medical AI System Pro",
      "version": "6.7.17",
      "relation": [
        "oecd:DirectCause",
        "oecd:ContributingFactor"
      ]
    },
    "developer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/Doctors",
      "name": "Doctors"
    },
    "deployer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/LinkedIn",
      "name": "LinkedIn"
    },
    "severity": "oecd:SeriousHazard",
    "harmType": [
      "oecd:PhysicalHarm",
      "oecd:HumanRightsHarm"
    ],
    "harmQuantification": {
      "@type": "oecd:HarmQuantification",
      "affected_stakeholders": "22063 customers",
      "economic_losses": "$12.7 million"
    },
    "countries": [
      {
        "@type": "core:Country",
        "@id": "https://www.wikidata.org/wiki/Mexico",
        "name": "Mexico"
      }
    ],
    "affectedStakeholders": [
      {
        "@type": "oecd:StakeholderGroup",
        "@id": "https://example.org/stakeholder-group/students",
        "name": "Students"
      },
      {
        "@type": "core:Person",
        "@id": "https://example.org/entities/person/bus-passengers",
        "name": "Bus passengers"
      },
      {
        "@type": "oecd:StakeholderGroup",
        "@id": "https://example.org/stakeholder-group/children",
        "name": "Children"
      }
    ],
    "businessFunction": [
      "oecd:OtherFunction"
    ],
    "submitter": {
      "@type": "oecd:Submitter",
      "@id": "https://example.org/submitter/reporter",
      "role": "Consumer Advocate",
      "affiliation": "AI Safety Coalition",
      "stakeholderGroup": "I am an affected stakeholder",
      "relationToIncident": "None of the above, but have partial or substantial knowledge of the incident (e.g. first-hand knowledge, research etc.)"
    },
    "unintendedUse": false
  },
  {
    "@context": [
      "http://localhost:3000/api/schemas/v1/core/context.jsonld",
      "http://localhost:3001/api/schemas/v1/oecd/context.jsonld"
    ],
    "@type": "oecd:Incident",
    "@id": "https://oecd.ai/incident/OECD-2022-142",
    "incident_id": "OECD-2022-142",
    "title": "Agricultural AI Misidentifies Crops Leading to Herbicide Damage",
    "description": "An AI-powered crop monitoring and treatment system misidentified valuable crops as weeds, resulting in herbicide application that destroyed thousands of acres of produce. The computer vision model was not properly validated for the specific crop varieties.",
    "date": "2022-04-30",
    "aiSystem": {
      "@type": "oecd:AISystem",
      "name": "Autonomous Systems Platform",
      "version": "7.16.70",
      "relation": [
        "oecd:ContributingFactor",
        "oecd:HumanError"
      ]
    },
    "developer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/Google",
      "name": "Google"
    },
    "deployer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/Volkswagen",
      "name": "Volkswagen"
    },
    "severity": "oecd:SeriousIncident",
    "harmType": [
      "oecd:EconomicHarm",
      "oecd:EnvironmentalHarm"
    ],
    "harmQuantification": {
      "@type": "oecd:HarmQuantification",
      "affected_stakeholders": "57456 patients"
    },
    "countries": [
      {
        "@type": "core:Country",
        "@id": "https://www.wikidata.org/wiki/Italy",
        "name": "Italy"
      }
    ],
    "affectedStakeholders": [
      {
        "@type": "core:Person",
        "@id": "https://example.org/entities/person/pedestrians",
        "name": "Pedestrians"
      },
      {
        "@type": "oecd:StakeholderGroup",
        "@id": "https://example.org/stakeholder-group/students",
        "name": "Students"
      },
      {
        "@type": "oecd:StakeholderGroup",
        "@id": "https://example.org/stakeholder-group/minority-groups",
        "name": "Minority Groups"
      }
    ],
    "businessFunction": [
      "oecd:Production",
      "oecd:OtherFunction"
    ],
    "submitter": {
      "@type": "oecd:Submitter",
      "@id": "https://example.org/submitter/reporter",
      "role": "Safety Engineer",
      "affiliation": "AI Safety Coalition",
      "stakeholderGroup": "None of the above, but have partial or substantial knowledge of the incident",
      "relationToIncident": "None of the above, but have partial or substantial knowledge of the incident (e.g. first-hand knowledge, research etc.)"
    },
    "unintendedUse": false
  },
  {
    "@context": [
      "http://localhost:3000/api/schemas/v1/core/context.jsonld",
      "http://localhost:3001/api/schemas/v1/oecd/context.jsonld"
    ],
    "@type": "oecd:Incident",
    "@id": "https://oecd.ai/incident/OECD-2022-143",
    "incident_id": "OECD-2022-143",
    "title": "Surgical Robot Malfunction During Minimally Invasive Procedure",
    "description": "An AI-assisted surgical robot experienced a control system failure during a procedure, requiring emergency conversion to traditional surgery. The AI's motion planning algorithms failed to account for unexpected tissue resistance.",
    "date": "2022-06-04",
    "aiSystem": {
      "@type": "oecd:AISystem",
      "name": "Medical AI System",
      "version": "10.12.9",
      "relation": [
        "oecd:DirectCause",
        "oecd:FailureToAct"
      ]
    },
    "developer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/Delphi_Technologies",
      "name": "Delphi Technologies"
    },
    "deployer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/Delhi_Metro_Rail_Corporation",
      "name": "Delhi Metro Rail Corporation"
    },
    "severity": "oecd:SeriousIncident",
    "harmType": [
      "oecd:PhysicalHarm"
    ],
    "harmQuantification": {
      "@type": "oecd:HarmQuantification",
      "affected_stakeholders": "1533 workers",
      "economic_losses": "$3.5 million"
    },
    "countries": [
      {
        "@type": "core:Country",
        "@id": "https://www.wikidata.org/wiki/United_States",
        "name": "United States"
      }
    ],
    "affectedStakeholders": [
      {
        "@type": "oecd:StakeholderGroup",
        "@id": "https://example.org/stakeholder-group/minority-groups",
        "name": "Minority Groups"
      }
    ],
    "businessFunction": [
      "oecd:OtherFunction"
    ],
    "submitter": {
      "@type": "oecd:Submitter",
      "@id": "https://example.org/submitter/reporter",
      "role": "Government Auditor",
      "affiliation": "Tech Accountability Project",
      "stakeholderGroup": "I am an affected stakeholder",
      "relationToIncident": "None of the above, but have partial or substantial knowledge of the incident (e.g. first-hand knowledge, research etc.)"
    },
    "unintendedUse": false
  },
  {
    "@context": [
      "http://localhost:3000/api/schemas/v1/core/context.jsonld",
      "http://localhost:3001/api/schemas/v1/oecd/context.jsonld"
    ],
    "@type": "oecd:Incident",
    "@id": "https://oecd.ai/incident/OECD-2022-144",
    "incident_id": "OECD-2022-144",
    "title": "Delivery Robot Swarm Blocks Emergency Vehicle Access",
    "description": "A fleet of autonomous delivery robots failed to coordinate their movements during an emergency, blocking paramedic access to a medical emergency. The swarm intelligence system lacked proper emergency vehicle detection and response protocols.",
    "date": "2022-06-08",
    "aiSystem": {
      "@type": "oecd:AISystem",
      "name": "Autonomous Systems Solution",
      "version": "5.15.28",
      "relation": [
        "oecd:ContributingFactor",
        "oecd:HumanError"
      ]
    },
    "developer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/USC_Information_Sciences_Institute",
      "name": "USC Information Sciences Institute"
    },
    "deployer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/Tesla,_Inc.",
      "name": "Tesla"
    },
    "severity": "oecd:SeriousHazard",
    "harmType": [
      "oecd:PhysicalHarm",
      "oecd:PublicInterestHarm"
    ],
    "harmQuantification": {
      "@type": "oecd:HarmQuantification",
      "affected_stakeholders": "76166 patients",
      "economic_losses": "$24.9 million"
    },
    "countries": [
      {
        "@type": "core:Country",
        "@id": "https://www.wikidata.org/wiki/Germany",
        "name": "Germany"
      }
    ],
    "affectedStakeholders": [
      {
        "@type": "oecd:StakeholderGroup",
        "@id": "https://example.org/stakeholder-group/workers",
        "name": "Workers"
      }
    ],
    "businessFunction": [
      "oecd:Logistics",
      "oecd:OtherFunction"
    ],
    "submitter": {
      "@type": "oecd:Submitter",
      "@id": "https://example.org/submitter/reporter",
      "role": "Consumer Advocate",
      "affiliation": "Digital Rights Organization",
      "stakeholderGroup": "I am an affected stakeholder",
      "relationToIncident": "None of the above, but have partial or substantial knowledge of the incident (e.g. first-hand knowledge, research etc.)"
    },
    "unintendedUse": false
  },
  {
    "@context": [
      "http://localhost:3000/api/schemas/v1/core/context.jsonld",
      "http://localhost:3001/api/schemas/v1/oecd/context.jsonld"
    ],
    "@type": "oecd:Incident",
    "@id": "https://oecd.ai/incident/OECD-2022-145",
    "incident_id": "OECD-2022-145",
    "title": "AI System Failure Related to Stable Diffusion Abused by 4chan Users to Deepfake Celebrity Porn",
    "description": "An AI system failure occurred with similar characteristics to the documented incident involving Stability AI. The system exhibited comparable failure modes resulting in harm to affected stakeholders.",
    "date": "2022-06-20",
    "aiSystem": {
      "@type": "oecd:AISystem",
      "name": "Smart System",
      "version": "2.3",
      "relation": [
        "oecd:DirectCause"
      ]
    },
    "developer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/Stability_AI",
      "name": "Stability AI"
    },
    "deployer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/Stability_AI",
      "name": "Stability AI"
    },
    "severity": "oecd:SeriousIncident",
    "harmType": [
      "oecd:OtherHarm"
    ],
    "harmQuantification": {
      "@type": "oecd:HarmQuantification",
      "affected_stakeholders": "40619 individuals",
      "economic_losses": "$3 million"
    },
    "countries": [
      {
        "@type": "core:Country",
        "@id": "https://www.wikidata.org/wiki/Mexico",
        "name": "Mexico"
      },
      {
        "@type": "core:Country",
        "@id": "https://www.wikidata.org/wiki/France",
        "name": "France"
      }
    ],
    "affectedStakeholders": [
      {
        "@type": "core:Person",
        "@id": "https://example.org/entities/person/stability-ai",
        "name": "Stability AI"
      },
      {
        "@type": "core:Person",
        "@id": "https://example.org/entities/person/deepfaked-celebrities",
        "name": "deepfaked celebrities"
      }
    ],
    "businessFunction": [
      "oecd:Compliance",
      "oecd:QualityControl"
    ],
    "submitter": {
      "@type": "oecd:Submitter",
      "@id": "https://example.org/submitter/submitter",
      "role": "Academic Researcher",
      "affiliation": "Government Oversight Committee",
      "stakeholderGroup": "I represent a government or regulatory body",
      "relationToIncident": "None of the above, but have partial or substantial knowledge of the incident (e.g. first-hand knowledge, research etc.)"
    },
    "unintendedUse": false,
    "sameAs": "https://incidentdatabase.ai/cite/314"
  },
  {
    "@context": [
      "http://localhost:3000/api/schemas/v1/core/context.jsonld",
      "http://localhost:3001/api/schemas/v1/oecd/context.jsonld"
    ],
    "@type": "oecd:Incident",
    "@id": "https://oecd.ai/incident/OECD-2022-146",
    "incident_id": "OECD-2022-146",
    "title": "Predictive Policing Algorithm Creates Feedback Loops in Minority Neighborhoods",
    "description": "An AI system for predicting crime hotspots consistently directed more police presence to minority neighborhoods, creating a self-reinforcing cycle where increased police presence led to more reported incidents, further biasing the algorithm.",
    "date": "2022-06-29",
    "aiSystem": {
      "@type": "oecd:AISystem",
      "name": "Security/Surveillance Engine",
      "version": "6.9.11",
      "relation": [
        "oecd:DirectCause"
      ]
    },
    "developer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/Nest_Labs",
      "name": "Nest Labs"
    },
    "deployer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/Boeing",
      "name": "Boeing"
    },
    "severity": "oecd:SeriousHazard",
    "harmType": [
      "oecd:HumanRightsHarm",
      "oecd:PsychologicalHarm"
    ],
    "harmQuantification": {
      "@type": "oecd:HarmQuantification",
      "affected_stakeholders": "73206 users",
      "economic_losses": "$1.1 million",
      "psychological_impact": "Documented stress and anxiety in affected population"
    },
    "countries": [
      {
        "@type": "core:Country",
        "@id": "https://www.wikidata.org/wiki/Spain",
        "name": "Spain"
      },
      {
        "@type": "core:Country",
        "@id": "https://www.wikidata.org/wiki/Sweden",
        "name": "Sweden"
      }
    ],
    "affectedStakeholders": [
      {
        "@type": "oecd:StakeholderGroup",
        "@id": "https://example.org/stakeholder-group/students",
        "name": "Students"
      }
    ],
    "businessFunction": [
      "oecd:Compliance",
      "oecd:Planning"
    ],
    "submitter": {
      "@type": "oecd:Submitter",
      "@id": "https://example.org/submitter/reporter",
      "role": "Consumer Advocate",
      "affiliation": "Consumer Protection Agency",
      "stakeholderGroup": "I am an affected stakeholder",
      "relationToIncident": "None of the above, but have partial or substantial knowledge of the incident (e.g. first-hand knowledge, research etc.)"
    },
    "unintendedUse": false
  },
  {
    "@context": [
      "http://localhost:3000/api/schemas/v1/core/context.jsonld",
      "http://localhost:3001/api/schemas/v1/oecd/context.jsonld"
    ],
    "@type": "oecd:Incident",
    "@id": "https://oecd.ai/incident/OECD-2022-147",
    "incident_id": "OECD-2022-147",
    "title": "AI System Failure Related to Networking Platform Giggle Employs AI to Determine Users’ Gender, Allegedly Excluding Transgender Women",
    "description": "An AI system failure occurred with similar characteristics to the documented incident involving Giggle. The system exhibited comparable failure modes resulting in harm to affected stakeholders.",
    "date": "2022-07-01",
    "aiSystem": {
      "@type": "oecd:AISystem",
      "name": "Automated System",
      "version": "3.0",
      "relation": [
        "oecd:DirectCause"
      ]
    },
    "developer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/Giggle",
      "name": "Giggle"
    },
    "deployer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/Giggle",
      "name": "Giggle"
    },
    "severity": "oecd:SeriousIncident",
    "harmType": [
      "oecd:OtherHarm"
    ],
    "harmQuantification": {
      "@type": "oecd:HarmQuantification",
      "affected_stakeholders": "13476 individuals"
    },
    "countries": [
      {
        "@type": "core:Country",
        "@id": "https://www.wikidata.org/wiki/Israel",
        "name": "Israel"
      },
      {
        "@type": "core:Country",
        "@id": "https://www.wikidata.org/wiki/Netherlands",
        "name": "Netherlands"
      }
    ],
    "affectedStakeholders": [
      {
        "@type": "oecd:StakeholderGroup",
        "@id": "https://example.org/stakeholder-group/women-of-color",
        "name": "women of color"
      },
      {
        "@type": "oecd:StakeholderGroup",
        "@id": "https://example.org/stakeholder-group/trans-women",
        "name": "trans women"
      }
    ],
    "businessFunction": [
      "oecd:Logistics",
      "oecd:Accounting"
    ],
    "submitter": {
      "@type": "oecd:Submitter",
      "@id": "https://example.org/submitter/submitter",
      "role": "Academic Researcher",
      "affiliation": "Tech Policy Center",
      "stakeholderGroup": "I represent a government or regulatory body",
      "relationToIncident": "None of the above, but have partial or substantial knowledge of the incident (e.g. first-hand knowledge, research etc.)"
    },
    "unintendedUse": false,
    "sameAs": "https://incidentdatabase.ai/cite/166"
  },
  {
    "@context": [
      "http://localhost:3000/api/schemas/v1/core/context.jsonld",
      "http://localhost:3001/api/schemas/v1/oecd/context.jsonld"
    ],
    "@type": "oecd:Incident",
    "@id": "https://oecd.ai/incident/OECD-2022-148",
    "incident_id": "OECD-2022-148",
    "title": "AI System Failure Related to Fake LinkedIn Profiles Created Using GAN Photos",
    "description": "An AI system failure occurred with similar characteristics to the documented incident involving unknown. The system exhibited comparable failure modes resulting in harm to affected stakeholders.",
    "date": "2022-07-03",
    "aiSystem": {
      "@type": "oecd:AISystem",
      "name": "Smart System",
      "version": "5.7",
      "relation": [
        "oecd:DirectCause"
      ]
    },
    "developer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/unknown",
      "name": "unknown"
    },
    "deployer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/unknown",
      "name": "unknown"
    },
    "severity": "oecd:SeriousIncident",
    "harmType": [
      "oecd:OtherHarm"
    ],
    "harmQuantification": {
      "@type": "oecd:HarmQuantification",
      "affected_stakeholders": "26156 individuals"
    },
    "countries": [
      {
        "@type": "core:Country",
        "@id": "https://www.wikidata.org/wiki/Brazil",
        "name": "Brazil"
      },
      {
        "@type": "core:Country",
        "@id": "https://www.wikidata.org/wiki/Spain",
        "name": "Spain"
      }
    ],
    "affectedStakeholders": [
      {
        "@type": "oecd:StakeholderGroup",
        "@id": "https://example.org/stakeholder-group/linkedin-users",
        "name": "LinkedIn users"
      }
    ],
    "businessFunction": [
      "oecd:HRManagement"
    ],
    "submitter": {
      "@type": "oecd:Submitter",
      "@id": "https://example.org/submitter/submitter",
      "role": "Industry Analyst",
      "affiliation": "University Research Lab",
      "stakeholderGroup": "I represent a government or regulatory body",
      "relationToIncident": "None of the above, but have partial or substantial knowledge of the incident (e.g. first-hand knowledge, research etc.)"
    },
    "unintendedUse": false,
    "sameAs": "https://incidentdatabase.ai/cite/174"
  },
  {
    "@context": [
      "http://localhost:3000/api/schemas/v1/core/context.jsonld",
      "http://localhost:3001/api/schemas/v1/oecd/context.jsonld"
    ],
    "@type": "oecd:Incident",
    "@id": "https://oecd.ai/incident/OECD-2022-149",
    "incident_id": "OECD-2022-149",
    "title": "AI Credit Scoring System Discriminates Against Recent Immigrants",
    "description": "An automated credit scoring system systematically assigned lower credit scores to recent immigrants despite strong financial indicators. The AI model heavily weighted credit history length, creating unfair barriers to financial services.",
    "date": "2022-07-19",
    "aiSystem": {
      "@type": "oecd:AISystem",
      "name": "Financial AI Engine Pro",
      "version": "8.13.87",
      "relation": [
        "oecd:ContributingFactor"
      ]
    },
    "developer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/LinkedIn",
      "name": "LinkedIn"
    },
    "deployer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/Delhi_Metro_Rail_Corporation",
      "name": "Delhi Metro Rail Corporation"
    },
    "severity": "oecd:SeriousIncident",
    "harmType": [
      "oecd:EconomicHarm",
      "oecd:HumanRightsHarm"
    ],
    "harmQuantification": {
      "@type": "oecd:HarmQuantification",
      "affected_stakeholders": "8260 users",
      "economic_losses": "$1.8 million"
    },
    "countries": [
      {
        "@type": "core:Country",
        "@id": "https://www.wikidata.org/wiki/Brazil",
        "name": "Brazil"
      }
    ],
    "affectedStakeholders": [
      {
        "@type": "oecd:StakeholderGroup",
        "@id": "https://example.org/stakeholder-group/children",
        "name": "Children"
      }
    ],
    "businessFunction": [
      "oecd:OtherFunction"
    ],
    "submitter": {
      "@type": "oecd:Submitter",
      "@id": "https://example.org/submitter/reporter",
      "role": "Safety Engineer",
      "affiliation": "University Ethics Lab",
      "stakeholderGroup": "I am an affected stakeholder",
      "relationToIncident": "None of the above, but have partial or substantial knowledge of the incident (e.g. first-hand knowledge, research etc.)"
    },
    "unintendedUse": false
  },
  {
    "@context": [
      "http://localhost:3000/api/schemas/v1/core/context.jsonld",
      "http://localhost:3001/api/schemas/v1/oecd/context.jsonld"
    ],
    "@type": "oecd:Incident",
    "@id": "https://oecd.ai/incident/OECD-2022-150",
    "incident_id": "OECD-2022-150",
    "title": "AI System Failure Related to AI translation is jeopardizing Afghan asylum claims",
    "description": "An AI system failure occurred with similar characteristics to the documented incident involving US Citizenship and Immigration Services. The system exhibited comparable failure modes resulting in harm to affected stakeholders.",
    "date": "2022-08-05",
    "aiSystem": {
      "@type": "oecd:AISystem",
      "name": "AI Engine",
      "version": "2.9",
      "relation": [
        "oecd:DirectCause"
      ]
    },
    "developer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/US_Citizenship_and_Immigration_Services",
      "name": "US Citizenship and Immigration Services"
    },
    "deployer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/US_Citizenship_and_Immigration_Services",
      "name": "US Citizenship and Immigration Services"
    },
    "severity": "oecd:SeriousIncident",
    "harmType": [
      "oecd:OtherHarm"
    ],
    "harmQuantification": {
      "@type": "oecd:HarmQuantification",
      "affected_stakeholders": "14971 individuals",
      "economic_losses": "$7 million"
    },
    "countries": [
      {
        "@type": "core:Country",
        "@id": "https://www.wikidata.org/wiki/Israel",
        "name": "Israel"
      },
      {
        "@type": "core:Country",
        "@id": "https://www.wikidata.org/wiki/Norway",
        "name": "Norway"
      },
      {
        "@type": "core:Country",
        "@id": "https://www.wikidata.org/wiki/Brazil",
        "name": "Brazil"
      }
    ],
    "affectedStakeholders": [
      {
        "@type": "core:Person",
        "@id": "https://example.org/entities/person/pashto-speaking-asylum-seekers",
        "name": "Pashto-speaking asylum seekers"
      },
      {
        "@type": "core:Person",
        "@id": "https://example.org/entities/person/dari-speaking-asylum-seekers",
        "name": "Dari-speaking asylum seekers"
      },
      {
        "@type": "core:Person",
        "@id": "https://example.org/entities/person/anonymous-pashto-speaking-refugee",
        "name": "anonymous Pashto-speaking refugee"
      }
    ],
    "businessFunction": [
      "oecd:Maintenance"
    ],
    "submitter": {
      "@type": "oecd:Submitter",
      "@id": "https://example.org/submitter/submitter",
      "role": "Academic Researcher",
      "affiliation": "Tech Policy Center",
      "stakeholderGroup": "None of the above, but have partial or substantial knowledge of the incident",
      "relationToIncident": "I am an affected stakeholder"
    },
    "unintendedUse": false,
    "sameAs": "https://incidentdatabase.ai/cite/532"
  },
  {
    "@context": [
      "http://localhost:3000/api/schemas/v1/core/context.jsonld",
      "http://localhost:3001/api/schemas/v1/oecd/context.jsonld"
    ],
    "@type": "oecd:Incident",
    "@id": "https://oecd.ai/incident/OECD-2022-151",
    "incident_id": "OECD-2022-151",
    "title": "AI System Failure Related to Networking Platform Giggle Employs AI to Determine Users’ Gender, Allegedly Excluding Transgender Women",
    "description": "An AI system failure occurred with similar characteristics to the documented incident involving Giggle. The system exhibited comparable failure modes resulting in harm to affected stakeholders.",
    "date": "2022-08-21",
    "aiSystem": {
      "@type": "oecd:AISystem",
      "name": "Smart Engine",
      "version": "3.8",
      "relation": [
        "oecd:DirectCause"
      ]
    },
    "developer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/Giggle",
      "name": "Giggle"
    },
    "deployer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/Giggle",
      "name": "Giggle"
    },
    "severity": "oecd:SeriousIncident",
    "harmType": [
      "oecd:OtherHarm"
    ],
    "harmQuantification": {
      "@type": "oecd:HarmQuantification",
      "affected_stakeholders": "27496 individuals",
      "economic_losses": "$5 million"
    },
    "countries": [
      {
        "@type": "core:Country",
        "@id": "https://www.wikidata.org/wiki/Japan",
        "name": "Japan"
      }
    ],
    "affectedStakeholders": [
      {
        "@type": "oecd:StakeholderGroup",
        "@id": "https://example.org/stakeholder-group/women-of-color",
        "name": "women of color"
      },
      {
        "@type": "oecd:StakeholderGroup",
        "@id": "https://example.org/stakeholder-group/trans-women",
        "name": "trans women"
      }
    ],
    "businessFunction": [
      "oecd:HRManagement"
    ],
    "submitter": {
      "@type": "oecd:Submitter",
      "@id": "https://example.org/submitter/submitter",
      "role": "Journalist",
      "affiliation": "AI Safety Institute",
      "stakeholderGroup": "None of the above, but have partial or substantial knowledge of the incident",
      "relationToIncident": "I am an affected stakeholder"
    },
    "unintendedUse": false,
    "sameAs": "https://incidentdatabase.ai/cite/166"
  },
  {
    "@context": [
      "http://localhost:3000/api/schemas/v1/core/context.jsonld",
      "http://localhost:3001/api/schemas/v1/oecd/context.jsonld"
    ],
    "@type": "oecd:Incident",
    "@id": "https://oecd.ai/incident/OECD-2022-152",
    "incident_id": "OECD-2022-152",
    "title": "Agricultural AI Misidentifies Crops Leading to Herbicide Damage",
    "description": "An AI-powered crop monitoring and treatment system misidentified valuable crops as weeds, resulting in herbicide application that destroyed thousands of acres of produce. The computer vision model was not properly validated for the specific crop varieties.",
    "date": "2022-10-19",
    "aiSystem": {
      "@type": "oecd:AISystem",
      "name": "Autonomous Systems System",
      "version": "6.12.40",
      "relation": [
        "oecd:DirectCause"
      ]
    },
    "developer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/LinkedIn",
      "name": "LinkedIn"
    },
    "deployer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/Frontier_Development",
      "name": "Frontier Development"
    },
    "severity": "oecd:SeriousIncident",
    "harmType": [
      "oecd:EconomicHarm",
      "oecd:EnvironmentalHarm"
    ],
    "harmQuantification": {
      "@type": "oecd:HarmQuantification",
      "affected_stakeholders": "60484 individuals",
      "economic_losses": "$16.7 million"
    },
    "countries": [
      {
        "@type": "core:Country",
        "@id": "https://www.wikidata.org/wiki/Israel",
        "name": "Israel"
      }
    ],
    "affectedStakeholders": [
      {
        "@type": "oecd:StakeholderGroup",
        "@id": "https://example.org/stakeholder-group/children",
        "name": "Children"
      },
      {
        "@type": "oecd:StakeholderGroup",
        "@id": "https://example.org/stakeholder-group/consumers",
        "name": "Consumers"
      },
      {
        "@type": "core:Person",
        "@id": "https://example.org/entities/person/motorists",
        "name": "Motorists"
      }
    ],
    "businessFunction": [
      "oecd:Production",
      "oecd:OtherFunction"
    ],
    "submitter": {
      "@type": "oecd:Submitter",
      "@id": "https://example.org/submitter/reporter",
      "role": "Industry Whistleblower",
      "affiliation": "AI Safety Coalition",
      "stakeholderGroup": "I work or am affiliated to a public interest body or NGO",
      "relationToIncident": "None of the above, but have partial or substantial knowledge of the incident (e.g. first-hand knowledge, research etc.)"
    },
    "unintendedUse": false
  },
  {
    "@context": [
      "http://localhost:3000/api/schemas/v1/core/context.jsonld",
      "http://localhost:3001/api/schemas/v1/oecd/context.jsonld"
    ],
    "@type": "oecd:Incident",
    "@id": "https://oecd.ai/incident/OECD-2022-153",
    "incident_id": "OECD-2022-153",
    "title": "AI System Failure Related to Black Uber Eats Driver Allegedly Subjected to Excessive Photo Checks and Dismissed via FRT Results",
    "description": "An AI system failure occurred with similar characteristics to the documented incident involving Uber Eats. The system exhibited comparable failure modes resulting in harm to affected stakeholders.",
    "date": "2022-11-13",
    "aiSystem": {
      "@type": "oecd:AISystem",
      "name": "Intelligent System",
      "version": "3.1",
      "relation": [
        "oecd:DirectCause"
      ]
    },
    "developer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/Uber_Eats",
      "name": "Uber Eats"
    },
    "deployer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/Uber_Eats",
      "name": "Uber Eats"
    },
    "severity": "oecd:SeriousIncident",
    "harmType": [
      "oecd:OtherHarm"
    ],
    "harmQuantification": {
      "@type": "oecd:HarmQuantification",
      "affected_stakeholders": "2860 individuals"
    },
    "countries": [
      {
        "@type": "core:Country",
        "@id": "https://www.wikidata.org/wiki/Singapore",
        "name": "Singapore"
      },
      {
        "@type": "core:Country",
        "@id": "https://www.wikidata.org/wiki/Norway",
        "name": "Norway"
      }
    ],
    "affectedStakeholders": [
      {
        "@type": "core:Person",
        "@id": "https://example.org/entities/person/uber-eats-black-delivery-drivers",
        "name": "Uber Eats Black delivery drivers"
      },
      {
        "@type": "core:Person",
        "@id": "https://example.org/entities/person/pa-edrissa-manjang",
        "name": "Pa Edrissa Manjang"
      }
    ],
    "businessFunction": [
      "oecd:QualityControl"
    ],
    "submitter": {
      "@type": "oecd:Submitter",
      "@id": "https://example.org/submitter/submitter",
      "role": "Ethics Officer",
      "affiliation": "AI Safety Institute",
      "stakeholderGroup": "None of the above, but have partial or substantial knowledge of the incident",
      "relationToIncident": "I am a user of the related AI system"
    },
    "unintendedUse": false,
    "sameAs": "https://incidentdatabase.ai/cite/265"
  },
  {
    "@context": [
      "http://localhost:3000/api/schemas/v1/core/context.jsonld",
      "http://localhost:3001/api/schemas/v1/oecd/context.jsonld"
    ],
    "@type": "oecd:Incident",
    "@id": "https://oecd.ai/incident/OECD-2022-154",
    "incident_id": "OECD-2022-154",
    "title": "AI System Failure Related to Stable Diffusion Abused by 4chan Users to Deepfake Celebrity Porn",
    "description": "An AI system failure occurred with similar characteristics to the documented incident involving Stability AI. The system exhibited comparable failure modes resulting in harm to affected stakeholders.",
    "date": "2022-11-13",
    "aiSystem": {
      "@type": "oecd:AISystem",
      "name": "Smart Solution",
      "version": "2.8",
      "relation": [
        "oecd:DirectCause"
      ]
    },
    "developer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/Stability_AI",
      "name": "Stability AI"
    },
    "deployer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/Stability_AI",
      "name": "Stability AI"
    },
    "severity": "oecd:SeriousIncident",
    "harmType": [
      "oecd:OtherHarm"
    ],
    "harmQuantification": {
      "@type": "oecd:HarmQuantification",
      "affected_stakeholders": "14257 individuals",
      "economic_losses": "$1 million"
    },
    "countries": [
      {
        "@type": "core:Country",
        "@id": "https://www.wikidata.org/wiki/Norway",
        "name": "Norway"
      },
      {
        "@type": "core:Country",
        "@id": "https://www.wikidata.org/wiki/Israel",
        "name": "Israel"
      },
      {
        "@type": "core:Country",
        "@id": "https://www.wikidata.org/wiki/Spain",
        "name": "Spain"
      }
    ],
    "affectedStakeholders": [
      {
        "@type": "core:Person",
        "@id": "https://example.org/entities/person/stability-ai",
        "name": "Stability AI"
      },
      {
        "@type": "core:Person",
        "@id": "https://example.org/entities/person/deepfaked-celebrities",
        "name": "deepfaked celebrities"
      }
    ],
    "businessFunction": [
      "oecd:Logistics",
      "oecd:ICTManagement"
    ],
    "submitter": {
      "@type": "oecd:Submitter",
      "@id": "https://example.org/submitter/submitter",
      "role": "Academic Researcher",
      "affiliation": "AI Safety Institute",
      "stakeholderGroup": "I work or am affiliated to a public interest body or NGO",
      "relationToIncident": "I am a user of the related AI system"
    },
    "unintendedUse": false,
    "sameAs": "https://incidentdatabase.ai/cite/314"
  },
  {
    "@context": [
      "http://localhost:3000/api/schemas/v1/core/context.jsonld",
      "http://localhost:3001/api/schemas/v1/oecd/context.jsonld"
    ],
    "@type": "oecd:Incident",
    "@id": "https://oecd.ai/incident/OECD-2022-155",
    "incident_id": "OECD-2022-155",
    "title": "AI System Failure Related to Networking Platform Giggle Employs AI to Determine Users’ Gender, Allegedly Excluding Transgender Women",
    "description": "An AI system failure occurred with similar characteristics to the documented incident involving Giggle. The system exhibited comparable failure modes resulting in harm to affected stakeholders.",
    "date": "2022-11-25",
    "aiSystem": {
      "@type": "oecd:AISystem",
      "name": "Smart Platform",
      "version": "3.0",
      "relation": [
        "oecd:DirectCause"
      ]
    },
    "developer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/Giggle",
      "name": "Giggle"
    },
    "deployer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/Giggle",
      "name": "Giggle"
    },
    "severity": "oecd:SeriousIncident",
    "harmType": [
      "oecd:OtherHarm"
    ],
    "harmQuantification": {
      "@type": "oecd:HarmQuantification",
      "affected_stakeholders": "39976 individuals"
    },
    "countries": [
      {
        "@type": "core:Country",
        "@id": "https://www.wikidata.org/wiki/Brazil",
        "name": "Brazil"
      },
      {
        "@type": "core:Country",
        "@id": "https://www.wikidata.org/wiki/United_Kingdom",
        "name": "United Kingdom"
      }
    ],
    "affectedStakeholders": [
      {
        "@type": "oecd:StakeholderGroup",
        "@id": "https://example.org/stakeholder-group/women-of-color",
        "name": "women of color"
      },
      {
        "@type": "oecd:StakeholderGroup",
        "@id": "https://example.org/stakeholder-group/trans-women",
        "name": "trans women"
      }
    ],
    "businessFunction": [
      "oecd:Planning"
    ],
    "submitter": {
      "@type": "oecd:Submitter",
      "@id": "https://example.org/submitter/submitter",
      "role": "Government Inspector",
      "affiliation": "Government Oversight Committee",
      "stakeholderGroup": "I represent a government or regulatory body",
      "relationToIncident": "None of the above, but have partial or substantial knowledge of the incident (e.g. first-hand knowledge, research etc.)"
    },
    "unintendedUse": false,
    "sameAs": "https://incidentdatabase.ai/cite/166"
  },
  {
    "@context": [
      "http://localhost:3000/api/schemas/v1/core/context.jsonld",
      "http://localhost:3001/api/schemas/v1/oecd/context.jsonld"
    ],
    "@type": "oecd:Incident",
    "@id": "https://oecd.ai/incident/OECD-2022-156",
    "incident_id": "OECD-2022-156",
    "title": "Facial Recognition System Falsely Identifies Protesters as Criminals",
    "description": "A law enforcement facial recognition system incorrectly matched peaceful protesters with criminal database entries, leading to wrongful detentions. The AI system showed higher error rates for certain ethnic groups and in crowded scenarios.",
    "date": "2022-11-25",
    "aiSystem": {
      "@type": "oecd:AISystem",
      "name": "Security/Surveillance Solution",
      "version": "10.18.62",
      "relation": [
        "oecd:ContributingFactor",
        "oecd:HumanError"
      ]
    },
    "developer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/Keolis",
      "name": "Keolis North America"
    },
    "deployer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/Boeing",
      "name": "Boeing"
    },
    "severity": "oecd:SeriousIncident",
    "harmType": [
      "oecd:PhysicalHarm",
      "oecd:HumanRightsHarm",
      "oecd:ReputationalHarm"
    ],
    "harmQuantification": {
      "@type": "oecd:HarmQuantification",
      "affected_stakeholders": "8861 patients",
      "economic_losses": "$23.3 million"
    },
    "countries": [
      {
        "@type": "core:Country",
        "@id": "https://www.wikidata.org/wiki/France",
        "name": "France"
      }
    ],
    "affectedStakeholders": [
      {
        "@type": "core:Person",
        "@id": "https://example.org/entities/person/bus-passengers",
        "name": "Bus passengers"
      },
      {
        "@type": "oecd:StakeholderGroup",
        "@id": "https://example.org/stakeholder-group/women",
        "name": "Women"
      },
      {
        "@type": "core:Person",
        "@id": "https://example.org/entities/person/motorists",
        "name": "Motorists"
      }
    ],
    "businessFunction": [
      "oecd:Compliance"
    ],
    "submitter": {
      "@type": "oecd:Submitter",
      "@id": "https://example.org/submitter/reporter",
      "role": "Data Scientist",
      "affiliation": "AI Safety Coalition",
      "stakeholderGroup": "I represent a government or regulatory body",
      "relationToIncident": "None of the above, but have partial or substantial knowledge of the incident (e.g. first-hand knowledge, research etc.)"
    },
    "unintendedUse": false
  },
  {
    "@context": [
      "http://localhost:3000/api/schemas/v1/core/context.jsonld",
      "http://localhost:3001/api/schemas/v1/oecd/context.jsonld"
    ],
    "@type": "oecd:Incident",
    "@id": "https://oecd.ai/incident/OECD-2022-157",
    "incident_id": "OECD-2022-157",
    "title": "AI Interview System Shows Bias Against Non-Native Speakers",
    "description": "An automated video interview analysis system consistently gave lower scores to qualified candidates with accents or non-native speech patterns. The AI's speech recognition and sentiment analysis components showed significant bias.",
    "date": "2022-12-09",
    "aiSystem": {
      "@type": "oecd:AISystem",
      "name": "Workplace AI System Pro",
      "version": "2.6.58",
      "relation": [
        "oecd:DirectCause",
        "oecd:FailureToAct"
      ]
    },
    "developer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/Keolis",
      "name": "Keolis North America"
    },
    "deployer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/YouTube",
      "name": "YouTube"
    },
    "severity": "oecd:SeriousIncident",
    "harmType": [
      "oecd:EconomicHarm",
      "oecd:HumanRightsHarm"
    ],
    "harmQuantification": {
      "@type": "oecd:HarmQuantification",
      "affected_stakeholders": "12079 customers"
    },
    "countries": [
      {
        "@type": "core:Country",
        "@id": "https://www.wikidata.org/wiki/Spain",
        "name": "Spain"
      },
      {
        "@type": "core:Country",
        "@id": "https://www.wikidata.org/wiki/Israel",
        "name": "Israel"
      }
    ],
    "affectedStakeholders": [
      {
        "@type": "oecd:StakeholderGroup",
        "@id": "https://example.org/stakeholder-group/children",
        "name": "Children"
      },
      {
        "@type": "oecd:StakeholderGroup",
        "@id": "https://example.org/stakeholder-group/workers",
        "name": "Workers"
      }
    ],
    "businessFunction": [
      "oecd:HRManagement"
    ],
    "submitter": {
      "@type": "oecd:Submitter",
      "@id": "https://example.org/submitter/reporter",
      "role": "Data Scientist",
      "affiliation": "Digital Rights Organization",
      "stakeholderGroup": "None of the above, but have partial or substantial knowledge of the incident",
      "relationToIncident": "None of the above, but have partial or substantial knowledge of the incident (e.g. first-hand knowledge, research etc.)"
    },
    "unintendedUse": false
  },
  {
    "@context": [
      "http://localhost:3000/api/schemas/v1/core/context.jsonld",
      "http://localhost:3001/api/schemas/v1/oecd/context.jsonld"
    ],
    "@type": "oecd:Incident",
    "@id": "https://oecd.ai/incident/OECD-2023-158",
    "incident_id": "OECD-2023-158",
    "title": "AI Diagnostic System Misses Critical Symptoms in Emergency Department",
    "description": "An AI triage system in emergency departments failed to identify critical symptoms in patients presenting with atypical manifestations of serious conditions. The system's training data lacked diversity in symptom presentations across different demographics.",
    "date": "2023-01-06",
    "aiSystem": {
      "@type": "oecd:AISystem",
      "name": "Medical AI Solution Pro",
      "version": "5.12.78",
      "relation": [
        "oecd:DirectCause"
      ]
    },
    "developer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/St_George's_Hospital_Medical_School",
      "name": "St George's Hospital Medical School"
    },
    "deployer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/Northpointe",
      "name": "Northpointe"
    },
    "severity": "oecd:SeriousHazard",
    "harmType": [
      "oecd:PhysicalHarm",
      "oecd:HumanRightsHarm"
    ],
    "harmQuantification": {
      "@type": "oecd:HarmQuantification",
      "affected_stakeholders": "84740 customers"
    },
    "countries": [
      {
        "@type": "core:Country",
        "@id": "https://www.wikidata.org/wiki/United_States",
        "name": "United States"
      }
    ],
    "affectedStakeholders": [
      {
        "@type": "oecd:StakeholderGroup",
        "@id": "https://example.org/stakeholder-group/minority-groups",
        "name": "Minority Groups"
      }
    ],
    "businessFunction": [
      "oecd:OtherFunction"
    ],
    "submitter": {
      "@type": "oecd:Submitter",
      "@id": "https://example.org/submitter/reporter",
      "role": "Safety Engineer",
      "affiliation": "Consumer Protection Agency",
      "stakeholderGroup": "None of the above, but have partial or substantial knowledge of the incident",
      "relationToIncident": "None of the above, but have partial or substantial knowledge of the incident (e.g. first-hand knowledge, research etc.)"
    },
    "unintendedUse": false
  },
  {
    "@context": [
      "http://localhost:3000/api/schemas/v1/core/context.jsonld",
      "http://localhost:3001/api/schemas/v1/oecd/context.jsonld"
    ],
    "@type": "oecd:Incident",
    "@id": "https://oecd.ai/incident/OECD-2023-159",
    "incident_id": "OECD-2023-159",
    "title": "AI System Failure Related to Tesla Autopilot Misidentified On-Road Horse-Drawn Carriage",
    "description": "An AI system failure occurred with similar characteristics to the documented incident involving Tesla. The system exhibited comparable failure modes resulting in harm to affected stakeholders.",
    "date": "2023-01-15",
    "aiSystem": {
      "@type": "oecd:AISystem",
      "name": "Intelligent Platform",
      "version": "4.6",
      "relation": [
        "oecd:DirectCause"
      ]
    },
    "developer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/Tesla,_Inc.",
      "name": "Tesla"
    },
    "deployer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/Tesla,_Inc.",
      "name": "Tesla"
    },
    "severity": "oecd:SeriousIncident",
    "harmType": [
      "oecd:OtherHarm"
    ],
    "harmQuantification": {
      "@type": "oecd:HarmQuantification",
      "affected_stakeholders": "40711 individuals"
    },
    "countries": [
      {
        "@type": "core:Country",
        "@id": "https://www.wikidata.org/wiki/South_Korea",
        "name": "South Korea"
      }
    ],
    "affectedStakeholders": [
      {
        "@type": "core:Person",
        "@id": "https://example.org/entities/person/tesla-drivers",
        "name": "Tesla drivers"
      },
      {
        "@type": "core:Person",
        "@id": "https://example.org/entities/person/horse-drawn-carriages",
        "name": "horse-drawn carriages"
      }
    ],
    "businessFunction": [
      "oecd:QualityControl"
    ],
    "submitter": {
      "@type": "oecd:Submitter",
      "@id": "https://example.org/submitter/submitter",
      "role": "Journalist",
      "affiliation": "Tech Policy Center",
      "stakeholderGroup": "None of the above, but have partial or substantial knowledge of the incident",
      "relationToIncident": "None of the above, but have partial or substantial knowledge of the incident (e.g. first-hand knowledge, research etc.)"
    },
    "unintendedUse": false,
    "sameAs": "https://incidentdatabase.ai/cite/398"
  },
  {
    "@context": [
      "http://localhost:3000/api/schemas/v1/core/context.jsonld",
      "http://localhost:3001/api/schemas/v1/oecd/context.jsonld"
    ],
    "@type": "oecd:Incident",
    "@id": "https://oecd.ai/incident/OECD-2023-160",
    "incident_id": "OECD-2023-160",
    "title": "AI Personal Assistant Shares Private Information in Group Settings",
    "description": "A voice-activated AI assistant failed to recognize multi-user environments and shared personal calendar entries, medical reminders, and financial information when responding to queries in group settings.",
    "date": "2023-01-15",
    "aiSystem": {
      "@type": "oecd:AISystem",
      "name": "Consumer AI Platform Pro",
      "version": "5.17.11",
      "relation": [
        "oecd:ContributingFactor"
      ]
    },
    "developer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/Apple_Inc.",
      "name": "Apple"
    },
    "deployer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/United_States_Government",
      "name": "United States Government"
    },
    "severity": "oecd:SeriousIncident",
    "harmType": [
      "oecd:ReputationalHarm",
      "oecd:HumanRightsHarm"
    ],
    "harmQuantification": {
      "@type": "oecd:HarmQuantification",
      "affected_stakeholders": "4353 individuals",
      "economic_losses": "$14.5 million"
    },
    "countries": [
      {
        "@type": "core:Country",
        "@id": "https://www.wikidata.org/wiki/United_States",
        "name": "United States"
      }
    ],
    "affectedStakeholders": [
      {
        "@type": "core:Person",
        "@id": "https://example.org/entities/person/black-people",
        "name": "Black people"
      }
    ],
    "businessFunction": [
      "oecd:CustomerService",
      "oecd:ICTManagement"
    ],
    "submitter": {
      "@type": "oecd:Submitter",
      "@id": "https://example.org/submitter/reporter",
      "role": "Safety Engineer",
      "affiliation": "Consumer Protection Agency",
      "stakeholderGroup": "I work or am affiliated to a public interest body or NGO",
      "relationToIncident": "None of the above, but have partial or substantial knowledge of the incident (e.g. first-hand knowledge, research etc.)"
    },
    "unintendedUse": false
  },
  {
    "@context": [
      "http://localhost:3000/api/schemas/v1/core/context.jsonld",
      "http://localhost:3001/api/schemas/v1/oecd/context.jsonld"
    ],
    "@type": "oecd:Incident",
    "@id": "https://oecd.ai/incident/OECD-2023-161",
    "incident_id": "OECD-2023-161",
    "title": "Agricultural AI Misidentifies Crops Leading to Herbicide Damage",
    "description": "An AI-powered crop monitoring and treatment system misidentified valuable crops as weeds, resulting in herbicide application that destroyed thousands of acres of produce. The computer vision model was not properly validated for the specific crop varieties.",
    "date": "2023-02-17",
    "aiSystem": {
      "@type": "oecd:AISystem",
      "name": "Autonomous Systems System",
      "version": "1.13.12",
      "relation": [
        "oecd:DirectCause"
      ]
    },
    "developer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/Boston_University",
      "name": "Boston University"
    },
    "deployer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/Volkswagen",
      "name": "Volkswagen"
    },
    "severity": "oecd:SeriousIncident",
    "harmType": [
      "oecd:EconomicHarm",
      "oecd:EnvironmentalHarm"
    ],
    "harmQuantification": {
      "@type": "oecd:HarmQuantification",
      "affected_stakeholders": "96201 users",
      "economic_losses": "$11.8 million"
    },
    "countries": [
      {
        "@type": "core:Country",
        "@id": "https://www.wikidata.org/wiki/Mexico",
        "name": "Mexico"
      },
      {
        "@type": "core:Country",
        "@id": "https://www.wikidata.org/wiki/China",
        "name": "China"
      }
    ],
    "affectedStakeholders": [
      {
        "@type": "oecd:StakeholderGroup",
        "@id": "https://example.org/stakeholder-group/students",
        "name": "Students"
      },
      {
        "@type": "oecd:StakeholderGroup",
        "@id": "https://example.org/stakeholder-group/workers",
        "name": "Workers"
      }
    ],
    "businessFunction": [
      "oecd:Production",
      "oecd:OtherFunction"
    ],
    "submitter": {
      "@type": "oecd:Submitter",
      "@id": "https://example.org/submitter/reporter",
      "role": "Data Scientist",
      "affiliation": "Digital Rights Organization",
      "stakeholderGroup": "I represent a government or regulatory body",
      "relationToIncident": "None of the above, but have partial or substantial knowledge of the incident (e.g. first-hand knowledge, research etc.)"
    },
    "unintendedUse": false
  },
  {
    "@context": [
      "http://localhost:3000/api/schemas/v1/core/context.jsonld",
      "http://localhost:3001/api/schemas/v1/oecd/context.jsonld"
    ],
    "@type": "oecd:Incident",
    "@id": "https://oecd.ai/incident/OECD-2023-162",
    "incident_id": "OECD-2023-162",
    "title": "AI System Failure Related to Black Uber Eats Driver Allegedly Subjected to Excessive Photo Checks and Dismissed via FRT Results",
    "description": "An AI system failure occurred with similar characteristics to the documented incident involving Uber Eats. The system exhibited comparable failure modes resulting in harm to affected stakeholders.",
    "date": "2023-03-13",
    "aiSystem": {
      "@type": "oecd:AISystem",
      "name": "Smart Engine",
      "version": "1.3",
      "relation": [
        "oecd:DirectCause"
      ]
    },
    "developer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/Uber_Eats",
      "name": "Uber Eats"
    },
    "deployer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/Uber_Eats",
      "name": "Uber Eats"
    },
    "severity": "oecd:SeriousIncident",
    "harmType": [
      "oecd:OtherHarm"
    ],
    "harmQuantification": {
      "@type": "oecd:HarmQuantification",
      "affected_stakeholders": "31334 individuals"
    },
    "countries": [
      {
        "@type": "core:Country",
        "@id": "https://www.wikidata.org/wiki/Spain",
        "name": "Spain"
      },
      {
        "@type": "core:Country",
        "@id": "https://www.wikidata.org/wiki/Italy",
        "name": "Italy"
      }
    ],
    "affectedStakeholders": [
      {
        "@type": "core:Person",
        "@id": "https://example.org/entities/person/uber-eats-black-delivery-drivers",
        "name": "Uber Eats Black delivery drivers"
      },
      {
        "@type": "core:Person",
        "@id": "https://example.org/entities/person/pa-edrissa-manjang",
        "name": "Pa Edrissa Manjang"
      }
    ],
    "businessFunction": [
      "oecd:Logistics"
    ],
    "submitter": {
      "@type": "oecd:Submitter",
      "@id": "https://example.org/submitter/submitter",
      "role": "AI Safety Researcher",
      "affiliation": "Government Oversight Committee",
      "stakeholderGroup": "I represent a government or regulatory body",
      "relationToIncident": "I am an affected stakeholder"
    },
    "unintendedUse": false,
    "sameAs": "https://incidentdatabase.ai/cite/265"
  },
  {
    "@context": [
      "http://localhost:3000/api/schemas/v1/core/context.jsonld",
      "http://localhost:3001/api/schemas/v1/oecd/context.jsonld"
    ],
    "@type": "oecd:Incident",
    "@id": "https://oecd.ai/incident/OECD-2023-163",
    "incident_id": "OECD-2023-163",
    "title": "AI Credit Scoring System Discriminates Against Recent Immigrants",
    "description": "An automated credit scoring system systematically assigned lower credit scores to recent immigrants despite strong financial indicators. The AI model heavily weighted credit history length, creating unfair barriers to financial services.",
    "date": "2023-03-16",
    "aiSystem": {
      "@type": "oecd:AISystem",
      "name": "Financial AI Solution Pro",
      "version": "5.14.84",
      "relation": [
        "oecd:DirectCause",
        "oecd:ContributingFactor"
      ]
    },
    "developer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/Apple_Inc.",
      "name": "Apple"
    },
    "deployer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/Northpointe",
      "name": "Northpointe"
    },
    "severity": "oecd:SeriousIncident",
    "harmType": [
      "oecd:EconomicHarm",
      "oecd:HumanRightsHarm"
    ],
    "harmQuantification": {
      "@type": "oecd:HarmQuantification",
      "affected_stakeholders": "84941 individuals",
      "economic_losses": "$47.0 million"
    },
    "countries": [
      {
        "@type": "core:Country",
        "@id": "https://www.wikidata.org/wiki/Italy",
        "name": "Italy"
      }
    ],
    "affectedStakeholders": [
      {
        "@type": "core:Person",
        "@id": "https://example.org/entities/person/pedestrians",
        "name": "Pedestrians"
      }
    ],
    "businessFunction": [
      "oecd:OtherFunction"
    ],
    "submitter": {
      "@type": "oecd:Submitter",
      "@id": "https://example.org/submitter/reporter",
      "role": "Consumer Advocate",
      "affiliation": "Consumer Protection Agency",
      "stakeholderGroup": "I work or am affiliated to a public interest body or NGO",
      "relationToIncident": "None of the above, but have partial or substantial knowledge of the incident (e.g. first-hand knowledge, research etc.)"
    },
    "unintendedUse": false
  },
  {
    "@context": [
      "http://localhost:3000/api/schemas/v1/core/context.jsonld",
      "http://localhost:3001/api/schemas/v1/oecd/context.jsonld"
    ],
    "@type": "oecd:Incident",
    "@id": "https://oecd.ai/incident/OECD-2023-164",
    "incident_id": "OECD-2023-164",
    "title": "AI System Failure Related to Starship’s Autonomous Food Delivery Robot Allegedly Stranded at Railroad Crossing in Oregon, Run over by Freight Train",
    "description": "An AI system failure occurred with similar characteristics to the documented incident involving Oregon State University. The system exhibited comparable failure modes resulting in harm to affected stakeholders.",
    "date": "2023-05-04",
    "aiSystem": {
      "@type": "oecd:AISystem",
      "name": "Smart Solution",
      "version": "2.8",
      "relation": [
        "oecd:DirectCause"
      ]
    },
    "developer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/Oregon_State_University",
      "name": "Oregon State University"
    },
    "deployer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/Oregon_State_University",
      "name": "Oregon State University"
    },
    "severity": "oecd:SeriousIncident",
    "harmType": [
      "oecd:OtherHarm"
    ],
    "harmQuantification": {
      "@type": "oecd:HarmQuantification",
      "affected_stakeholders": "29518 individuals"
    },
    "countries": [
      {
        "@type": "core:Country",
        "@id": "https://www.wikidata.org/wiki/India",
        "name": "India"
      },
      {
        "@type": "core:Country",
        "@id": "https://www.wikidata.org/wiki/Sweden",
        "name": "Sweden"
      }
    ],
    "affectedStakeholders": [
      {
        "@type": "core:Person",
        "@id": "https://example.org/entities/person/oregon-state-university",
        "name": "Oregon State University"
      },
      {
        "@type": "core:Person",
        "@id": "https://example.org/entities/person/freight-train-crew",
        "name": "freight train crew"
      }
    ],
    "businessFunction": [
      "oecd:Compliance",
      "oecd:Procurement"
    ],
    "submitter": {
      "@type": "oecd:Submitter",
      "@id": "https://example.org/submitter/submitter",
      "role": "Government Inspector",
      "affiliation": "AI Safety Institute",
      "stakeholderGroup": "I represent a government or regulatory body",
      "relationToIncident": "None of the above, but have partial or substantial knowledge of the incident (e.g. first-hand knowledge, research etc.)"
    },
    "unintendedUse": false,
    "sameAs": "https://incidentdatabase.ai/cite/176"
  },
  {
    "@context": [
      "http://localhost:3000/api/schemas/v1/core/context.jsonld",
      "http://localhost:3001/api/schemas/v1/oecd/context.jsonld"
    ],
    "@type": "oecd:Incident",
    "@id": "https://oecd.ai/incident/OECD-2023-165",
    "incident_id": "OECD-2023-165",
    "title": "Delivery Robot Swarm Blocks Emergency Vehicle Access",
    "description": "A fleet of autonomous delivery robots failed to coordinate their movements during an emergency, blocking paramedic access to a medical emergency. The swarm intelligence system lacked proper emergency vehicle detection and response protocols.",
    "date": "2023-05-08",
    "aiSystem": {
      "@type": "oecd:AISystem",
      "name": "Autonomous Systems Platform Pro",
      "version": "6.3.27",
      "relation": [
        "oecd:ContributingFactor",
        "oecd:HumanError"
      ]
    },
    "developer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/St_George's_Hospital_Medical_School",
      "name": "St George's Hospital Medical School"
    },
    "deployer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/Starbucks",
      "name": "Starbucks"
    },
    "severity": "oecd:SeriousHazard",
    "harmType": [
      "oecd:PhysicalHarm",
      "oecd:PublicInterestHarm"
    ],
    "harmQuantification": {
      "@type": "oecd:HarmQuantification",
      "affected_stakeholders": "27018 workers",
      "economic_losses": "$36.4 million"
    },
    "countries": [
      {
        "@type": "core:Country",
        "@id": "https://www.wikidata.org/wiki/United_States",
        "name": "United States"
      },
      {
        "@type": "core:Country",
        "@id": "https://www.wikidata.org/wiki/Brazil",
        "name": "Brazil"
      }
    ],
    "affectedStakeholders": [
      {
        "@type": "oecd:StakeholderGroup",
        "@id": "https://example.org/stakeholder-group/children",
        "name": "Children"
      },
      {
        "@type": "core:Person",
        "@id": "https://example.org/entities/person/motorists",
        "name": "Motorists"
      }
    ],
    "businessFunction": [
      "oecd:Logistics",
      "oecd:OtherFunction"
    ],
    "submitter": {
      "@type": "oecd:Submitter",
      "@id": "https://example.org/submitter/reporter",
      "role": "Academic Researcher",
      "affiliation": "Tech Accountability Project",
      "stakeholderGroup": "I represent a government or regulatory body",
      "relationToIncident": "None of the above, but have partial or substantial knowledge of the incident (e.g. first-hand knowledge, research etc.)"
    },
    "unintendedUse": false
  },
  {
    "@context": [
      "http://localhost:3000/api/schemas/v1/core/context.jsonld",
      "http://localhost:3001/api/schemas/v1/oecd/context.jsonld"
    ],
    "@type": "oecd:Incident",
    "@id": "https://oecd.ai/incident/OECD-2023-166",
    "incident_id": "OECD-2023-166",
    "title": "AI System Failure Related to Black Uber Eats Driver Allegedly Subjected to Excessive Photo Checks and Dismissed via FRT Results",
    "description": "An AI system failure occurred with similar characteristics to the documented incident involving Uber Eats. The system exhibited comparable failure modes resulting in harm to affected stakeholders.",
    "date": "2023-05-10",
    "aiSystem": {
      "@type": "oecd:AISystem",
      "name": "AI Engine",
      "version": "3.1",
      "relation": [
        "oecd:DirectCause"
      ]
    },
    "developer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/Uber_Eats",
      "name": "Uber Eats"
    },
    "deployer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/Uber_Eats",
      "name": "Uber Eats"
    },
    "severity": "oecd:SeriousIncident",
    "harmType": [
      "oecd:OtherHarm"
    ],
    "harmQuantification": {
      "@type": "oecd:HarmQuantification",
      "affected_stakeholders": "22668 individuals",
      "economic_losses": "$4 million"
    },
    "countries": [
      {
        "@type": "core:Country",
        "@id": "https://www.wikidata.org/wiki/South_Korea",
        "name": "South Korea"
      },
      {
        "@type": "core:Country",
        "@id": "https://www.wikidata.org/wiki/Norway",
        "name": "Norway"
      }
    ],
    "affectedStakeholders": [
      {
        "@type": "core:Person",
        "@id": "https://example.org/entities/person/uber-eats-black-delivery-drivers",
        "name": "Uber Eats Black delivery drivers"
      },
      {
        "@type": "core:Person",
        "@id": "https://example.org/entities/person/pa-edrissa-manjang",
        "name": "Pa Edrissa Manjang"
      }
    ],
    "businessFunction": [
      "oecd:Sales"
    ],
    "submitter": {
      "@type": "oecd:Submitter",
      "@id": "https://example.org/submitter/submitter",
      "role": "AI Safety Researcher",
      "affiliation": "Tech Policy Center",
      "stakeholderGroup": "I work or am affiliated to a public interest body or NGO",
      "relationToIncident": "None of the above, but have partial or substantial knowledge of the incident (e.g. first-hand knowledge, research etc.)"
    },
    "unintendedUse": false,
    "sameAs": "https://incidentdatabase.ai/cite/265"
  },
  {
    "@context": [
      "http://localhost:3000/api/schemas/v1/core/context.jsonld",
      "http://localhost:3001/api/schemas/v1/oecd/context.jsonld"
    ],
    "@type": "oecd:Incident",
    "@id": "https://oecd.ai/incident/OECD-2023-167",
    "incident_id": "OECD-2023-167",
    "title": "AI System Failure Related to Tesla Autopilot Misidentified On-Road Horse-Drawn Carriage",
    "description": "An AI system failure occurred with similar characteristics to the documented incident involving Tesla. The system exhibited comparable failure modes resulting in harm to affected stakeholders.",
    "date": "2023-05-28",
    "aiSystem": {
      "@type": "oecd:AISystem",
      "name": "Intelligent Engine",
      "version": "2.1",
      "relation": [
        "oecd:DirectCause"
      ]
    },
    "developer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/Tesla,_Inc.",
      "name": "Tesla"
    },
    "deployer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/Tesla,_Inc.",
      "name": "Tesla"
    },
    "severity": "oecd:SeriousIncident",
    "harmType": [
      "oecd:OtherHarm"
    ],
    "harmQuantification": {
      "@type": "oecd:HarmQuantification",
      "affected_stakeholders": "38734 individuals"
    },
    "countries": [
      {
        "@type": "core:Country",
        "@id": "https://www.wikidata.org/wiki/India",
        "name": "India"
      }
    ],
    "affectedStakeholders": [
      {
        "@type": "core:Person",
        "@id": "https://example.org/entities/person/tesla-drivers",
        "name": "Tesla drivers"
      },
      {
        "@type": "core:Person",
        "@id": "https://example.org/entities/person/horse-drawn-carriages",
        "name": "horse-drawn carriages"
      }
    ],
    "businessFunction": [
      "oecd:Production"
    ],
    "submitter": {
      "@type": "oecd:Submitter",
      "@id": "https://example.org/submitter/submitter",
      "role": "Ethics Officer",
      "affiliation": "University Research Lab",
      "stakeholderGroup": "I represent a government or regulatory body",
      "relationToIncident": "I am an affected stakeholder"
    },
    "unintendedUse": true,
    "sameAs": "https://incidentdatabase.ai/cite/398"
  },
  {
    "@context": [
      "http://localhost:3000/api/schemas/v1/core/context.jsonld",
      "http://localhost:3001/api/schemas/v1/oecd/context.jsonld"
    ],
    "@type": "oecd:Incident",
    "@id": "https://oecd.ai/incident/OECD-2023-168",
    "incident_id": "OECD-2023-168",
    "title": "Surgical Robot Malfunction During Minimally Invasive Procedure",
    "description": "An AI-assisted surgical robot experienced a control system failure during a procedure, requiring emergency conversion to traditional surgery. The AI's motion planning algorithms failed to account for unexpected tissue resistance.",
    "date": "2023-05-29",
    "aiSystem": {
      "@type": "oecd:AISystem",
      "name": "Medical AI System Pro",
      "version": "3.1.60",
      "relation": [
        "oecd:DirectCause"
      ]
    },
    "developer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/Keolis",
      "name": "Keolis North America"
    },
    "deployer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/Apple_Inc.",
      "name": "Apple"
    },
    "severity": "oecd:SeriousIncident",
    "harmType": [
      "oecd:PhysicalHarm"
    ],
    "harmQuantification": {
      "@type": "oecd:HarmQuantification",
      "affected_stakeholders": "90692 workers",
      "economic_losses": "$39.8 million"
    },
    "countries": [
      {
        "@type": "core:Country",
        "@id": "https://www.wikidata.org/wiki/China",
        "name": "China"
      }
    ],
    "affectedStakeholders": [
      {
        "@type": "core:Person",
        "@id": "https://example.org/entities/person/motorists",
        "name": "Motorists"
      }
    ],
    "businessFunction": [
      "oecd:OtherFunction"
    ],
    "submitter": {
      "@type": "oecd:Submitter",
      "@id": "https://example.org/submitter/reporter",
      "role": "Data Scientist",
      "affiliation": "AI Safety Coalition",
      "stakeholderGroup": "I represent a government or regulatory body",
      "relationToIncident": "None of the above, but have partial or substantial knowledge of the incident (e.g. first-hand knowledge, research etc.)"
    },
    "unintendedUse": false
  },
  {
    "@context": [
      "http://localhost:3000/api/schemas/v1/core/context.jsonld",
      "http://localhost:3001/api/schemas/v1/oecd/context.jsonld"
    ],
    "@type": "oecd:Incident",
    "@id": "https://oecd.ai/incident/OECD-2023-169",
    "incident_id": "OECD-2023-169",
    "title": "AI Diagnostic System Misses Critical Symptoms in Emergency Department",
    "description": "An AI triage system in emergency departments failed to identify critical symptoms in patients presenting with atypical manifestations of serious conditions. The system's training data lacked diversity in symptom presentations across different demographics.",
    "date": "2023-06-04",
    "aiSystem": {
      "@type": "oecd:AISystem",
      "name": "Medical AI Platform",
      "version": "5.13.17",
      "relation": [
        "oecd:ContributingFactor",
        "oecd:HumanError"
      ]
    },
    "developer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/Keolis",
      "name": "Keolis North America"
    },
    "deployer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/Youth_Laboratories",
      "name": "Youth Laboratories"
    },
    "severity": "oecd:SeriousHazard",
    "harmType": [
      "oecd:PhysicalHarm",
      "oecd:HumanRightsHarm"
    ],
    "harmQuantification": {
      "@type": "oecd:HarmQuantification",
      "affected_stakeholders": "4560 workers"
    },
    "countries": [
      {
        "@type": "core:Country",
        "@id": "https://www.wikidata.org/wiki/Israel",
        "name": "Israel"
      },
      {
        "@type": "core:Country",
        "@id": "https://www.wikidata.org/wiki/Norway",
        "name": "Norway"
      }
    ],
    "affectedStakeholders": [
      {
        "@type": "oecd:StakeholderGroup",
        "@id": "https://example.org/stakeholder-group/women",
        "name": "Women"
      }
    ],
    "businessFunction": [
      "oecd:OtherFunction"
    ],
    "submitter": {
      "@type": "oecd:Submitter",
      "@id": "https://example.org/submitter/reporter",
      "role": "Industry Whistleblower",
      "affiliation": "Digital Rights Organization",
      "stakeholderGroup": "I work or am affiliated to a public interest body or NGO",
      "relationToIncident": "None of the above, but have partial or substantial knowledge of the incident (e.g. first-hand knowledge, research etc.)"
    },
    "unintendedUse": false
  },
  {
    "@context": [
      "http://localhost:3000/api/schemas/v1/core/context.jsonld",
      "http://localhost:3001/api/schemas/v1/oecd/context.jsonld"
    ],
    "@type": "oecd:Incident",
    "@id": "https://oecd.ai/incident/OECD-2023-170",
    "incident_id": "OECD-2023-170",
    "title": "AI System Failure Related to Tesla Autopilot Misidentified On-Road Horse-Drawn Carriage",
    "description": "An AI system failure occurred with similar characteristics to the documented incident involving Tesla. The system exhibited comparable failure modes resulting in harm to affected stakeholders.",
    "date": "2023-06-20",
    "aiSystem": {
      "@type": "oecd:AISystem",
      "name": "Smart System",
      "version": "2.2",
      "relation": [
        "oecd:DirectCause"
      ]
    },
    "developer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/Tesla,_Inc.",
      "name": "Tesla"
    },
    "deployer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/Tesla,_Inc.",
      "name": "Tesla"
    },
    "severity": "oecd:SeriousIncident",
    "harmType": [
      "oecd:OtherHarm"
    ],
    "harmQuantification": {
      "@type": "oecd:HarmQuantification",
      "affected_stakeholders": "31734 individuals",
      "economic_losses": "$3 million"
    },
    "countries": [
      {
        "@type": "core:Country",
        "@id": "https://www.wikidata.org/wiki/Sweden",
        "name": "Sweden"
      },
      {
        "@type": "core:Country",
        "@id": "https://www.wikidata.org/wiki/United_Kingdom",
        "name": "United Kingdom"
      }
    ],
    "affectedStakeholders": [
      {
        "@type": "core:Person",
        "@id": "https://example.org/entities/person/tesla-drivers",
        "name": "Tesla drivers"
      },
      {
        "@type": "core:Person",
        "@id": "https://example.org/entities/person/horse-drawn-carriages",
        "name": "horse-drawn carriages"
      }
    ],
    "businessFunction": [
      "oecd:CustomerService",
      "oecd:Planning"
    ],
    "submitter": {
      "@type": "oecd:Submitter",
      "@id": "https://example.org/submitter/submitter",
      "role": "Academic Researcher",
      "affiliation": "AI Safety Institute",
      "stakeholderGroup": "I work or am affiliated to a public interest body or NGO",
      "relationToIncident": "None of the above, but have partial or substantial knowledge of the incident (e.g. first-hand knowledge, research etc.)"
    },
    "unintendedUse": false,
    "sameAs": "https://incidentdatabase.ai/cite/398"
  },
  {
    "@context": [
      "http://localhost:3000/api/schemas/v1/core/context.jsonld",
      "http://localhost:3001/api/schemas/v1/oecd/context.jsonld"
    ],
    "@type": "oecd:Incident",
    "@id": "https://oecd.ai/incident/OECD-2023-171",
    "incident_id": "OECD-2023-171",
    "title": "AI System Failure Related to Black Uber Eats Driver Allegedly Subjected to Excessive Photo Checks and Dismissed via FRT Results",
    "description": "An AI system failure occurred with similar characteristics to the documented incident involving Uber Eats. The system exhibited comparable failure modes resulting in harm to affected stakeholders.",
    "date": "2023-07-19",
    "aiSystem": {
      "@type": "oecd:AISystem",
      "name": "Smart Solution",
      "version": "3.6",
      "relation": [
        "oecd:DirectCause"
      ]
    },
    "developer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/Uber_Eats",
      "name": "Uber Eats"
    },
    "deployer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/Uber_Eats",
      "name": "Uber Eats"
    },
    "severity": "oecd:SeriousIncident",
    "harmType": [
      "oecd:OtherHarm"
    ],
    "harmQuantification": {
      "@type": "oecd:HarmQuantification",
      "affected_stakeholders": "32078 individuals",
      "economic_losses": "$5 million"
    },
    "countries": [
      {
        "@type": "core:Country",
        "@id": "https://www.wikidata.org/wiki/Canada",
        "name": "Canada"
      },
      {
        "@type": "core:Country",
        "@id": "https://www.wikidata.org/wiki/Italy",
        "name": "Italy"
      }
    ],
    "affectedStakeholders": [
      {
        "@type": "core:Person",
        "@id": "https://example.org/entities/person/uber-eats-black-delivery-drivers",
        "name": "Uber Eats Black delivery drivers"
      },
      {
        "@type": "core:Person",
        "@id": "https://example.org/entities/person/pa-edrissa-manjang",
        "name": "Pa Edrissa Manjang"
      }
    ],
    "businessFunction": [
      "oecd:CustomerService",
      "oecd:Procurement"
    ],
    "submitter": {
      "@type": "oecd:Submitter",
      "@id": "https://example.org/submitter/submitter",
      "role": "Industry Analyst",
      "affiliation": "Government Oversight Committee",
      "stakeholderGroup": "I work or am affiliated to a public interest body or NGO",
      "relationToIncident": "I am a user of the related AI system"
    },
    "unintendedUse": false,
    "sameAs": "https://incidentdatabase.ai/cite/265"
  },
  {
    "@context": [
      "http://localhost:3000/api/schemas/v1/core/context.jsonld",
      "http://localhost:3001/api/schemas/v1/oecd/context.jsonld"
    ],
    "@type": "oecd:Incident",
    "@id": "https://oecd.ai/incident/OECD-2023-172",
    "incident_id": "OECD-2023-172",
    "title": "AI System Failure Related to AI-Generated Fake Audio of Verbal Abuse Incident Circulates of British Labour Leader Keir Starmer",
    "description": "An AI system failure occurred with similar characteristics to the documented incident involving unknown. The system exhibited comparable failure modes resulting in harm to affected stakeholders.",
    "date": "2023-08-03",
    "aiSystem": {
      "@type": "oecd:AISystem",
      "name": "AI System",
      "version": "5.0",
      "relation": [
        "oecd:DirectCause"
      ]
    },
    "developer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/unknown",
      "name": "unknown"
    },
    "deployer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/unknown",
      "name": "unknown"
    },
    "severity": "oecd:SeriousIncident",
    "harmType": [
      "oecd:OtherHarm"
    ],
    "harmQuantification": {
      "@type": "oecd:HarmQuantification",
      "affected_stakeholders": "45023 individuals"
    },
    "countries": [
      {
        "@type": "core:Country",
        "@id": "https://www.wikidata.org/wiki/Netherlands",
        "name": "Netherlands"
      },
      {
        "@type": "core:Country",
        "@id": "https://www.wikidata.org/wiki/Spain",
        "name": "Spain"
      },
      {
        "@type": "core:Country",
        "@id": "https://www.wikidata.org/wiki/United_States",
        "name": "United States"
      }
    ],
    "affectedStakeholders": [
      {
        "@type": "core:Person",
        "@id": "https://example.org/entities/person/uk-labour-party",
        "name": "UK Labour Party"
      },
      {
        "@type": "core:Person",
        "@id": "https://example.org/entities/person/keir-starmer",
        "name": "Keir Starmer"
      }
    ],
    "businessFunction": [
      "oecd:CustomerService"
    ],
    "submitter": {
      "@type": "oecd:Submitter",
      "@id": "https://example.org/submitter/submitter",
      "role": "AI Safety Researcher",
      "affiliation": "AI Safety Institute",
      "stakeholderGroup": "None of the above, but have partial or substantial knowledge of the incident",
      "relationToIncident": "I am a user of the related AI system"
    },
    "unintendedUse": false,
    "sameAs": "https://incidentdatabase.ai/cite/601"
  },
  {
    "@context": [
      "http://localhost:3000/api/schemas/v1/core/context.jsonld",
      "http://localhost:3001/api/schemas/v1/oecd/context.jsonld"
    ],
    "@type": "oecd:Incident",
    "@id": "https://oecd.ai/incident/OECD-2023-173",
    "incident_id": "OECD-2023-173",
    "title": "AI System Failure Related to Tesla Autopilot Misidentified On-Road Horse-Drawn Carriage",
    "description": "An AI system failure occurred with similar characteristics to the documented incident involving Tesla. The system exhibited comparable failure modes resulting in harm to affected stakeholders.",
    "date": "2023-08-07",
    "aiSystem": {
      "@type": "oecd:AISystem",
      "name": "Smart Solution",
      "version": "5.2",
      "relation": [
        "oecd:DirectCause"
      ]
    },
    "developer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/Tesla,_Inc.",
      "name": "Tesla"
    },
    "deployer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/Tesla,_Inc.",
      "name": "Tesla"
    },
    "severity": "oecd:SeriousIncident",
    "harmType": [
      "oecd:OtherHarm"
    ],
    "harmQuantification": {
      "@type": "oecd:HarmQuantification",
      "affected_stakeholders": "40211 individuals",
      "economic_losses": "$2 million"
    },
    "countries": [
      {
        "@type": "core:Country",
        "@id": "https://www.wikidata.org/wiki/France",
        "name": "France"
      },
      {
        "@type": "core:Country",
        "@id": "https://www.wikidata.org/wiki/Germany",
        "name": "Germany"
      }
    ],
    "affectedStakeholders": [
      {
        "@type": "core:Person",
        "@id": "https://example.org/entities/person/tesla-drivers",
        "name": "Tesla drivers"
      },
      {
        "@type": "core:Person",
        "@id": "https://example.org/entities/person/horse-drawn-carriages",
        "name": "horse-drawn carriages"
      }
    ],
    "businessFunction": [
      "oecd:Accounting",
      "oecd:ResearchDevelopment"
    ],
    "submitter": {
      "@type": "oecd:Submitter",
      "@id": "https://example.org/submitter/submitter",
      "role": "Academic Researcher",
      "affiliation": "University Research Lab",
      "stakeholderGroup": "I represent a government or regulatory body",
      "relationToIncident": "None of the above, but have partial or substantial knowledge of the incident (e.g. first-hand knowledge, research etc.)"
    },
    "unintendedUse": true,
    "sameAs": "https://incidentdatabase.ai/cite/398"
  },
  {
    "@context": [
      "http://localhost:3000/api/schemas/v1/core/context.jsonld",
      "http://localhost:3001/api/schemas/v1/oecd/context.jsonld"
    ],
    "@type": "oecd:Incident",
    "@id": "https://oecd.ai/incident/OECD-2023-174",
    "incident_id": "OECD-2023-174",
    "title": "AI System Failure Related to Female Celebrities' Faces Shown in Sexually Suggestive Ads for Deepfake App",
    "description": "An AI system failure occurred with similar characteristics to the documented incident involving Facemega. The system exhibited comparable failure modes resulting in harm to affected stakeholders.",
    "date": "2023-08-25",
    "aiSystem": {
      "@type": "oecd:AISystem",
      "name": "Smart System",
      "version": "1.3",
      "relation": [
        "oecd:DirectCause"
      ]
    },
    "developer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/Facemega",
      "name": "Facemega"
    },
    "deployer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/Facemega",
      "name": "Facemega"
    },
    "severity": "oecd:SeriousIncident",
    "harmType": [
      "oecd:OtherHarm"
    ],
    "harmQuantification": {
      "@type": "oecd:HarmQuantification",
      "affected_stakeholders": "48236 individuals",
      "economic_losses": "$3 million"
    },
    "countries": [
      {
        "@type": "core:Country",
        "@id": "https://www.wikidata.org/wiki/South_Korea",
        "name": "South Korea"
      },
      {
        "@type": "core:Country",
        "@id": "https://www.wikidata.org/wiki/France",
        "name": "France"
      }
    ],
    "affectedStakeholders": [
      {
        "@type": "core:Person",
        "@id": "https://example.org/entities/person/scarlett-johansson",
        "name": "Scarlett Johansson"
      },
      {
        "@type": "core:Person",
        "@id": "https://example.org/entities/person/female-celebrities",
        "name": "female celebrities"
      },
      {
        "@type": "core:Person",
        "@id": "https://example.org/entities/person/emma-watson",
        "name": "Emma Watson"
      }
    ],
    "businessFunction": [
      "oecd:Marketing",
      "oecd:ResearchDevelopment"
    ],
    "submitter": {
      "@type": "oecd:Submitter",
      "@id": "https://example.org/submitter/submitter",
      "role": "Ethics Officer",
      "affiliation": "AI Safety Institute",
      "stakeholderGroup": "I represent a government or regulatory body",
      "relationToIncident": "None of the above, but have partial or substantial knowledge of the incident (e.g. first-hand knowledge, research etc.)"
    },
    "unintendedUse": true,
    "sameAs": "https://incidentdatabase.ai/cite/494"
  },
  {
    "@context": [
      "http://localhost:3000/api/schemas/v1/core/context.jsonld",
      "http://localhost:3001/api/schemas/v1/oecd/context.jsonld"
    ],
    "@type": "oecd:Incident",
    "@id": "https://oecd.ai/incident/OECD-2023-175",
    "incident_id": "OECD-2023-175",
    "title": "AI System Failure Related to Fake LinkedIn Profiles Created Using GAN Photos",
    "description": "An AI system failure occurred with similar characteristics to the documented incident involving unknown. The system exhibited comparable failure modes resulting in harm to affected stakeholders.",
    "date": "2023-08-30",
    "aiSystem": {
      "@type": "oecd:AISystem",
      "name": "Smart Solution",
      "version": "2.1",
      "relation": [
        "oecd:DirectCause"
      ]
    },
    "developer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/unknown",
      "name": "unknown"
    },
    "deployer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/unknown",
      "name": "unknown"
    },
    "severity": "oecd:SeriousIncident",
    "harmType": [
      "oecd:OtherHarm"
    ],
    "harmQuantification": {
      "@type": "oecd:HarmQuantification",
      "affected_stakeholders": "18392 individuals",
      "economic_losses": "$9 million"
    },
    "countries": [
      {
        "@type": "core:Country",
        "@id": "https://www.wikidata.org/wiki/Canada",
        "name": "Canada"
      },
      {
        "@type": "core:Country",
        "@id": "https://www.wikidata.org/wiki/Sweden",
        "name": "Sweden"
      }
    ],
    "affectedStakeholders": [
      {
        "@type": "oecd:StakeholderGroup",
        "@id": "https://example.org/stakeholder-group/linkedin-users",
        "name": "LinkedIn users"
      }
    ],
    "businessFunction": [
      "oecd:Production",
      "oecd:ResearchDevelopment"
    ],
    "submitter": {
      "@type": "oecd:Submitter",
      "@id": "https://example.org/submitter/submitter",
      "role": "Academic Researcher",
      "affiliation": "Government Oversight Committee",
      "stakeholderGroup": "I represent a government or regulatory body",
      "relationToIncident": "I am an affected stakeholder"
    },
    "unintendedUse": true,
    "sameAs": "https://incidentdatabase.ai/cite/174"
  },
  {
    "@context": [
      "http://localhost:3000/api/schemas/v1/core/context.jsonld",
      "http://localhost:3001/api/schemas/v1/oecd/context.jsonld"
    ],
    "@type": "oecd:Incident",
    "@id": "https://oecd.ai/incident/OECD-2023-176",
    "incident_id": "OECD-2023-176",
    "title": "AI System Failure Related to Glovo Driver in Italy Fired via Automated Email after Being Killed in Accident",
    "description": "An AI system failure occurred with similar characteristics to the documented incident involving Glovo. The system exhibited comparable failure modes resulting in harm to affected stakeholders.",
    "date": "2023-09-23",
    "aiSystem": {
      "@type": "oecd:AISystem",
      "name": "Automated System",
      "version": "2.1",
      "relation": [
        "oecd:DirectCause"
      ]
    },
    "developer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/Glovo",
      "name": "Glovo"
    },
    "deployer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/Glovo",
      "name": "Glovo"
    },
    "severity": "oecd:SeriousIncident",
    "harmType": [
      "oecd:OtherHarm"
    ],
    "harmQuantification": {
      "@type": "oecd:HarmQuantification",
      "affected_stakeholders": "8511 individuals"
    },
    "countries": [
      {
        "@type": "core:Country",
        "@id": "https://www.wikidata.org/wiki/Israel",
        "name": "Israel"
      }
    ],
    "affectedStakeholders": [
      {
        "@type": "core:Person",
        "@id": "https://example.org/entities/person/sebastian-galassi-s-family",
        "name": "Sebastian Galassi's family"
      },
      {
        "@type": "core:Person",
        "@id": "https://example.org/entities/person/sebastian-galassi",
        "name": "Sebastian Galassi"
      }
    ],
    "businessFunction": [
      "oecd:Marketing"
    ],
    "submitter": {
      "@type": "oecd:Submitter",
      "@id": "https://example.org/submitter/submitter",
      "role": "Industry Analyst",
      "affiliation": "Government Oversight Committee",
      "stakeholderGroup": "None of the above, but have partial or substantial knowledge of the incident",
      "relationToIncident": "I am a user of the related AI system"
    },
    "unintendedUse": false,
    "sameAs": "https://incidentdatabase.ai/cite/384"
  },
  {
    "@context": [
      "http://localhost:3000/api/schemas/v1/core/context.jsonld",
      "http://localhost:3001/api/schemas/v1/oecd/context.jsonld"
    ],
    "@type": "oecd:Incident",
    "@id": "https://oecd.ai/incident/OECD-2023-177",
    "incident_id": "OECD-2023-177",
    "title": "AI System Failure Related to Stable Diffusion Abused by 4chan Users to Deepfake Celebrity Porn",
    "description": "An AI system failure occurred with similar characteristics to the documented incident involving Stability AI. The system exhibited comparable failure modes resulting in harm to affected stakeholders.",
    "date": "2023-09-24",
    "aiSystem": {
      "@type": "oecd:AISystem",
      "name": "Smart System",
      "version": "5.9",
      "relation": [
        "oecd:DirectCause"
      ]
    },
    "developer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/Stability_AI",
      "name": "Stability AI"
    },
    "deployer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/Stability_AI",
      "name": "Stability AI"
    },
    "severity": "oecd:SeriousIncident",
    "harmType": [
      "oecd:OtherHarm"
    ],
    "harmQuantification": {
      "@type": "oecd:HarmQuantification",
      "affected_stakeholders": "16459 individuals"
    },
    "countries": [
      {
        "@type": "core:Country",
        "@id": "https://www.wikidata.org/wiki/United_States",
        "name": "United States"
      }
    ],
    "affectedStakeholders": [
      {
        "@type": "core:Person",
        "@id": "https://example.org/entities/person/stability-ai",
        "name": "Stability AI"
      },
      {
        "@type": "core:Person",
        "@id": "https://example.org/entities/person/deepfaked-celebrities",
        "name": "deepfaked celebrities"
      }
    ],
    "businessFunction": [
      "oecd:Accounting",
      "oecd:Production"
    ],
    "submitter": {
      "@type": "oecd:Submitter",
      "@id": "https://example.org/submitter/submitter",
      "role": "Journalist",
      "affiliation": "University Research Lab",
      "stakeholderGroup": "I represent a government or regulatory body",
      "relationToIncident": "I am a user of the related AI system"
    },
    "unintendedUse": false,
    "sameAs": "https://incidentdatabase.ai/cite/314"
  },
  {
    "@context": [
      "http://localhost:3000/api/schemas/v1/core/context.jsonld",
      "http://localhost:3001/api/schemas/v1/oecd/context.jsonld"
    ],
    "@type": "oecd:Incident",
    "@id": "https://oecd.ai/incident/OECD-2023-178",
    "incident_id": "OECD-2023-178",
    "title": "AI Diagnostic System Misses Critical Symptoms in Emergency Department",
    "description": "An AI triage system in emergency departments failed to identify critical symptoms in patients presenting with atypical manifestations of serious conditions. The system's training data lacked diversity in symptom presentations across different demographics.",
    "date": "2023-09-24",
    "aiSystem": {
      "@type": "oecd:AISystem",
      "name": "Medical AI Engine Pro",
      "version": "9.8.73",
      "relation": [
        "oecd:DirectCause",
        "oecd:FailureToAct"
      ]
    },
    "developer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/Uber",
      "name": "Uber"
    },
    "deployer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/Google",
      "name": "Google"
    },
    "severity": "oecd:SeriousHazard",
    "harmType": [
      "oecd:PhysicalHarm",
      "oecd:HumanRightsHarm"
    ],
    "harmQuantification": {
      "@type": "oecd:HarmQuantification",
      "affected_stakeholders": "81772 users",
      "economic_losses": "$21.2 million"
    },
    "countries": [
      {
        "@type": "core:Country",
        "@id": "https://www.wikidata.org/wiki/Spain",
        "name": "Spain"
      },
      {
        "@type": "core:Country",
        "@id": "https://www.wikidata.org/wiki/United_States",
        "name": "United States"
      }
    ],
    "affectedStakeholders": [
      {
        "@type": "core:Person",
        "@id": "https://example.org/entities/person/medical-residents",
        "name": "Medical Residents"
      },
      {
        "@type": "core:Person",
        "@id": "https://example.org/entities/person/job-applicants",
        "name": "Job applicants"
      },
      {
        "@type": "oecd:StakeholderGroup",
        "@id": "https://example.org/stakeholder-group/patients",
        "name": "Patients"
      }
    ],
    "businessFunction": [
      "oecd:OtherFunction"
    ],
    "submitter": {
      "@type": "oecd:Submitter",
      "@id": "https://example.org/submitter/reporter",
      "role": "Data Scientist",
      "affiliation": "Digital Rights Organization",
      "stakeholderGroup": "None of the above, but have partial or substantial knowledge of the incident",
      "relationToIncident": "None of the above, but have partial or substantial knowledge of the incident (e.g. first-hand knowledge, research etc.)"
    },
    "unintendedUse": false
  },
  {
    "@context": [
      "http://localhost:3000/api/schemas/v1/core/context.jsonld",
      "http://localhost:3001/api/schemas/v1/oecd/context.jsonld"
    ],
    "@type": "oecd:Incident",
    "@id": "https://oecd.ai/incident/OECD-2023-179",
    "incident_id": "OECD-2023-179",
    "title": "Delivery Robot Swarm Blocks Emergency Vehicle Access",
    "description": "A fleet of autonomous delivery robots failed to coordinate their movements during an emergency, blocking paramedic access to a medical emergency. The swarm intelligence system lacked proper emergency vehicle detection and response protocols.",
    "date": "2023-10-06",
    "aiSystem": {
      "@type": "oecd:AISystem",
      "name": "Autonomous Systems Engine Pro",
      "version": "7.4.37",
      "relation": [
        "oecd:ContributingFactor"
      ]
    },
    "developer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/Apple_Inc.",
      "name": "Apple"
    },
    "deployer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/United_States_Government",
      "name": "United States Government"
    },
    "severity": "oecd:SeriousHazard",
    "harmType": [
      "oecd:PhysicalHarm",
      "oecd:PublicInterestHarm"
    ],
    "harmQuantification": {
      "@type": "oecd:HarmQuantification",
      "affected_stakeholders": "5934 workers",
      "economic_losses": "$9.9 million"
    },
    "countries": [
      {
        "@type": "core:Country",
        "@id": "https://www.wikidata.org/wiki/China",
        "name": "China"
      }
    ],
    "affectedStakeholders": [
      {
        "@type": "oecd:StakeholderGroup",
        "@id": "https://example.org/stakeholder-group/women",
        "name": "Women"
      }
    ],
    "businessFunction": [
      "oecd:Logistics",
      "oecd:OtherFunction"
    ],
    "submitter": {
      "@type": "oecd:Submitter",
      "@id": "https://example.org/submitter/reporter",
      "role": "Government Auditor",
      "affiliation": "Tech Accountability Project",
      "stakeholderGroup": "I work or am affiliated to a public interest body or NGO",
      "relationToIncident": "None of the above, but have partial or substantial knowledge of the incident (e.g. first-hand knowledge, research etc.)"
    },
    "unintendedUse": false
  },
  {
    "@context": [
      "http://localhost:3000/api/schemas/v1/core/context.jsonld",
      "http://localhost:3001/api/schemas/v1/oecd/context.jsonld"
    ],
    "@type": "oecd:Incident",
    "@id": "https://oecd.ai/incident/OECD-2023-180",
    "incident_id": "OECD-2023-180",
    "title": "AI System Failure Related to Bankrate's Resumption of AI-Generated Content Allegedly Continuing to Produce Inaccurate and Misleading Information",
    "description": "An AI system failure occurred with similar characteristics to the documented incident involving Red Ventures. The system exhibited comparable failure modes resulting in harm to affected stakeholders.",
    "date": "2023-10-29",
    "aiSystem": {
      "@type": "oecd:AISystem",
      "name": "Smart Solution",
      "version": "5.1",
      "relation": [
        "oecd:DirectCause"
      ]
    },
    "developer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/Red_Ventures",
      "name": "Red Ventures"
    },
    "deployer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/Red_Ventures",
      "name": "Red Ventures"
    },
    "severity": "oecd:SeriousIncident",
    "harmType": [
      "oecd:OtherHarm"
    ],
    "harmQuantification": {
      "@type": "oecd:HarmQuantification",
      "affected_stakeholders": "8615 individuals"
    },
    "countries": [
      {
        "@type": "core:Country",
        "@id": "https://www.wikidata.org/wiki/France",
        "name": "France"
      },
      {
        "@type": "core:Country",
        "@id": "https://www.wikidata.org/wiki/Australia",
        "name": "Australia"
      },
      {
        "@type": "core:Country",
        "@id": "https://www.wikidata.org/wiki/Germany",
        "name": "Germany"
      }
    ],
    "affectedStakeholders": [
      {
        "@type": "core:Person",
        "@id": "https://example.org/entities/person/journalistic-integrity",
        "name": "Journalistic integrity"
      },
      {
        "@type": "oecd:StakeholderGroup",
        "@id": "https://example.org/stakeholder-group/general-public",
        "name": "General public"
      }
    ],
    "businessFunction": [
      "oecd:Production"
    ],
    "submitter": {
      "@type": "oecd:Submitter",
      "@id": "https://example.org/submitter/submitter",
      "role": "Industry Analyst",
      "affiliation": "Digital Rights Foundation",
      "stakeholderGroup": "None of the above, but have partial or substantial knowledge of the incident",
      "relationToIncident": "I am an affected stakeholder"
    },
    "unintendedUse": true,
    "sameAs": "https://incidentdatabase.ai/cite/577"
  },
  {
    "@context": [
      "http://localhost:3000/api/schemas/v1/core/context.jsonld",
      "http://localhost:3001/api/schemas/v1/oecd/context.jsonld"
    ],
    "@type": "oecd:Incident",
    "@id": "https://oecd.ai/incident/OECD-2023-181",
    "incident_id": "OECD-2023-181",
    "title": "AI System Failure Related to Fake LinkedIn Profiles Created Using GAN Photos",
    "description": "An AI system failure occurred with similar characteristics to the documented incident involving unknown. The system exhibited comparable failure modes resulting in harm to affected stakeholders.",
    "date": "2023-12-02",
    "aiSystem": {
      "@type": "oecd:AISystem",
      "name": "Intelligent Solution",
      "version": "5.2",
      "relation": [
        "oecd:DirectCause"
      ]
    },
    "developer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/unknown",
      "name": "unknown"
    },
    "deployer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/unknown",
      "name": "unknown"
    },
    "severity": "oecd:SeriousIncident",
    "harmType": [
      "oecd:OtherHarm"
    ],
    "harmQuantification": {
      "@type": "oecd:HarmQuantification",
      "affected_stakeholders": "3102 individuals",
      "economic_losses": "$8 million"
    },
    "countries": [
      {
        "@type": "core:Country",
        "@id": "https://www.wikidata.org/wiki/France",
        "name": "France"
      },
      {
        "@type": "core:Country",
        "@id": "https://www.wikidata.org/wiki/Norway",
        "name": "Norway"
      },
      {
        "@type": "core:Country",
        "@id": "https://www.wikidata.org/wiki/Spain",
        "name": "Spain"
      }
    ],
    "affectedStakeholders": [
      {
        "@type": "oecd:StakeholderGroup",
        "@id": "https://example.org/stakeholder-group/linkedin-users",
        "name": "LinkedIn users"
      }
    ],
    "businessFunction": [
      "oecd:Planning"
    ],
    "submitter": {
      "@type": "oecd:Submitter",
      "@id": "https://example.org/submitter/submitter",
      "role": "Government Inspector",
      "affiliation": "Digital Rights Foundation",
      "stakeholderGroup": "I represent a government or regulatory body",
      "relationToIncident": "I am an affected stakeholder"
    },
    "unintendedUse": false,
    "sameAs": "https://incidentdatabase.ai/cite/174"
  },
  {
    "@context": [
      "http://localhost:3000/api/schemas/v1/core/context.jsonld",
      "http://localhost:3001/api/schemas/v1/oecd/context.jsonld"
    ],
    "@type": "oecd:Incident",
    "@id": "https://oecd.ai/incident/OECD-2023-182",
    "incident_id": "OECD-2023-182",
    "title": "AI Diagnostic System Misses Critical Symptoms in Emergency Department",
    "description": "An AI triage system in emergency departments failed to identify critical symptoms in patients presenting with atypical manifestations of serious conditions. The system's training data lacked diversity in symptom presentations across different demographics.",
    "date": "2023-12-07",
    "aiSystem": {
      "@type": "oecd:AISystem",
      "name": "Medical AI Engine",
      "version": "4.7.59",
      "relation": [
        "oecd:DirectCause"
      ]
    },
    "developer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/Uber",
      "name": "Uber"
    },
    "deployer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/Navya_(company)",
      "name": "Navya"
    },
    "severity": "oecd:SeriousHazard",
    "harmType": [
      "oecd:PhysicalHarm",
      "oecd:HumanRightsHarm"
    ],
    "harmQuantification": {
      "@type": "oecd:HarmQuantification",
      "affected_stakeholders": "18347 individuals"
    },
    "countries": [
      {
        "@type": "core:Country",
        "@id": "https://www.wikidata.org/wiki/Israel",
        "name": "Israel"
      }
    ],
    "affectedStakeholders": [
      {
        "@type": "oecd:StakeholderGroup",
        "@id": "https://example.org/stakeholder-group/children",
        "name": "Children"
      },
      {
        "@type": "core:Person",
        "@id": "https://example.org/entities/person/black-people",
        "name": "Black people"
      },
      {
        "@type": "core:Person",
        "@id": "https://example.org/entities/person/motorists",
        "name": "Motorists"
      }
    ],
    "businessFunction": [
      "oecd:OtherFunction"
    ],
    "submitter": {
      "@type": "oecd:Submitter",
      "@id": "https://example.org/submitter/reporter",
      "role": "Data Scientist",
      "affiliation": "Consumer Protection Agency",
      "stakeholderGroup": "I am an affected stakeholder",
      "relationToIncident": "None of the above, but have partial or substantial knowledge of the incident (e.g. first-hand knowledge, research etc.)"
    },
    "unintendedUse": false
  },
  {
    "@context": [
      "http://localhost:3000/api/schemas/v1/core/context.jsonld",
      "http://localhost:3001/api/schemas/v1/oecd/context.jsonld"
    ],
    "@type": "oecd:Incident",
    "@id": "https://oecd.ai/incident/OECD-2023-183",
    "incident_id": "OECD-2023-183",
    "title": "AI Credit Scoring System Discriminates Against Recent Immigrants",
    "description": "An automated credit scoring system systematically assigned lower credit scores to recent immigrants despite strong financial indicators. The AI model heavily weighted credit history length, creating unfair barriers to financial services.",
    "date": "2023-12-26",
    "aiSystem": {
      "@type": "oecd:AISystem",
      "name": "Financial AI Engine Pro",
      "version": "10.3.46",
      "relation": [
        "oecd:DirectCause",
        "oecd:ContributingFactor"
      ]
    },
    "developer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/Navya_(company)",
      "name": "Navya"
    },
    "deployer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/Delphi_Technologies",
      "name": "Delphi Technologies"
    },
    "severity": "oecd:SeriousIncident",
    "harmType": [
      "oecd:EconomicHarm",
      "oecd:HumanRightsHarm"
    ],
    "harmQuantification": {
      "@type": "oecd:HarmQuantification",
      "affected_stakeholders": "67251 users",
      "economic_losses": "$26.0 million"
    },
    "countries": [
      {
        "@type": "core:Country",
        "@id": "https://www.wikidata.org/wiki/Sweden",
        "name": "Sweden"
      }
    ],
    "affectedStakeholders": [
      {
        "@type": "core:Person",
        "@id": "https://example.org/entities/person/bus-passengers",
        "name": "Bus passengers"
      },
      {
        "@type": "oecd:StakeholderGroup",
        "@id": "https://example.org/stakeholder-group/minority-groups",
        "name": "Minority Groups"
      }
    ],
    "businessFunction": [
      "oecd:OtherFunction"
    ],
    "submitter": {
      "@type": "oecd:Submitter",
      "@id": "https://example.org/submitter/reporter",
      "role": "Consumer Advocate",
      "affiliation": "Digital Rights Organization",
      "stakeholderGroup": "I work or am affiliated to a public interest body or NGO",
      "relationToIncident": "None of the above, but have partial or substantial knowledge of the incident (e.g. first-hand knowledge, research etc.)"
    },
    "unintendedUse": false
  },
  {
    "@context": [
      "http://localhost:3000/api/schemas/v1/core/context.jsonld",
      "http://localhost:3001/api/schemas/v1/oecd/context.jsonld"
    ],
    "@type": "oecd:Incident",
    "@id": "https://oecd.ai/incident/OECD-2023-184",
    "incident_id": "OECD-2023-184",
    "title": "Facial Recognition System Falsely Identifies Protesters as Criminals",
    "description": "A law enforcement facial recognition system incorrectly matched peaceful protesters with criminal database entries, leading to wrongful detentions. The AI system showed higher error rates for certain ethnic groups and in crowded scenarios.",
    "date": "2023-12-27",
    "aiSystem": {
      "@type": "oecd:AISystem",
      "name": "Security/Surveillance Solution Pro",
      "version": "6.10.73",
      "relation": [
        "oecd:DirectCause"
      ]
    },
    "developer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/Uber",
      "name": "Uber"
    },
    "deployer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/Northpointe",
      "name": "Northpointe"
    },
    "severity": "oecd:SeriousIncident",
    "harmType": [
      "oecd:PhysicalHarm",
      "oecd:HumanRightsHarm",
      "oecd:ReputationalHarm"
    ],
    "harmQuantification": {
      "@type": "oecd:HarmQuantification",
      "affected_stakeholders": "30474 customers",
      "economic_losses": "$12.9 million"
    },
    "countries": [
      {
        "@type": "core:Country",
        "@id": "https://www.wikidata.org/wiki/Brazil",
        "name": "Brazil"
      }
    ],
    "affectedStakeholders": [
      {
        "@type": "core:Person",
        "@id": "https://example.org/entities/person/motorists",
        "name": "Motorists"
      }
    ],
    "businessFunction": [
      "oecd:Compliance"
    ],
    "submitter": {
      "@type": "oecd:Submitter",
      "@id": "https://example.org/submitter/reporter",
      "role": "Data Scientist",
      "affiliation": "Tech Accountability Project",
      "stakeholderGroup": "I am an affected stakeholder",
      "relationToIncident": "None of the above, but have partial or substantial knowledge of the incident (e.g. first-hand knowledge, research etc.)"
    },
    "unintendedUse": true
  },
  {
    "@context": [
      "http://localhost:3000/api/schemas/v1/core/context.jsonld",
      "http://localhost:3001/api/schemas/v1/oecd/context.jsonld"
    ],
    "@type": "oecd:Incident",
    "@id": "https://oecd.ai/incident/OECD-2023-185",
    "incident_id": "OECD-2023-185",
    "title": "AI System Failure Related to Stable Diffusion Abused by 4chan Users to Deepfake Celebrity Porn",
    "description": "An AI system failure occurred with similar characteristics to the documented incident involving Stability AI. The system exhibited comparable failure modes resulting in harm to affected stakeholders.",
    "date": "2023-12-30",
    "aiSystem": {
      "@type": "oecd:AISystem",
      "name": "Smart Platform",
      "version": "3.3",
      "relation": [
        "oecd:DirectCause"
      ]
    },
    "developer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/Stability_AI",
      "name": "Stability AI"
    },
    "deployer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/Stability_AI",
      "name": "Stability AI"
    },
    "severity": "oecd:SeriousIncident",
    "harmType": [
      "oecd:OtherHarm"
    ],
    "harmQuantification": {
      "@type": "oecd:HarmQuantification",
      "affected_stakeholders": "21725 individuals"
    },
    "countries": [
      {
        "@type": "core:Country",
        "@id": "https://www.wikidata.org/wiki/France",
        "name": "France"
      },
      {
        "@type": "core:Country",
        "@id": "https://www.wikidata.org/wiki/South_Korea",
        "name": "South Korea"
      }
    ],
    "affectedStakeholders": [
      {
        "@type": "core:Person",
        "@id": "https://example.org/entities/person/stability-ai",
        "name": "Stability AI"
      },
      {
        "@type": "core:Person",
        "@id": "https://example.org/entities/person/deepfaked-celebrities",
        "name": "deepfaked celebrities"
      }
    ],
    "businessFunction": [
      "oecd:Marketing",
      "oecd:Planning"
    ],
    "submitter": {
      "@type": "oecd:Submitter",
      "@id": "https://example.org/submitter/submitter",
      "role": "AI Safety Researcher",
      "affiliation": "Tech Policy Center",
      "stakeholderGroup": "I represent a government or regulatory body",
      "relationToIncident": "I am an affected stakeholder"
    },
    "unintendedUse": false,
    "sameAs": "https://incidentdatabase.ai/cite/314"
  },
  {
    "@context": [
      "http://localhost:3000/api/schemas/v1/core/context.jsonld",
      "http://localhost:3001/api/schemas/v1/oecd/context.jsonld"
    ],
    "@type": "oecd:Incident",
    "@id": "https://oecd.ai/incident/OECD-2024-186",
    "incident_id": "OECD-2024-186",
    "title": "AI System Failure Related to Female Celebrities' Faces Shown in Sexually Suggestive Ads for Deepfake App",
    "description": "An AI system failure occurred with similar characteristics to the documented incident involving Facemega. The system exhibited comparable failure modes resulting in harm to affected stakeholders.",
    "date": "2024-01-02",
    "aiSystem": {
      "@type": "oecd:AISystem",
      "name": "Smart System",
      "version": "3.7",
      "relation": [
        "oecd:DirectCause"
      ]
    },
    "developer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/Facemega",
      "name": "Facemega"
    },
    "deployer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/Facemega",
      "name": "Facemega"
    },
    "severity": "oecd:SeriousIncident",
    "harmType": [
      "oecd:OtherHarm"
    ],
    "harmQuantification": {
      "@type": "oecd:HarmQuantification",
      "affected_stakeholders": "3292 individuals",
      "economic_losses": "$1 million"
    },
    "countries": [
      {
        "@type": "core:Country",
        "@id": "https://www.wikidata.org/wiki/United_Kingdom",
        "name": "United Kingdom"
      },
      {
        "@type": "core:Country",
        "@id": "https://www.wikidata.org/wiki/Germany",
        "name": "Germany"
      }
    ],
    "affectedStakeholders": [
      {
        "@type": "core:Person",
        "@id": "https://example.org/entities/person/scarlett-johansson",
        "name": "Scarlett Johansson"
      },
      {
        "@type": "core:Person",
        "@id": "https://example.org/entities/person/female-celebrities",
        "name": "female celebrities"
      },
      {
        "@type": "core:Person",
        "@id": "https://example.org/entities/person/emma-watson",
        "name": "Emma Watson"
      }
    ],
    "businessFunction": [
      "oecd:Procurement",
      "oecd:Production"
    ],
    "submitter": {
      "@type": "oecd:Submitter",
      "@id": "https://example.org/submitter/submitter",
      "role": "Academic Researcher",
      "affiliation": "AI Safety Institute",
      "stakeholderGroup": "I represent a government or regulatory body",
      "relationToIncident": "I am a user of the related AI system"
    },
    "unintendedUse": false,
    "sameAs": "https://incidentdatabase.ai/cite/494"
  },
  {
    "@context": [
      "http://localhost:3000/api/schemas/v1/core/context.jsonld",
      "http://localhost:3001/api/schemas/v1/oecd/context.jsonld"
    ],
    "@type": "oecd:Incident",
    "@id": "https://oecd.ai/incident/OECD-2024-187",
    "incident_id": "OECD-2024-187",
    "title": "Employee Monitoring AI Incorrectly Flags Remote Workers as Unproductive",
    "description": "An AI-powered employee productivity monitoring system incorrectly categorized focused work activities as idle time, leading to unfair performance reviews and terminations. The system failed to understand different working styles and break patterns.",
    "date": "2024-01-17",
    "aiSystem": {
      "@type": "oecd:AISystem",
      "name": "Workplace AI System",
      "version": "5.2.54",
      "relation": [
        "oecd:DirectCause"
      ]
    },
    "developer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/Uber",
      "name": "Uber"
    },
    "deployer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/Uber",
      "name": "Uber"
    },
    "severity": "oecd:SeriousIncident",
    "harmType": [
      "oecd:EconomicHarm",
      "oecd:PsychologicalHarm",
      "oecd:ReputationalHarm"
    ],
    "harmQuantification": {
      "@type": "oecd:HarmQuantification",
      "affected_stakeholders": "2442 workers",
      "economic_losses": "$0.3 million",
      "psychological_impact": "Documented stress and anxiety in affected population"
    },
    "countries": [
      {
        "@type": "core:Country",
        "@id": "https://www.wikidata.org/wiki/Norway",
        "name": "Norway"
      },
      {
        "@type": "core:Country",
        "@id": "https://www.wikidata.org/wiki/Japan",
        "name": "Japan"
      }
    ],
    "affectedStakeholders": [
      {
        "@type": "oecd:StakeholderGroup",
        "@id": "https://example.org/stakeholder-group/workers",
        "name": "Workers"
      },
      {
        "@type": "core:Person",
        "@id": "https://example.org/entities/person/medical-residents",
        "name": "Medical Residents"
      }
    ],
    "businessFunction": [
      "oecd:HRManagement",
      "oecd:QualityControl"
    ],
    "submitter": {
      "@type": "oecd:Submitter",
      "@id": "https://example.org/submitter/reporter",
      "role": "Consumer Advocate",
      "affiliation": "University Ethics Lab",
      "stakeholderGroup": "I represent a government or regulatory body",
      "relationToIncident": "None of the above, but have partial or substantial knowledge of the incident (e.g. first-hand knowledge, research etc.)"
    },
    "unintendedUse": false
  },
  {
    "@context": [
      "http://localhost:3000/api/schemas/v1/core/context.jsonld",
      "http://localhost:3001/api/schemas/v1/oecd/context.jsonld"
    ],
    "@type": "oecd:Incident",
    "@id": "https://oecd.ai/incident/OECD-2024-188",
    "incident_id": "OECD-2024-188",
    "title": "Smart Home AI Creates Dangerous Living Conditions for Elderly",
    "description": "An AI-powered smart home system learned incorrect patterns from an elderly resident with dementia, subsequently creating dangerous conditions by adjusting heating, lighting, and security settings inappropriately.",
    "date": "2024-01-19",
    "aiSystem": {
      "@type": "oecd:AISystem",
      "name": "Consumer AI Engine",
      "version": "6.12.8",
      "relation": [
        "oecd:ContributingFactor"
      ]
    },
    "developer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/Nest_Labs",
      "name": "Nest Labs"
    },
    "deployer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/LinkedIn",
      "name": "LinkedIn"
    },
    "severity": "oecd:SeriousHazard",
    "harmType": [
      "oecd:PhysicalHarm",
      "oecd:PsychologicalHarm"
    ],
    "harmQuantification": {
      "@type": "oecd:HarmQuantification",
      "affected_stakeholders": "92624 customers",
      "economic_losses": "$25.8 million",
      "psychological_impact": "Documented stress and anxiety in affected population"
    },
    "countries": [
      {
        "@type": "core:Country",
        "@id": "https://www.wikidata.org/wiki/Netherlands",
        "name": "Netherlands"
      },
      {
        "@type": "core:Country",
        "@id": "https://www.wikidata.org/wiki/India",
        "name": "India"
      }
    ],
    "affectedStakeholders": [
      {
        "@type": "oecd:StakeholderGroup",
        "@id": "https://example.org/stakeholder-group/children",
        "name": "Children"
      },
      {
        "@type": "oecd:StakeholderGroup",
        "@id": "https://example.org/stakeholder-group/consumers",
        "name": "Consumers"
      }
    ],
    "businessFunction": [
      "oecd:CustomerService",
      "oecd:OtherFunction"
    ],
    "submitter": {
      "@type": "oecd:Submitter",
      "@id": "https://example.org/submitter/reporter",
      "role": "Industry Whistleblower",
      "affiliation": "University Ethics Lab",
      "stakeholderGroup": "None of the above, but have partial or substantial knowledge of the incident",
      "relationToIncident": "None of the above, but have partial or substantial knowledge of the incident (e.g. first-hand knowledge, research etc.)"
    },
    "unintendedUse": false
  },
  {
    "@context": [
      "http://localhost:3000/api/schemas/v1/core/context.jsonld",
      "http://localhost:3001/api/schemas/v1/oecd/context.jsonld"
    ],
    "@type": "oecd:Incident",
    "@id": "https://oecd.ai/incident/OECD-2024-189",
    "incident_id": "OECD-2024-189",
    "title": "AI System Failure Related to Tesla Autopilot Misidentified On-Road Horse-Drawn Carriage",
    "description": "An AI system failure occurred with similar characteristics to the documented incident involving Tesla. The system exhibited comparable failure modes resulting in harm to affected stakeholders.",
    "date": "2024-01-31",
    "aiSystem": {
      "@type": "oecd:AISystem",
      "name": "Intelligent Solution",
      "version": "5.4",
      "relation": [
        "oecd:DirectCause"
      ]
    },
    "developer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/Tesla,_Inc.",
      "name": "Tesla"
    },
    "deployer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/Tesla,_Inc.",
      "name": "Tesla"
    },
    "severity": "oecd:SeriousIncident",
    "harmType": [
      "oecd:OtherHarm"
    ],
    "harmQuantification": {
      "@type": "oecd:HarmQuantification",
      "affected_stakeholders": "45412 individuals",
      "economic_losses": "$10 million"
    },
    "countries": [
      {
        "@type": "core:Country",
        "@id": "https://www.wikidata.org/wiki/Spain",
        "name": "Spain"
      }
    ],
    "affectedStakeholders": [
      {
        "@type": "core:Person",
        "@id": "https://example.org/entities/person/tesla-drivers",
        "name": "Tesla drivers"
      },
      {
        "@type": "core:Person",
        "@id": "https://example.org/entities/person/horse-drawn-carriages",
        "name": "horse-drawn carriages"
      }
    ],
    "businessFunction": [
      "oecd:Sales",
      "oecd:Production"
    ],
    "submitter": {
      "@type": "oecd:Submitter",
      "@id": "https://example.org/submitter/submitter",
      "role": "Academic Researcher",
      "affiliation": "University Research Lab",
      "stakeholderGroup": "I work or am affiliated to a public interest body or NGO",
      "relationToIncident": "None of the above, but have partial or substantial knowledge of the incident (e.g. first-hand knowledge, research etc.)"
    },
    "unintendedUse": false,
    "sameAs": "https://incidentdatabase.ai/cite/398"
  },
  {
    "@context": [
      "http://localhost:3000/api/schemas/v1/core/context.jsonld",
      "http://localhost:3001/api/schemas/v1/oecd/context.jsonld"
    ],
    "@type": "oecd:Incident",
    "@id": "https://oecd.ai/incident/OECD-2024-190",
    "incident_id": "OECD-2024-190",
    "title": "AI System Failure Related to Starship’s Autonomous Food Delivery Robot Allegedly Stranded at Railroad Crossing in Oregon, Run over by Freight Train",
    "description": "An AI system failure occurred with similar characteristics to the documented incident involving Oregon State University. The system exhibited comparable failure modes resulting in harm to affected stakeholders.",
    "date": "2024-01-31",
    "aiSystem": {
      "@type": "oecd:AISystem",
      "name": "Intelligent Platform",
      "version": "5.2",
      "relation": [
        "oecd:DirectCause"
      ]
    },
    "developer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/Oregon_State_University",
      "name": "Oregon State University"
    },
    "deployer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/Oregon_State_University",
      "name": "Oregon State University"
    },
    "severity": "oecd:SeriousIncident",
    "harmType": [
      "oecd:OtherHarm"
    ],
    "harmQuantification": {
      "@type": "oecd:HarmQuantification",
      "affected_stakeholders": "31361 individuals"
    },
    "countries": [
      {
        "@type": "core:Country",
        "@id": "https://www.wikidata.org/wiki/Netherlands",
        "name": "Netherlands"
      }
    ],
    "affectedStakeholders": [
      {
        "@type": "core:Person",
        "@id": "https://example.org/entities/person/oregon-state-university",
        "name": "Oregon State University"
      },
      {
        "@type": "core:Person",
        "@id": "https://example.org/entities/person/freight-train-crew",
        "name": "freight train crew"
      }
    ],
    "businessFunction": [
      "oecd:Accounting"
    ],
    "submitter": {
      "@type": "oecd:Submitter",
      "@id": "https://example.org/submitter/submitter",
      "role": "AI Safety Researcher",
      "affiliation": "University Research Lab",
      "stakeholderGroup": "None of the above, but have partial or substantial knowledge of the incident",
      "relationToIncident": "I am an affected stakeholder"
    },
    "unintendedUse": false,
    "sameAs": "https://incidentdatabase.ai/cite/176"
  },
  {
    "@context": [
      "http://localhost:3000/api/schemas/v1/core/context.jsonld",
      "http://localhost:3001/api/schemas/v1/oecd/context.jsonld"
    ],
    "@type": "oecd:Incident",
    "@id": "https://oecd.ai/incident/OECD-2024-191",
    "incident_id": "OECD-2024-191",
    "title": "AI System Failure Related to Class Action Lawsuit Over Alleged Defects in Volkswagen's AI-Driven AEB Systems",
    "description": "An AI system failure occurred with similar characteristics to the documented incident involving Volkswagen Group of America. The system exhibited comparable failure modes resulting in harm to affected stakeholders.",
    "date": "2024-02-02",
    "aiSystem": {
      "@type": "oecd:AISystem",
      "name": "Intelligent Solution",
      "version": "3.2",
      "relation": [
        "oecd:DirectCause"
      ]
    },
    "developer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/Volkswagen_Group_of_America",
      "name": "Volkswagen Group of America"
    },
    "deployer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/Volkswagen_Group_of_America",
      "name": "Volkswagen Group of America"
    },
    "severity": "oecd:SeriousIncident",
    "harmType": [
      "oecd:OtherHarm"
    ],
    "harmQuantification": {
      "@type": "oecd:HarmQuantification",
      "affected_stakeholders": "34896 individuals",
      "economic_losses": "$1 million"
    },
    "countries": [
      {
        "@type": "core:Country",
        "@id": "https://www.wikidata.org/wiki/Spain",
        "name": "Spain"
      },
      {
        "@type": "core:Country",
        "@id": "https://www.wikidata.org/wiki/United_States",
        "name": "United States"
      }
    ],
    "affectedStakeholders": [
      {
        "@type": "core:Person",
        "@id": "https://example.org/entities/person/volkswagen-drivers",
        "name": "Volkswagen drivers"
      },
      {
        "@type": "oecd:StakeholderGroup",
        "@id": "https://example.org/stakeholder-group/potential-passengers-and-road-users-at-risk-due-to-malfunctioning-aeb-systems",
        "name": "Potential passengers and road users at risk due to malfunctioning AEB systems"
      }
    ],
    "businessFunction": [
      "oecd:Sales",
      "oecd:Planning"
    ],
    "submitter": {
      "@type": "oecd:Submitter",
      "@id": "https://example.org/submitter/submitter",
      "role": "Industry Analyst",
      "affiliation": "University Research Lab",
      "stakeholderGroup": "I represent a government or regulatory body",
      "relationToIncident": "I am a user of the related AI system"
    },
    "unintendedUse": false,
    "sameAs": "https://incidentdatabase.ai/cite/746"
  },
  {
    "@context": [
      "http://localhost:3000/api/schemas/v1/core/context.jsonld",
      "http://localhost:3001/api/schemas/v1/oecd/context.jsonld"
    ],
    "@type": "oecd:Incident",
    "@id": "https://oecd.ai/incident/OECD-2024-192",
    "incident_id": "OECD-2024-192",
    "title": "AI System Failure Related to Fake LinkedIn Profiles Created Using GAN Photos",
    "description": "An AI system failure occurred with similar characteristics to the documented incident involving unknown. The system exhibited comparable failure modes resulting in harm to affected stakeholders.",
    "date": "2024-02-07",
    "aiSystem": {
      "@type": "oecd:AISystem",
      "name": "Smart Solution",
      "version": "2.2",
      "relation": [
        "oecd:DirectCause"
      ]
    },
    "developer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/unknown",
      "name": "unknown"
    },
    "deployer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/unknown",
      "name": "unknown"
    },
    "severity": "oecd:SeriousIncident",
    "harmType": [
      "oecd:OtherHarm"
    ],
    "harmQuantification": {
      "@type": "oecd:HarmQuantification",
      "affected_stakeholders": "24793 individuals",
      "economic_losses": "$4 million"
    },
    "countries": [
      {
        "@type": "core:Country",
        "@id": "https://www.wikidata.org/wiki/United_States",
        "name": "United States"
      },
      {
        "@type": "core:Country",
        "@id": "https://www.wikidata.org/wiki/United_Kingdom",
        "name": "United Kingdom"
      }
    ],
    "affectedStakeholders": [
      {
        "@type": "oecd:StakeholderGroup",
        "@id": "https://example.org/stakeholder-group/linkedin-users",
        "name": "LinkedIn users"
      }
    ],
    "businessFunction": [
      "oecd:ICTManagement",
      "oecd:Compliance"
    ],
    "submitter": {
      "@type": "oecd:Submitter",
      "@id": "https://example.org/submitter/submitter",
      "role": "Ethics Officer",
      "affiliation": "Digital Rights Foundation",
      "stakeholderGroup": "I represent a government or regulatory body",
      "relationToIncident": "None of the above, but have partial or substantial knowledge of the incident (e.g. first-hand knowledge, research etc.)"
    },
    "unintendedUse": false,
    "sameAs": "https://incidentdatabase.ai/cite/174"
  },
  {
    "@context": [
      "http://localhost:3000/api/schemas/v1/core/context.jsonld",
      "http://localhost:3001/api/schemas/v1/oecd/context.jsonld"
    ],
    "@type": "oecd:Incident",
    "@id": "https://oecd.ai/incident/OECD-2024-193",
    "incident_id": "OECD-2024-193",
    "title": "AI System Failure Related to Glovo Driver in Italy Fired via Automated Email after Being Killed in Accident",
    "description": "An AI system failure occurred with similar characteristics to the documented incident involving Glovo. The system exhibited comparable failure modes resulting in harm to affected stakeholders.",
    "date": "2024-02-10",
    "aiSystem": {
      "@type": "oecd:AISystem",
      "name": "Intelligent System",
      "version": "3.0",
      "relation": [
        "oecd:DirectCause"
      ]
    },
    "developer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/Glovo",
      "name": "Glovo"
    },
    "deployer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/Glovo",
      "name": "Glovo"
    },
    "severity": "oecd:SeriousIncident",
    "harmType": [
      "oecd:OtherHarm"
    ],
    "harmQuantification": {
      "@type": "oecd:HarmQuantification",
      "affected_stakeholders": "29488 individuals",
      "economic_losses": "$2 million"
    },
    "countries": [
      {
        "@type": "core:Country",
        "@id": "https://www.wikidata.org/wiki/France",
        "name": "France"
      },
      {
        "@type": "core:Country",
        "@id": "https://www.wikidata.org/wiki/Australia",
        "name": "Australia"
      },
      {
        "@type": "core:Country",
        "@id": "https://www.wikidata.org/wiki/Japan",
        "name": "Japan"
      }
    ],
    "affectedStakeholders": [
      {
        "@type": "core:Person",
        "@id": "https://example.org/entities/person/sebastian-galassi-s-family",
        "name": "Sebastian Galassi's family"
      },
      {
        "@type": "core:Person",
        "@id": "https://example.org/entities/person/sebastian-galassi",
        "name": "Sebastian Galassi"
      }
    ],
    "businessFunction": [
      "oecd:Production",
      "oecd:Sales"
    ],
    "submitter": {
      "@type": "oecd:Submitter",
      "@id": "https://example.org/submitter/submitter",
      "role": "Ethics Officer",
      "affiliation": "Digital Rights Foundation",
      "stakeholderGroup": "I represent a government or regulatory body",
      "relationToIncident": "I am a user of the related AI system"
    },
    "unintendedUse": false,
    "sameAs": "https://incidentdatabase.ai/cite/384"
  },
  {
    "@context": [
      "http://localhost:3000/api/schemas/v1/core/context.jsonld",
      "http://localhost:3001/api/schemas/v1/oecd/context.jsonld"
    ],
    "@type": "oecd:Incident",
    "@id": "https://oecd.ai/incident/OECD-2024-194",
    "incident_id": "OECD-2024-194",
    "title": "AI System Failure Related to British Female Politicians Victimized by Deepfake Pornography",
    "description": "An AI system failure occurred with similar characteristics to the documented incident involving Unknown deepfake creators. The system exhibited comparable failure modes resulting in harm to affected stakeholders.",
    "date": "2024-02-20",
    "aiSystem": {
      "@type": "oecd:AISystem",
      "name": "Intelligent Engine",
      "version": "1.9",
      "relation": [
        "oecd:DirectCause"
      ]
    },
    "developer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/Unknown_deepfake_creators",
      "name": "Unknown deepfake creators"
    },
    "deployer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/Unknown_deepfake_creators",
      "name": "Unknown deepfake creators"
    },
    "severity": "oecd:SeriousIncident",
    "harmType": [
      "oecd:OtherHarm"
    ],
    "harmQuantification": {
      "@type": "oecd:HarmQuantification",
      "affected_stakeholders": "42160 individuals",
      "economic_losses": "$2 million"
    },
    "countries": [
      {
        "@type": "core:Country",
        "@id": "https://www.wikidata.org/wiki/United_Kingdom",
        "name": "United Kingdom"
      },
      {
        "@type": "core:Country",
        "@id": "https://www.wikidata.org/wiki/France",
        "name": "France"
      },
      {
        "@type": "core:Country",
        "@id": "https://www.wikidata.org/wiki/Netherlands",
        "name": "Netherlands"
      }
    ],
    "affectedStakeholders": [
      {
        "@type": "core:Person",
        "@id": "https://example.org/entities/person/stella-creasy",
        "name": "Stella Creasy"
      },
      {
        "@type": "core:Person",
        "@id": "https://example.org/entities/person/priti-patel",
        "name": "Priti Patel"
      },
      {
        "@type": "core:Person",
        "@id": "https://example.org/entities/person/penny-mordaunt",
        "name": "Penny Mordaunt"
      },
      {
        "@type": "core:Person",
        "@id": "https://example.org/entities/person/gillian-keegan",
        "name": "Gillian Keegan"
      },
      {
        "@type": "core:Person",
        "@id": "https://example.org/entities/person/dehenna-davison",
        "name": "Dehenna Davison"
      },
      {
        "@type": "core:Person",
        "@id": "https://example.org/entities/person/angela-rayner",
        "name": "Angela Rayner"
      }
    ],
    "businessFunction": [
      "oecd:QualityControl"
    ],
    "submitter": {
      "@type": "oecd:Submitter",
      "@id": "https://example.org/submitter/submitter",
      "role": "AI Safety Researcher",
      "affiliation": "AI Safety Institute",
      "stakeholderGroup": "I represent a government or regulatory body",
      "relationToIncident": "I am an affected stakeholder"
    },
    "unintendedUse": true,
    "sameAs": "https://incidentdatabase.ai/cite/754"
  },
  {
    "@context": [
      "http://localhost:3000/api/schemas/v1/core/context.jsonld",
      "http://localhost:3001/api/schemas/v1/oecd/context.jsonld"
    ],
    "@type": "oecd:Incident",
    "@id": "https://oecd.ai/incident/OECD-2024-195",
    "incident_id": "OECD-2024-195",
    "title": "AI System Failure Related to British Female Politicians Victimized by Deepfake Pornography",
    "description": "An AI system failure occurred with similar characteristics to the documented incident involving Unknown deepfake creators. The system exhibited comparable failure modes resulting in harm to affected stakeholders.",
    "date": "2024-02-21",
    "aiSystem": {
      "@type": "oecd:AISystem",
      "name": "Smart System",
      "version": "2.7",
      "relation": [
        "oecd:DirectCause"
      ]
    },
    "developer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/Unknown_deepfake_creators",
      "name": "Unknown deepfake creators"
    },
    "deployer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/Unknown_deepfake_creators",
      "name": "Unknown deepfake creators"
    },
    "severity": "oecd:SeriousIncident",
    "harmType": [
      "oecd:OtherHarm"
    ],
    "harmQuantification": {
      "@type": "oecd:HarmQuantification",
      "affected_stakeholders": "6480 individuals",
      "economic_losses": "$3 million"
    },
    "countries": [
      {
        "@type": "core:Country",
        "@id": "https://www.wikidata.org/wiki/United_States",
        "name": "United States"
      },
      {
        "@type": "core:Country",
        "@id": "https://www.wikidata.org/wiki/Canada",
        "name": "Canada"
      },
      {
        "@type": "core:Country",
        "@id": "https://www.wikidata.org/wiki/South_Korea",
        "name": "South Korea"
      }
    ],
    "affectedStakeholders": [
      {
        "@type": "core:Person",
        "@id": "https://example.org/entities/person/stella-creasy",
        "name": "Stella Creasy"
      },
      {
        "@type": "core:Person",
        "@id": "https://example.org/entities/person/priti-patel",
        "name": "Priti Patel"
      },
      {
        "@type": "core:Person",
        "@id": "https://example.org/entities/person/penny-mordaunt",
        "name": "Penny Mordaunt"
      },
      {
        "@type": "core:Person",
        "@id": "https://example.org/entities/person/gillian-keegan",
        "name": "Gillian Keegan"
      },
      {
        "@type": "core:Person",
        "@id": "https://example.org/entities/person/dehenna-davison",
        "name": "Dehenna Davison"
      },
      {
        "@type": "core:Person",
        "@id": "https://example.org/entities/person/angela-rayner",
        "name": "Angela Rayner"
      }
    ],
    "businessFunction": [
      "oecd:Procurement",
      "oecd:Production"
    ],
    "submitter": {
      "@type": "oecd:Submitter",
      "@id": "https://example.org/submitter/submitter",
      "role": "AI Safety Researcher",
      "affiliation": "Tech Policy Center",
      "stakeholderGroup": "I represent a government or regulatory body",
      "relationToIncident": "None of the above, but have partial or substantial knowledge of the incident (e.g. first-hand knowledge, research etc.)"
    },
    "unintendedUse": false,
    "sameAs": "https://incidentdatabase.ai/cite/754"
  },
  {
    "@context": [
      "http://localhost:3000/api/schemas/v1/core/context.jsonld",
      "http://localhost:3001/api/schemas/v1/oecd/context.jsonld"
    ],
    "@type": "oecd:Incident",
    "@id": "https://oecd.ai/incident/OECD-2024-196",
    "incident_id": "OECD-2024-196",
    "title": "Predictive Policing Algorithm Creates Feedback Loops in Minority Neighborhoods",
    "description": "An AI system for predicting crime hotspots consistently directed more police presence to minority neighborhoods, creating a self-reinforcing cycle where increased police presence led to more reported incidents, further biasing the algorithm.",
    "date": "2024-05-25",
    "aiSystem": {
      "@type": "oecd:AISystem",
      "name": "Security/Surveillance Engine Pro",
      "version": "1.5.24",
      "relation": [
        "oecd:DirectCause"
      ]
    },
    "developer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/Doctors",
      "name": "Doctors"
    },
    "deployer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/United_States_Government",
      "name": "United States Government"
    },
    "severity": "oecd:SeriousHazard",
    "harmType": [
      "oecd:HumanRightsHarm",
      "oecd:PsychologicalHarm"
    ],
    "harmQuantification": {
      "@type": "oecd:HarmQuantification",
      "affected_stakeholders": "73973 individuals",
      "economic_losses": "$6.3 million",
      "psychological_impact": "Documented stress and anxiety in affected population"
    },
    "countries": [
      {
        "@type": "core:Country",
        "@id": "https://www.wikidata.org/wiki/Sweden",
        "name": "Sweden"
      },
      {
        "@type": "core:Country",
        "@id": "https://www.wikidata.org/wiki/Germany",
        "name": "Germany"
      }
    ],
    "affectedStakeholders": [
      {
        "@type": "core:Person",
        "@id": "https://example.org/entities/person/pedestrians",
        "name": "Pedestrians"
      },
      {
        "@type": "oecd:StakeholderGroup",
        "@id": "https://example.org/stakeholder-group/patients",
        "name": "Patients"
      },
      {
        "@type": "core:Person",
        "@id": "https://example.org/entities/person/motorists",
        "name": "Motorists"
      }
    ],
    "businessFunction": [
      "oecd:Compliance",
      "oecd:Planning"
    ],
    "submitter": {
      "@type": "oecd:Submitter",
      "@id": "https://example.org/submitter/reporter",
      "role": "Consumer Advocate",
      "affiliation": "University Ethics Lab",
      "stakeholderGroup": "I work or am affiliated to a public interest body or NGO",
      "relationToIncident": "None of the above, but have partial or substantial knowledge of the incident (e.g. first-hand knowledge, research etc.)"
    },
    "unintendedUse": false
  },
  {
    "@context": [
      "http://localhost:3000/api/schemas/v1/core/context.jsonld",
      "http://localhost:3001/api/schemas/v1/oecd/context.jsonld"
    ],
    "@type": "oecd:Incident",
    "@id": "https://oecd.ai/incident/OECD-2024-197",
    "incident_id": "OECD-2024-197",
    "title": "AI Credit Scoring System Discriminates Against Recent Immigrants",
    "description": "An automated credit scoring system systematically assigned lower credit scores to recent immigrants despite strong financial indicators. The AI model heavily weighted credit history length, creating unfair barriers to financial services.",
    "date": "2024-05-31",
    "aiSystem": {
      "@type": "oecd:AISystem",
      "name": "Financial AI Engine",
      "version": "4.4.4",
      "relation": [
        "oecd:ContributingFactor"
      ]
    },
    "developer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/LinkedIn",
      "name": "LinkedIn"
    },
    "deployer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/Amazon_(company)",
      "name": "Amazon"
    },
    "severity": "oecd:SeriousIncident",
    "harmType": [
      "oecd:EconomicHarm",
      "oecd:HumanRightsHarm"
    ],
    "harmQuantification": {
      "@type": "oecd:HarmQuantification",
      "affected_stakeholders": "614 customers"
    },
    "countries": [
      {
        "@type": "core:Country",
        "@id": "https://www.wikidata.org/wiki/Singapore",
        "name": "Singapore"
      }
    ],
    "affectedStakeholders": [
      {
        "@type": "core:Person",
        "@id": "https://example.org/entities/person/motorists",
        "name": "Motorists"
      }
    ],
    "businessFunction": [
      "oecd:OtherFunction"
    ],
    "submitter": {
      "@type": "oecd:Submitter",
      "@id": "https://example.org/submitter/reporter",
      "role": "Industry Whistleblower",
      "affiliation": "Digital Rights Organization",
      "stakeholderGroup": "I work or am affiliated to a public interest body or NGO",
      "relationToIncident": "None of the above, but have partial or substantial knowledge of the incident (e.g. first-hand knowledge, research etc.)"
    },
    "unintendedUse": false
  },
  {
    "@context": [
      "http://localhost:3000/api/schemas/v1/core/context.jsonld",
      "http://localhost:3001/api/schemas/v1/oecd/context.jsonld"
    ],
    "@type": "oecd:Incident",
    "@id": "https://oecd.ai/incident/OECD-2024-198",
    "incident_id": "OECD-2024-198",
    "title": "AI Interview System Shows Bias Against Non-Native Speakers",
    "description": "An automated video interview analysis system consistently gave lower scores to qualified candidates with accents or non-native speech patterns. The AI's speech recognition and sentiment analysis components showed significant bias.",
    "date": "2024-06-17",
    "aiSystem": {
      "@type": "oecd:AISystem",
      "name": "Workplace AI System",
      "version": "4.16.87",
      "relation": [
        "oecd:ContributingFactor"
      ]
    },
    "developer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/Uber",
      "name": "Uber"
    },
    "deployer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/New_York_city_Dept._of_Education",
      "name": "New York city Dept. of Education"
    },
    "severity": "oecd:SeriousIncident",
    "harmType": [
      "oecd:EconomicHarm",
      "oecd:HumanRightsHarm"
    ],
    "harmQuantification": {
      "@type": "oecd:HarmQuantification",
      "affected_stakeholders": "39301 workers",
      "economic_losses": "$5.5 million"
    },
    "countries": [
      {
        "@type": "core:Country",
        "@id": "https://www.wikidata.org/wiki/Canada",
        "name": "Canada"
      },
      {
        "@type": "core:Country",
        "@id": "https://www.wikidata.org/wiki/France",
        "name": "France"
      }
    ],
    "affectedStakeholders": [
      {
        "@type": "core:Person",
        "@id": "https://example.org/entities/person/job-applicants",
        "name": "Job applicants"
      }
    ],
    "businessFunction": [
      "oecd:HRManagement"
    ],
    "submitter": {
      "@type": "oecd:Submitter",
      "@id": "https://example.org/submitter/reporter",
      "role": "Industry Whistleblower",
      "affiliation": "University Ethics Lab",
      "stakeholderGroup": "None of the above, but have partial or substantial knowledge of the incident",
      "relationToIncident": "None of the above, but have partial or substantial knowledge of the incident (e.g. first-hand knowledge, research etc.)"
    },
    "unintendedUse": true
  },
  {
    "@context": [
      "http://localhost:3000/api/schemas/v1/core/context.jsonld",
      "http://localhost:3001/api/schemas/v1/oecd/context.jsonld"
    ],
    "@type": "oecd:Incident",
    "@id": "https://oecd.ai/incident/OECD-2024-199",
    "incident_id": "OECD-2024-199",
    "title": "Facial Recognition System Falsely Identifies Protesters as Criminals",
    "description": "A law enforcement facial recognition system incorrectly matched peaceful protesters with criminal database entries, leading to wrongful detentions. The AI system showed higher error rates for certain ethnic groups and in crowded scenarios.",
    "date": "2024-06-26",
    "aiSystem": {
      "@type": "oecd:AISystem",
      "name": "Security/Surveillance System",
      "version": "4.6.36",
      "relation": [
        "oecd:DirectCause"
      ]
    },
    "developer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/YouTube",
      "name": "YouTube"
    },
    "deployer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/Google",
      "name": "Google"
    },
    "severity": "oecd:SeriousIncident",
    "harmType": [
      "oecd:PhysicalHarm",
      "oecd:HumanRightsHarm",
      "oecd:ReputationalHarm"
    ],
    "harmQuantification": {
      "@type": "oecd:HarmQuantification",
      "affected_stakeholders": "79021 individuals",
      "economic_losses": "$11.0 million"
    },
    "countries": [
      {
        "@type": "core:Country",
        "@id": "https://www.wikidata.org/wiki/France",
        "name": "France"
      },
      {
        "@type": "core:Country",
        "@id": "https://www.wikidata.org/wiki/Brazil",
        "name": "Brazil"
      }
    ],
    "affectedStakeholders": [
      {
        "@type": "oecd:StakeholderGroup",
        "@id": "https://example.org/stakeholder-group/patients",
        "name": "Patients"
      }
    ],
    "businessFunction": [
      "oecd:Compliance"
    ],
    "submitter": {
      "@type": "oecd:Submitter",
      "@id": "https://example.org/submitter/reporter",
      "role": "Safety Engineer",
      "affiliation": "Consumer Protection Agency",
      "stakeholderGroup": "I am an affected stakeholder",
      "relationToIncident": "None of the above, but have partial or substantial knowledge of the incident (e.g. first-hand knowledge, research etc.)"
    },
    "unintendedUse": false
  },
  {
    "@context": [
      "http://localhost:3000/api/schemas/v1/core/context.jsonld",
      "http://localhost:3001/api/schemas/v1/oecd/context.jsonld"
    ],
    "@type": "oecd:Incident",
    "@id": "https://oecd.ai/incident/OECD-2024-200",
    "incident_id": "OECD-2024-200",
    "title": "AI Diagnostic System Misses Critical Symptoms in Emergency Department",
    "description": "An AI triage system in emergency departments failed to identify critical symptoms in patients presenting with atypical manifestations of serious conditions. The system's training data lacked diversity in symptom presentations across different demographics.",
    "date": "2024-06-26",
    "aiSystem": {
      "@type": "oecd:AISystem",
      "name": "Medical AI System",
      "version": "6.14.51",
      "relation": [
        "oecd:DirectCause"
      ]
    },
    "developer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/Frontier_Development",
      "name": "Frontier Development"
    },
    "deployer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/Google",
      "name": "Google"
    },
    "severity": "oecd:SeriousHazard",
    "harmType": [
      "oecd:PhysicalHarm",
      "oecd:HumanRightsHarm"
    ],
    "harmQuantification": {
      "@type": "oecd:HarmQuantification",
      "affected_stakeholders": "64254 customers"
    },
    "countries": [
      {
        "@type": "core:Country",
        "@id": "https://www.wikidata.org/wiki/Norway",
        "name": "Norway"
      },
      {
        "@type": "core:Country",
        "@id": "https://www.wikidata.org/wiki/United_States",
        "name": "United States"
      }
    ],
    "affectedStakeholders": [
      {
        "@type": "oecd:StakeholderGroup",
        "@id": "https://example.org/stakeholder-group/minority-groups",
        "name": "Minority Groups"
      },
      {
        "@type": "core:Person",
        "@id": "https://example.org/entities/person/black-people",
        "name": "Black people"
      }
    ],
    "businessFunction": [
      "oecd:OtherFunction"
    ],
    "submitter": {
      "@type": "oecd:Submitter",
      "@id": "https://example.org/submitter/reporter",
      "role": "Safety Engineer",
      "affiliation": "Consumer Protection Agency",
      "stakeholderGroup": "None of the above, but have partial or substantial knowledge of the incident",
      "relationToIncident": "None of the above, but have partial or substantial knowledge of the incident (e.g. first-hand knowledge, research etc.)"
    },
    "unintendedUse": false
  },
  {
    "@context": [
      "http://localhost:3000/api/schemas/v1/core/context.jsonld",
      "http://localhost:3001/api/schemas/v1/oecd/context.jsonld"
    ],
    "@type": "oecd:Incident",
    "@id": "https://oecd.ai/incident/OECD-2024-201",
    "incident_id": "OECD-2024-201",
    "title": "AI Diagnostic System Misses Critical Symptoms in Emergency Department",
    "description": "An AI triage system in emergency departments failed to identify critical symptoms in patients presenting with atypical manifestations of serious conditions. The system's training data lacked diversity in symptom presentations across different demographics.",
    "date": "2024-06-27",
    "aiSystem": {
      "@type": "oecd:AISystem",
      "name": "Medical AI System",
      "version": "2.1.77",
      "relation": [
        "oecd:DirectCause",
        "oecd:ContributingFactor"
      ]
    },
    "developer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/LinkedIn",
      "name": "LinkedIn"
    },
    "deployer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/Hospitals",
      "name": "Hospitals"
    },
    "severity": "oecd:SeriousHazard",
    "harmType": [
      "oecd:PhysicalHarm",
      "oecd:HumanRightsHarm"
    ],
    "harmQuantification": {
      "@type": "oecd:HarmQuantification",
      "affected_stakeholders": "63580 individuals"
    },
    "countries": [
      {
        "@type": "core:Country",
        "@id": "https://www.wikidata.org/wiki/Italy",
        "name": "Italy"
      },
      {
        "@type": "core:Country",
        "@id": "https://www.wikidata.org/wiki/United_States",
        "name": "United States"
      }
    ],
    "affectedStakeholders": [
      {
        "@type": "oecd:StakeholderGroup",
        "@id": "https://example.org/stakeholder-group/students",
        "name": "Students"
      }
    ],
    "businessFunction": [
      "oecd:OtherFunction"
    ],
    "submitter": {
      "@type": "oecd:Submitter",
      "@id": "https://example.org/submitter/reporter",
      "role": "Data Scientist",
      "affiliation": "University Ethics Lab",
      "stakeholderGroup": "None of the above, but have partial or substantial knowledge of the incident",
      "relationToIncident": "None of the above, but have partial or substantial knowledge of the incident (e.g. first-hand knowledge, research etc.)"
    },
    "unintendedUse": false
  },
  {
    "@context": [
      "http://localhost:3000/api/schemas/v1/core/context.jsonld",
      "http://localhost:3001/api/schemas/v1/oecd/context.jsonld"
    ],
    "@type": "oecd:Incident",
    "@id": "https://oecd.ai/incident/OECD-2024-202",
    "incident_id": "OECD-2024-202",
    "title": "Delivery Robot Swarm Blocks Emergency Vehicle Access",
    "description": "A fleet of autonomous delivery robots failed to coordinate their movements during an emergency, blocking paramedic access to a medical emergency. The swarm intelligence system lacked proper emergency vehicle detection and response protocols.",
    "date": "2024-07-05",
    "aiSystem": {
      "@type": "oecd:AISystem",
      "name": "Autonomous Systems System",
      "version": "9.18.1",
      "relation": [
        "oecd:DirectCause"
      ]
    },
    "developer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/LinkedIn",
      "name": "LinkedIn"
    },
    "deployer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/Tesla,_Inc.",
      "name": "Tesla"
    },
    "severity": "oecd:SeriousHazard",
    "harmType": [
      "oecd:PhysicalHarm",
      "oecd:PublicInterestHarm"
    ],
    "harmQuantification": {
      "@type": "oecd:HarmQuantification",
      "affected_stakeholders": "50380 users",
      "economic_losses": "$33.7 million"
    },
    "countries": [
      {
        "@type": "core:Country",
        "@id": "https://www.wikidata.org/wiki/Italy",
        "name": "Italy"
      },
      {
        "@type": "core:Country",
        "@id": "https://www.wikidata.org/wiki/United_States",
        "name": "United States"
      }
    ],
    "affectedStakeholders": [
      {
        "@type": "oecd:StakeholderGroup",
        "@id": "https://example.org/stakeholder-group/children",
        "name": "Children"
      }
    ],
    "businessFunction": [
      "oecd:Logistics",
      "oecd:OtherFunction"
    ],
    "submitter": {
      "@type": "oecd:Submitter",
      "@id": "https://example.org/submitter/reporter",
      "role": "Government Auditor",
      "affiliation": "Tech Accountability Project",
      "stakeholderGroup": "I work or am affiliated to a public interest body or NGO",
      "relationToIncident": "None of the above, but have partial or substantial knowledge of the incident (e.g. first-hand knowledge, research etc.)"
    },
    "unintendedUse": true
  },
  {
    "@context": [
      "http://localhost:3000/api/schemas/v1/core/context.jsonld",
      "http://localhost:3001/api/schemas/v1/oecd/context.jsonld"
    ],
    "@type": "oecd:Incident",
    "@id": "https://oecd.ai/incident/OECD-2024-203",
    "incident_id": "OECD-2024-203",
    "title": "AI System Failure Related to AI Chatbots Reportedly Inaccurately Conveyed Real-Time Political News",
    "description": "An AI system failure occurred with similar characteristics to the documented incident involving Perplexity. The system exhibited comparable failure modes resulting in harm to affected stakeholders.",
    "date": "2024-07-31",
    "aiSystem": {
      "@type": "oecd:AISystem",
      "name": "Smart System",
      "version": "2.5",
      "relation": [
        "oecd:DirectCause"
      ]
    },
    "developer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/Perplexity",
      "name": "Perplexity"
    },
    "deployer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/Perplexity",
      "name": "Perplexity"
    },
    "severity": "oecd:SeriousIncident",
    "harmType": [
      "oecd:OtherHarm"
    ],
    "harmQuantification": {
      "@type": "oecd:HarmQuantification",
      "affected_stakeholders": "18033 individuals"
    },
    "countries": [
      {
        "@type": "core:Country",
        "@id": "https://www.wikidata.org/wiki/Spain",
        "name": "Spain"
      },
      {
        "@type": "core:Country",
        "@id": "https://www.wikidata.org/wiki/Australia",
        "name": "Australia"
      }
    ],
    "affectedStakeholders": [
      {
        "@type": "core:Person",
        "@id": "https://example.org/entities/person/journalism",
        "name": "Journalism"
      },
      {
        "@type": "oecd:StakeholderGroup",
        "@id": "https://example.org/stakeholder-group/general-public",
        "name": "General public"
      },
      {
        "@type": "oecd:StakeholderGroup",
        "@id": "https://example.org/stakeholder-group/chatbot-users",
        "name": "Chatbot users"
      }
    ],
    "businessFunction": [
      "oecd:Production",
      "oecd:Maintenance"
    ],
    "submitter": {
      "@type": "oecd:Submitter",
      "@id": "https://example.org/submitter/submitter",
      "role": "AI Safety Researcher",
      "affiliation": "Digital Rights Foundation",
      "stakeholderGroup": "I represent a government or regulatory body",
      "relationToIncident": "None of the above, but have partial or substantial knowledge of the incident (e.g. first-hand knowledge, research etc.)"
    },
    "unintendedUse": false,
    "sameAs": "https://incidentdatabase.ai/cite/750"
  },
  {
    "@context": [
      "http://localhost:3000/api/schemas/v1/core/context.jsonld",
      "http://localhost:3001/api/schemas/v1/oecd/context.jsonld"
    ],
    "@type": "oecd:Incident",
    "@id": "https://oecd.ai/incident/OECD-2024-204",
    "incident_id": "OECD-2024-204",
    "title": "AI Personal Assistant Shares Private Information in Group Settings",
    "description": "A voice-activated AI assistant failed to recognize multi-user environments and shared personal calendar entries, medical reminders, and financial information when responding to queries in group settings.",
    "date": "2024-08-01",
    "aiSystem": {
      "@type": "oecd:AISystem",
      "name": "Consumer AI Platform Pro",
      "version": "6.17.31",
      "relation": [
        "oecd:DirectCause"
      ]
    },
    "developer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/Volkswagen",
      "name": "Volkswagen"
    },
    "deployer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/The_DAO",
      "name": "The DAO"
    },
    "severity": "oecd:SeriousIncident",
    "harmType": [
      "oecd:ReputationalHarm",
      "oecd:HumanRightsHarm"
    ],
    "harmQuantification": {
      "@type": "oecd:HarmQuantification",
      "affected_stakeholders": "41589 individuals",
      "economic_losses": "$11.3 million"
    },
    "countries": [
      {
        "@type": "core:Country",
        "@id": "https://www.wikidata.org/wiki/Spain",
        "name": "Spain"
      }
    ],
    "affectedStakeholders": [
      {
        "@type": "oecd:StakeholderGroup",
        "@id": "https://example.org/stakeholder-group/students",
        "name": "Students"
      },
      {
        "@type": "core:Person",
        "@id": "https://example.org/entities/person/pedestrians",
        "name": "Pedestrians"
      },
      {
        "@type": "oecd:StakeholderGroup",
        "@id": "https://example.org/stakeholder-group/workers",
        "name": "Workers"
      }
    ],
    "businessFunction": [
      "oecd:CustomerService",
      "oecd:ICTManagement"
    ],
    "submitter": {
      "@type": "oecd:Submitter",
      "@id": "https://example.org/submitter/reporter",
      "role": "Data Scientist",
      "affiliation": "Consumer Protection Agency",
      "stakeholderGroup": "None of the above, but have partial or substantial knowledge of the incident",
      "relationToIncident": "None of the above, but have partial or substantial knowledge of the incident (e.g. first-hand knowledge, research etc.)"
    },
    "unintendedUse": false
  },
  {
    "@context": [
      "http://localhost:3000/api/schemas/v1/core/context.jsonld",
      "http://localhost:3001/api/schemas/v1/oecd/context.jsonld"
    ],
    "@type": "oecd:Incident",
    "@id": "https://oecd.ai/incident/OECD-2024-205",
    "incident_id": "OECD-2024-205",
    "title": "Smart Home AI Creates Dangerous Living Conditions for Elderly",
    "description": "An AI-powered smart home system learned incorrect patterns from an elderly resident with dementia, subsequently creating dangerous conditions by adjusting heating, lighting, and security settings inappropriately.",
    "date": "2024-08-10",
    "aiSystem": {
      "@type": "oecd:AISystem",
      "name": "Consumer AI Engine",
      "version": "6.0.62",
      "relation": [
        "oecd:DirectCause",
        "oecd:ContributingFactor"
      ]
    },
    "developer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/YouTube",
      "name": "YouTube"
    },
    "deployer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/The_DAO",
      "name": "The DAO"
    },
    "severity": "oecd:SeriousHazard",
    "harmType": [
      "oecd:PhysicalHarm",
      "oecd:PsychologicalHarm"
    ],
    "harmQuantification": {
      "@type": "oecd:HarmQuantification",
      "affected_stakeholders": "94152 workers",
      "economic_losses": "$25.2 million",
      "psychological_impact": "Documented stress and anxiety in affected population"
    },
    "countries": [
      {
        "@type": "core:Country",
        "@id": "https://www.wikidata.org/wiki/United_Kingdom",
        "name": "United Kingdom"
      }
    ],
    "affectedStakeholders": [
      {
        "@type": "oecd:StakeholderGroup",
        "@id": "https://example.org/stakeholder-group/workers",
        "name": "Workers"
      },
      {
        "@type": "core:Person",
        "@id": "https://example.org/entities/person/motorists",
        "name": "Motorists"
      }
    ],
    "businessFunction": [
      "oecd:CustomerService",
      "oecd:OtherFunction"
    ],
    "submitter": {
      "@type": "oecd:Submitter",
      "@id": "https://example.org/submitter/reporter",
      "role": "Data Scientist",
      "affiliation": "Consumer Protection Agency",
      "stakeholderGroup": "None of the above, but have partial or substantial knowledge of the incident",
      "relationToIncident": "None of the above, but have partial or substantial knowledge of the incident (e.g. first-hand knowledge, research etc.)"
    },
    "unintendedUse": false
  },
  {
    "@context": [
      "http://localhost:3000/api/schemas/v1/core/context.jsonld",
      "http://localhost:3001/api/schemas/v1/oecd/context.jsonld"
    ],
    "@type": "oecd:Incident",
    "@id": "https://oecd.ai/incident/OECD-2024-206",
    "incident_id": "OECD-2024-206",
    "title": "AI System Failure Related to Class Action Lawsuit Over Alleged Defects in Volkswagen's AI-Driven AEB Systems",
    "description": "An AI system failure occurred with similar characteristics to the documented incident involving Volkswagen Group of America. The system exhibited comparable failure modes resulting in harm to affected stakeholders.",
    "date": "2024-08-11",
    "aiSystem": {
      "@type": "oecd:AISystem",
      "name": "Intelligent Engine",
      "version": "5.1",
      "relation": [
        "oecd:DirectCause"
      ]
    },
    "developer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/Volkswagen_Group_of_America",
      "name": "Volkswagen Group of America"
    },
    "deployer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/Volkswagen_Group_of_America",
      "name": "Volkswagen Group of America"
    },
    "severity": "oecd:SeriousIncident",
    "harmType": [
      "oecd:OtherHarm"
    ],
    "harmQuantification": {
      "@type": "oecd:HarmQuantification",
      "affected_stakeholders": "49847 individuals"
    },
    "countries": [
      {
        "@type": "core:Country",
        "@id": "https://www.wikidata.org/wiki/Norway",
        "name": "Norway"
      }
    ],
    "affectedStakeholders": [
      {
        "@type": "core:Person",
        "@id": "https://example.org/entities/person/volkswagen-drivers",
        "name": "Volkswagen drivers"
      },
      {
        "@type": "oecd:StakeholderGroup",
        "@id": "https://example.org/stakeholder-group/potential-passengers-and-road-users-at-risk-due-to-malfunctioning-aeb-systems",
        "name": "Potential passengers and road users at risk due to malfunctioning AEB systems"
      }
    ],
    "businessFunction": [
      "oecd:CustomerService",
      "oecd:Marketing"
    ],
    "submitter": {
      "@type": "oecd:Submitter",
      "@id": "https://example.org/submitter/submitter",
      "role": "Academic Researcher",
      "affiliation": "Digital Rights Foundation",
      "stakeholderGroup": "I represent a government or regulatory body",
      "relationToIncident": "None of the above, but have partial or substantial knowledge of the incident (e.g. first-hand knowledge, research etc.)"
    },
    "unintendedUse": true,
    "sameAs": "https://incidentdatabase.ai/cite/746"
  },
  {
    "@context": [
      "http://localhost:3000/api/schemas/v1/core/context.jsonld",
      "http://localhost:3001/api/schemas/v1/oecd/context.jsonld"
    ],
    "@type": "oecd:Incident",
    "@id": "https://oecd.ai/incident/OECD-2024-207",
    "incident_id": "OECD-2024-207",
    "title": "Predictive Policing Algorithm Creates Feedback Loops in Minority Neighborhoods",
    "description": "An AI system for predicting crime hotspots consistently directed more police presence to minority neighborhoods, creating a self-reinforcing cycle where increased police presence led to more reported incidents, further biasing the algorithm.",
    "date": "2024-08-22",
    "aiSystem": {
      "@type": "oecd:AISystem",
      "name": "Security/Surveillance Engine Pro",
      "version": "4.1.52",
      "relation": [
        "oecd:DirectCause",
        "oecd:ContributingFactor"
      ]
    },
    "developer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/Uber",
      "name": "Uber"
    },
    "deployer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/Apple_Inc.",
      "name": "Apple"
    },
    "severity": "oecd:SeriousHazard",
    "harmType": [
      "oecd:HumanRightsHarm",
      "oecd:PsychologicalHarm"
    ],
    "harmQuantification": {
      "@type": "oecd:HarmQuantification",
      "affected_stakeholders": "7671 customers",
      "psychological_impact": "Documented stress and anxiety in affected population"
    },
    "countries": [
      {
        "@type": "core:Country",
        "@id": "https://www.wikidata.org/wiki/France",
        "name": "France"
      },
      {
        "@type": "core:Country",
        "@id": "https://www.wikidata.org/wiki/Mexico",
        "name": "Mexico"
      }
    ],
    "affectedStakeholders": [
      {
        "@type": "oecd:StakeholderGroup",
        "@id": "https://example.org/stakeholder-group/minority-groups",
        "name": "Minority Groups"
      },
      {
        "@type": "oecd:StakeholderGroup",
        "@id": "https://example.org/stakeholder-group/students",
        "name": "Students"
      },
      {
        "@type": "core:Person",
        "@id": "https://example.org/entities/person/medical-residents",
        "name": "Medical Residents"
      }
    ],
    "businessFunction": [
      "oecd:Compliance",
      "oecd:Planning"
    ],
    "submitter": {
      "@type": "oecd:Submitter",
      "@id": "https://example.org/submitter/reporter",
      "role": "Industry Whistleblower",
      "affiliation": "Consumer Protection Agency",
      "stakeholderGroup": "None of the above, but have partial or substantial knowledge of the incident",
      "relationToIncident": "None of the above, but have partial or substantial knowledge of the incident (e.g. first-hand knowledge, research etc.)"
    },
    "unintendedUse": true
  },
  {
    "@context": [
      "http://localhost:3000/api/schemas/v1/core/context.jsonld",
      "http://localhost:3001/api/schemas/v1/oecd/context.jsonld"
    ],
    "@type": "oecd:Incident",
    "@id": "https://oecd.ai/incident/OECD-2024-208",
    "incident_id": "OECD-2024-208",
    "title": "AI System Failure Related to Deepfake of Kamala Harris Saying Damaging Comments Circulates on X and Is Amplified by Elon Musk",
    "description": "An AI system failure occurred with similar characteristics to the documented incident involving X (Twitter). The system exhibited comparable failure modes resulting in harm to affected stakeholders.",
    "date": "2024-09-03",
    "aiSystem": {
      "@type": "oecd:AISystem",
      "name": "Smart Engine",
      "version": "2.2",
      "relation": [
        "oecd:DirectCause"
      ]
    },
    "developer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/X_(Twitter)",
      "name": "X (Twitter)"
    },
    "deployer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/X_(Twitter)",
      "name": "X (Twitter)"
    },
    "severity": "oecd:SeriousIncident",
    "harmType": [
      "oecd:OtherHarm"
    ],
    "harmQuantification": {
      "@type": "oecd:HarmQuantification",
      "affected_stakeholders": "47304 individuals",
      "economic_losses": "$6 million"
    },
    "countries": [
      {
        "@type": "core:Country",
        "@id": "https://www.wikidata.org/wiki/Italy",
        "name": "Italy"
      },
      {
        "@type": "core:Country",
        "@id": "https://www.wikidata.org/wiki/Brazil",
        "name": "Brazil"
      },
      {
        "@type": "core:Country",
        "@id": "https://www.wikidata.org/wiki/Sweden",
        "name": "Sweden"
      }
    ],
    "affectedStakeholders": [
      {
        "@type": "core:Person",
        "@id": "https://example.org/entities/person/truth",
        "name": "Truth"
      },
      {
        "@type": "core:Person",
        "@id": "https://example.org/entities/person/kamala-harris",
        "name": "Kamala Harris"
      },
      {
        "@type": "core:Person",
        "@id": "https://example.org/entities/person/joe-biden",
        "name": "Joe Biden"
      },
      {
        "@type": "oecd:StakeholderGroup",
        "@id": "https://example.org/stakeholder-group/general-public",
        "name": "General public"
      },
      {
        "@type": "core:Person",
        "@id": "https://example.org/entities/person/american-voters",
        "name": "American voters"
      }
    ],
    "businessFunction": [
      "oecd:Compliance",
      "oecd:CustomerService"
    ],
    "submitter": {
      "@type": "oecd:Submitter",
      "@id": "https://example.org/submitter/submitter",
      "role": "Academic Researcher",
      "affiliation": "University Research Lab",
      "stakeholderGroup": "None of the above, but have partial or substantial knowledge of the incident",
      "relationToIncident": "I am an affected stakeholder"
    },
    "unintendedUse": false,
    "sameAs": "https://incidentdatabase.ai/cite/756"
  },
  {
    "@context": [
      "http://localhost:3000/api/schemas/v1/core/context.jsonld",
      "http://localhost:3001/api/schemas/v1/oecd/context.jsonld"
    ],
    "@type": "oecd:Incident",
    "@id": "https://oecd.ai/incident/OECD-2024-209",
    "incident_id": "OECD-2024-209",
    "title": "AI System Failure Related to AI-Generated Fake Audio of Verbal Abuse Incident Circulates of British Labour Leader Keir Starmer",
    "description": "An AI system failure occurred with similar characteristics to the documented incident involving unknown. The system exhibited comparable failure modes resulting in harm to affected stakeholders.",
    "date": "2024-09-03",
    "aiSystem": {
      "@type": "oecd:AISystem",
      "name": "AI Solution",
      "version": "1.2",
      "relation": [
        "oecd:DirectCause"
      ]
    },
    "developer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/unknown",
      "name": "unknown"
    },
    "deployer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/unknown",
      "name": "unknown"
    },
    "severity": "oecd:SeriousIncident",
    "harmType": [
      "oecd:OtherHarm"
    ],
    "harmQuantification": {
      "@type": "oecd:HarmQuantification",
      "affected_stakeholders": "17015 individuals",
      "economic_losses": "$4 million"
    },
    "countries": [
      {
        "@type": "core:Country",
        "@id": "https://www.wikidata.org/wiki/United_Kingdom",
        "name": "United Kingdom"
      },
      {
        "@type": "core:Country",
        "@id": "https://www.wikidata.org/wiki/Canada",
        "name": "Canada"
      },
      {
        "@type": "core:Country",
        "@id": "https://www.wikidata.org/wiki/Australia",
        "name": "Australia"
      }
    ],
    "affectedStakeholders": [
      {
        "@type": "core:Person",
        "@id": "https://example.org/entities/person/uk-labour-party",
        "name": "UK Labour Party"
      },
      {
        "@type": "core:Person",
        "@id": "https://example.org/entities/person/keir-starmer",
        "name": "Keir Starmer"
      }
    ],
    "businessFunction": [
      "oecd:Logistics"
    ],
    "submitter": {
      "@type": "oecd:Submitter",
      "@id": "https://example.org/submitter/submitter",
      "role": "AI Safety Researcher",
      "affiliation": "AI Safety Institute",
      "stakeholderGroup": "I represent a government or regulatory body",
      "relationToIncident": "I am an affected stakeholder"
    },
    "unintendedUse": false,
    "sameAs": "https://incidentdatabase.ai/cite/601"
  },
  {
    "@context": [
      "http://localhost:3000/api/schemas/v1/core/context.jsonld",
      "http://localhost:3001/api/schemas/v1/oecd/context.jsonld"
    ],
    "@type": "oecd:Incident",
    "@id": "https://oecd.ai/incident/OECD-2024-210",
    "incident_id": "OECD-2024-210",
    "title": "Surgical Robot Malfunction During Minimally Invasive Procedure",
    "description": "An AI-assisted surgical robot experienced a control system failure during a procedure, requiring emergency conversion to traditional surgery. The AI's motion planning algorithms failed to account for unexpected tissue resistance.",
    "date": "2024-09-07",
    "aiSystem": {
      "@type": "oecd:AISystem",
      "name": "Medical AI System",
      "version": "7.11.62",
      "relation": [
        "oecd:DirectCause",
        "oecd:ContributingFactor"
      ]
    },
    "developer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/Northpointe",
      "name": "Northpointe"
    },
    "deployer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/Starbucks",
      "name": "Starbucks"
    },
    "severity": "oecd:SeriousIncident",
    "harmType": [
      "oecd:PhysicalHarm"
    ],
    "harmQuantification": {
      "@type": "oecd:HarmQuantification",
      "affected_stakeholders": "50843 individuals",
      "economic_losses": "$7.0 million"
    },
    "countries": [
      {
        "@type": "core:Country",
        "@id": "https://www.wikidata.org/wiki/United_Kingdom",
        "name": "United Kingdom"
      },
      {
        "@type": "core:Country",
        "@id": "https://www.wikidata.org/wiki/Netherlands",
        "name": "Netherlands"
      }
    ],
    "affectedStakeholders": [
      {
        "@type": "oecd:StakeholderGroup",
        "@id": "https://example.org/stakeholder-group/patients",
        "name": "Patients"
      },
      {
        "@type": "core:Person",
        "@id": "https://example.org/entities/person/job-applicants",
        "name": "Job applicants"
      }
    ],
    "businessFunction": [
      "oecd:OtherFunction"
    ],
    "submitter": {
      "@type": "oecd:Submitter",
      "@id": "https://example.org/submitter/reporter",
      "role": "Government Auditor",
      "affiliation": "Consumer Protection Agency",
      "stakeholderGroup": "I am an affected stakeholder",
      "relationToIncident": "None of the above, but have partial or substantial knowledge of the incident (e.g. first-hand knowledge, research etc.)"
    },
    "unintendedUse": false
  },
  {
    "@context": [
      "http://localhost:3000/api/schemas/v1/core/context.jsonld",
      "http://localhost:3001/api/schemas/v1/oecd/context.jsonld"
    ],
    "@type": "oecd:Incident",
    "@id": "https://oecd.ai/incident/OECD-2024-211",
    "incident_id": "OECD-2024-211",
    "title": "Facial Recognition System Falsely Identifies Protesters as Criminals",
    "description": "A law enforcement facial recognition system incorrectly matched peaceful protesters with criminal database entries, leading to wrongful detentions. The AI system showed higher error rates for certain ethnic groups and in crowded scenarios.",
    "date": "2024-09-11",
    "aiSystem": {
      "@type": "oecd:AISystem",
      "name": "Security/Surveillance Platform",
      "version": "6.7.37",
      "relation": [
        "oecd:ContributingFactor"
      ]
    },
    "developer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/Google",
      "name": "Google"
    },
    "deployer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/New_Zealand",
      "name": "New Zealand"
    },
    "severity": "oecd:SeriousIncident",
    "harmType": [
      "oecd:PhysicalHarm",
      "oecd:HumanRightsHarm",
      "oecd:ReputationalHarm"
    ],
    "harmQuantification": {
      "@type": "oecd:HarmQuantification",
      "affected_stakeholders": "39027 patients"
    },
    "countries": [
      {
        "@type": "core:Country",
        "@id": "https://www.wikidata.org/wiki/Brazil",
        "name": "Brazil"
      }
    ],
    "affectedStakeholders": [
      {
        "@type": "core:Person",
        "@id": "https://example.org/entities/person/job-applicants",
        "name": "Job applicants"
      },
      {
        "@type": "core:Person",
        "@id": "https://example.org/entities/person/bus-passengers",
        "name": "Bus passengers"
      }
    ],
    "businessFunction": [
      "oecd:Compliance"
    ],
    "submitter": {
      "@type": "oecd:Submitter",
      "@id": "https://example.org/submitter/reporter",
      "role": "Consumer Advocate",
      "affiliation": "Tech Accountability Project",
      "stakeholderGroup": "None of the above, but have partial or substantial knowledge of the incident",
      "relationToIncident": "None of the above, but have partial or substantial knowledge of the incident (e.g. first-hand knowledge, research etc.)"
    },
    "unintendedUse": false
  },
  {
    "@context": [
      "http://localhost:3000/api/schemas/v1/core/context.jsonld",
      "http://localhost:3001/api/schemas/v1/oecd/context.jsonld"
    ],
    "@type": "oecd:Incident",
    "@id": "https://oecd.ai/incident/OECD-2024-212",
    "incident_id": "OECD-2024-212",
    "title": "Facial Recognition System Falsely Identifies Protesters as Criminals",
    "description": "A law enforcement facial recognition system incorrectly matched peaceful protesters with criminal database entries, leading to wrongful detentions. The AI system showed higher error rates for certain ethnic groups and in crowded scenarios.",
    "date": "2024-09-12",
    "aiSystem": {
      "@type": "oecd:AISystem",
      "name": "Security/Surveillance System Pro",
      "version": "5.15.73",
      "relation": [
        "oecd:DirectCause"
      ]
    },
    "developer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/Google",
      "name": "Google"
    },
    "deployer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/Tesla,_Inc.",
      "name": "Tesla"
    },
    "severity": "oecd:SeriousIncident",
    "harmType": [
      "oecd:PhysicalHarm",
      "oecd:HumanRightsHarm",
      "oecd:ReputationalHarm"
    ],
    "harmQuantification": {
      "@type": "oecd:HarmQuantification",
      "affected_stakeholders": "70577 patients",
      "economic_losses": "$40.4 million"
    },
    "countries": [
      {
        "@type": "core:Country",
        "@id": "https://www.wikidata.org/wiki/Germany",
        "name": "Germany"
      }
    ],
    "affectedStakeholders": [
      {
        "@type": "core:Person",
        "@id": "https://example.org/entities/person/bus-passengers",
        "name": "Bus passengers"
      },
      {
        "@type": "oecd:StakeholderGroup",
        "@id": "https://example.org/stakeholder-group/workers",
        "name": "Workers"
      }
    ],
    "businessFunction": [
      "oecd:Compliance"
    ],
    "submitter": {
      "@type": "oecd:Submitter",
      "@id": "https://example.org/submitter/reporter",
      "role": "Industry Whistleblower",
      "affiliation": "Consumer Protection Agency",
      "stakeholderGroup": "I work or am affiliated to a public interest body or NGO",
      "relationToIncident": "None of the above, but have partial or substantial knowledge of the incident (e.g. first-hand knowledge, research etc.)"
    },
    "unintendedUse": true
  },
  {
    "@context": [
      "http://localhost:3000/api/schemas/v1/core/context.jsonld",
      "http://localhost:3001/api/schemas/v1/oecd/context.jsonld"
    ],
    "@type": "oecd:Incident",
    "@id": "https://oecd.ai/incident/OECD-2024-213",
    "incident_id": "OECD-2024-213",
    "title": "AI System Failure Related to Starship’s Autonomous Food Delivery Robot Allegedly Stranded at Railroad Crossing in Oregon, Run over by Freight Train",
    "description": "An AI system failure occurred with similar characteristics to the documented incident involving Oregon State University. The system exhibited comparable failure modes resulting in harm to affected stakeholders.",
    "date": "2024-09-16",
    "aiSystem": {
      "@type": "oecd:AISystem",
      "name": "Smart System",
      "version": "3.3",
      "relation": [
        "oecd:DirectCause"
      ]
    },
    "developer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/Oregon_State_University",
      "name": "Oregon State University"
    },
    "deployer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/Oregon_State_University",
      "name": "Oregon State University"
    },
    "severity": "oecd:SeriousIncident",
    "harmType": [
      "oecd:OtherHarm"
    ],
    "harmQuantification": {
      "@type": "oecd:HarmQuantification",
      "affected_stakeholders": "31935 individuals",
      "economic_losses": "$7 million"
    },
    "countries": [
      {
        "@type": "core:Country",
        "@id": "https://www.wikidata.org/wiki/Spain",
        "name": "Spain"
      },
      {
        "@type": "core:Country",
        "@id": "https://www.wikidata.org/wiki/India",
        "name": "India"
      }
    ],
    "affectedStakeholders": [
      {
        "@type": "core:Person",
        "@id": "https://example.org/entities/person/oregon-state-university",
        "name": "Oregon State University"
      },
      {
        "@type": "core:Person",
        "@id": "https://example.org/entities/person/freight-train-crew",
        "name": "freight train crew"
      }
    ],
    "businessFunction": [
      "oecd:Accounting"
    ],
    "submitter": {
      "@type": "oecd:Submitter",
      "@id": "https://example.org/submitter/submitter",
      "role": "Industry Analyst",
      "affiliation": "University Research Lab",
      "stakeholderGroup": "I represent a government or regulatory body",
      "relationToIncident": "I am a user of the related AI system"
    },
    "unintendedUse": false,
    "sameAs": "https://incidentdatabase.ai/cite/176"
  },
  {
    "@context": [
      "http://localhost:3000/api/schemas/v1/core/context.jsonld",
      "http://localhost:3001/api/schemas/v1/oecd/context.jsonld"
    ],
    "@type": "oecd:Incident",
    "@id": "https://oecd.ai/incident/OECD-2024-214",
    "incident_id": "OECD-2024-214",
    "title": "AI System Failure Related to Glovo Driver in Italy Fired via Automated Email after Being Killed in Accident",
    "description": "An AI system failure occurred with similar characteristics to the documented incident involving Glovo. The system exhibited comparable failure modes resulting in harm to affected stakeholders.",
    "date": "2024-10-07",
    "aiSystem": {
      "@type": "oecd:AISystem",
      "name": "Smart Solution",
      "version": "1.2",
      "relation": [
        "oecd:DirectCause"
      ]
    },
    "developer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/Glovo",
      "name": "Glovo"
    },
    "deployer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/Glovo",
      "name": "Glovo"
    },
    "severity": "oecd:SeriousIncident",
    "harmType": [
      "oecd:OtherHarm"
    ],
    "harmQuantification": {
      "@type": "oecd:HarmQuantification",
      "affected_stakeholders": "19496 individuals"
    },
    "countries": [
      {
        "@type": "core:Country",
        "@id": "https://www.wikidata.org/wiki/Sweden",
        "name": "Sweden"
      },
      {
        "@type": "core:Country",
        "@id": "https://www.wikidata.org/wiki/India",
        "name": "India"
      },
      {
        "@type": "core:Country",
        "@id": "https://www.wikidata.org/wiki/Japan",
        "name": "Japan"
      }
    ],
    "affectedStakeholders": [
      {
        "@type": "core:Person",
        "@id": "https://example.org/entities/person/sebastian-galassi-s-family",
        "name": "Sebastian Galassi's family"
      },
      {
        "@type": "core:Person",
        "@id": "https://example.org/entities/person/sebastian-galassi",
        "name": "Sebastian Galassi"
      }
    ],
    "businessFunction": [
      "oecd:Marketing",
      "oecd:HRManagement"
    ],
    "submitter": {
      "@type": "oecd:Submitter",
      "@id": "https://example.org/submitter/submitter",
      "role": "Government Inspector",
      "affiliation": "AI Safety Institute",
      "stakeholderGroup": "I represent a government or regulatory body",
      "relationToIncident": "I am a user of the related AI system"
    },
    "unintendedUse": true,
    "sameAs": "https://incidentdatabase.ai/cite/384"
  },
  {
    "@context": [
      "http://localhost:3000/api/schemas/v1/core/context.jsonld",
      "http://localhost:3001/api/schemas/v1/oecd/context.jsonld"
    ],
    "@type": "oecd:Incident",
    "@id": "https://oecd.ai/incident/OECD-2024-215",
    "incident_id": "OECD-2024-215",
    "title": "AI Diagnostic System Misses Critical Symptoms in Emergency Department",
    "description": "An AI triage system in emergency departments failed to identify critical symptoms in patients presenting with atypical manifestations of serious conditions. The system's training data lacked diversity in symptom presentations across different demographics.",
    "date": "2024-10-12",
    "aiSystem": {
      "@type": "oecd:AISystem",
      "name": "Medical AI Engine Pro",
      "version": "3.0.28",
      "relation": [
        "oecd:ContributingFactor",
        "oecd:HumanError"
      ]
    },
    "developer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/Equivant",
      "name": "Equivant"
    },
    "deployer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/Uber",
      "name": "Uber"
    },
    "severity": "oecd:SeriousHazard",
    "harmType": [
      "oecd:PhysicalHarm",
      "oecd:HumanRightsHarm"
    ],
    "harmQuantification": {
      "@type": "oecd:HarmQuantification",
      "affected_stakeholders": "18500 workers",
      "economic_losses": "$8.5 million"
    },
    "countries": [
      {
        "@type": "core:Country",
        "@id": "https://www.wikidata.org/wiki/Brazil",
        "name": "Brazil"
      },
      {
        "@type": "core:Country",
        "@id": "https://www.wikidata.org/wiki/Japan",
        "name": "Japan"
      }
    ],
    "affectedStakeholders": [
      {
        "@type": "core:Person",
        "@id": "https://example.org/entities/person/bus-passengers",
        "name": "Bus passengers"
      },
      {
        "@type": "oecd:StakeholderGroup",
        "@id": "https://example.org/stakeholder-group/women",
        "name": "Women"
      },
      {
        "@type": "core:Person",
        "@id": "https://example.org/entities/person/black-people",
        "name": "Black people"
      }
    ],
    "businessFunction": [
      "oecd:OtherFunction"
    ],
    "submitter": {
      "@type": "oecd:Submitter",
      "@id": "https://example.org/submitter/reporter",
      "role": "Safety Engineer",
      "affiliation": "Tech Accountability Project",
      "stakeholderGroup": "I represent a government or regulatory body",
      "relationToIncident": "None of the above, but have partial or substantial knowledge of the incident (e.g. first-hand knowledge, research etc.)"
    },
    "unintendedUse": true
  },
  {
    "@context": [
      "http://localhost:3000/api/schemas/v1/core/context.jsonld",
      "http://localhost:3001/api/schemas/v1/oecd/context.jsonld"
    ],
    "@type": "oecd:Incident",
    "@id": "https://oecd.ai/incident/OECD-2024-216",
    "incident_id": "OECD-2024-216",
    "title": "AI System Failure Related to AI-Generated Fake Audio of Verbal Abuse Incident Circulates of British Labour Leader Keir Starmer",
    "description": "An AI system failure occurred with similar characteristics to the documented incident involving unknown. The system exhibited comparable failure modes resulting in harm to affected stakeholders.",
    "date": "2024-10-17",
    "aiSystem": {
      "@type": "oecd:AISystem",
      "name": "Intelligent Platform",
      "version": "3.4",
      "relation": [
        "oecd:DirectCause"
      ]
    },
    "developer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/unknown",
      "name": "unknown"
    },
    "deployer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/unknown",
      "name": "unknown"
    },
    "severity": "oecd:SeriousIncident",
    "harmType": [
      "oecd:OtherHarm"
    ],
    "harmQuantification": {
      "@type": "oecd:HarmQuantification",
      "affected_stakeholders": "11778 individuals",
      "economic_losses": "$8 million"
    },
    "countries": [
      {
        "@type": "core:Country",
        "@id": "https://www.wikidata.org/wiki/China",
        "name": "China"
      },
      {
        "@type": "core:Country",
        "@id": "https://www.wikidata.org/wiki/Israel",
        "name": "Israel"
      }
    ],
    "affectedStakeholders": [
      {
        "@type": "core:Person",
        "@id": "https://example.org/entities/person/uk-labour-party",
        "name": "UK Labour Party"
      },
      {
        "@type": "core:Person",
        "@id": "https://example.org/entities/person/keir-starmer",
        "name": "Keir Starmer"
      }
    ],
    "businessFunction": [
      "oecd:Accounting"
    ],
    "submitter": {
      "@type": "oecd:Submitter",
      "@id": "https://example.org/submitter/submitter",
      "role": "Ethics Officer",
      "affiliation": "Digital Rights Foundation",
      "stakeholderGroup": "None of the above, but have partial or substantial knowledge of the incident",
      "relationToIncident": "None of the above, but have partial or substantial knowledge of the incident (e.g. first-hand knowledge, research etc.)"
    },
    "unintendedUse": false,
    "sameAs": "https://incidentdatabase.ai/cite/601"
  },
  {
    "@context": [
      "http://localhost:3000/api/schemas/v1/core/context.jsonld",
      "http://localhost:3001/api/schemas/v1/oecd/context.jsonld"
    ],
    "@type": "oecd:Incident",
    "@id": "https://oecd.ai/incident/OECD-2024-217",
    "incident_id": "OECD-2024-217",
    "title": "AI Diagnostic System Misses Critical Symptoms in Emergency Department",
    "description": "An AI triage system in emergency departments failed to identify critical symptoms in patients presenting with atypical manifestations of serious conditions. The system's training data lacked diversity in symptom presentations across different demographics.",
    "date": "2024-10-20",
    "aiSystem": {
      "@type": "oecd:AISystem",
      "name": "Medical AI Engine Pro",
      "version": "2.18.34",
      "relation": [
        "oecd:DirectCause",
        "oecd:FailureToAct"
      ]
    },
    "developer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/LinkedIn",
      "name": "LinkedIn"
    },
    "deployer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/New_York_city_Dept._of_Education",
      "name": "New York city Dept. of Education"
    },
    "severity": "oecd:SeriousHazard",
    "harmType": [
      "oecd:PhysicalHarm",
      "oecd:HumanRightsHarm"
    ],
    "harmQuantification": {
      "@type": "oecd:HarmQuantification",
      "affected_stakeholders": "1622 patients",
      "economic_losses": "$26.9 million"
    },
    "countries": [
      {
        "@type": "core:Country",
        "@id": "https://www.wikidata.org/wiki/Israel",
        "name": "Israel"
      },
      {
        "@type": "core:Country",
        "@id": "https://www.wikidata.org/wiki/Netherlands",
        "name": "Netherlands"
      }
    ],
    "affectedStakeholders": [
      {
        "@type": "oecd:StakeholderGroup",
        "@id": "https://example.org/stakeholder-group/children",
        "name": "Children"
      }
    ],
    "businessFunction": [
      "oecd:OtherFunction"
    ],
    "submitter": {
      "@type": "oecd:Submitter",
      "@id": "https://example.org/submitter/reporter",
      "role": "Safety Engineer",
      "affiliation": "Tech Accountability Project",
      "stakeholderGroup": "I am an affected stakeholder",
      "relationToIncident": "None of the above, but have partial or substantial knowledge of the incident (e.g. first-hand knowledge, research etc.)"
    },
    "unintendedUse": false
  },
  {
    "@context": [
      "http://localhost:3000/api/schemas/v1/core/context.jsonld",
      "http://localhost:3001/api/schemas/v1/oecd/context.jsonld"
    ],
    "@type": "oecd:Incident",
    "@id": "https://oecd.ai/incident/OECD-2024-218",
    "incident_id": "OECD-2024-218",
    "title": "AI System Failure Related to Bankrate's Resumption of AI-Generated Content Allegedly Continuing to Produce Inaccurate and Misleading Information",
    "description": "An AI system failure occurred with similar characteristics to the documented incident involving Red Ventures. The system exhibited comparable failure modes resulting in harm to affected stakeholders.",
    "date": "2024-10-22",
    "aiSystem": {
      "@type": "oecd:AISystem",
      "name": "Intelligent System",
      "version": "2.9",
      "relation": [
        "oecd:DirectCause"
      ]
    },
    "developer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/Red_Ventures",
      "name": "Red Ventures"
    },
    "deployer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/Red_Ventures",
      "name": "Red Ventures"
    },
    "severity": "oecd:SeriousIncident",
    "harmType": [
      "oecd:OtherHarm"
    ],
    "harmQuantification": {
      "@type": "oecd:HarmQuantification",
      "affected_stakeholders": "39643 individuals",
      "economic_losses": "$5 million"
    },
    "countries": [
      {
        "@type": "core:Country",
        "@id": "https://www.wikidata.org/wiki/France",
        "name": "France"
      },
      {
        "@type": "core:Country",
        "@id": "https://www.wikidata.org/wiki/China",
        "name": "China"
      }
    ],
    "affectedStakeholders": [
      {
        "@type": "core:Person",
        "@id": "https://example.org/entities/person/journalistic-integrity",
        "name": "Journalistic integrity"
      },
      {
        "@type": "oecd:StakeholderGroup",
        "@id": "https://example.org/stakeholder-group/general-public",
        "name": "General public"
      }
    ],
    "businessFunction": [
      "oecd:ResearchDevelopment",
      "oecd:Maintenance"
    ],
    "submitter": {
      "@type": "oecd:Submitter",
      "@id": "https://example.org/submitter/submitter",
      "role": "Academic Researcher",
      "affiliation": "AI Safety Institute",
      "stakeholderGroup": "I represent a government or regulatory body",
      "relationToIncident": "None of the above, but have partial or substantial knowledge of the incident (e.g. first-hand knowledge, research etc.)"
    },
    "unintendedUse": false,
    "sameAs": "https://incidentdatabase.ai/cite/577"
  },
  {
    "@context": [
      "http://localhost:3000/api/schemas/v1/core/context.jsonld",
      "http://localhost:3001/api/schemas/v1/oecd/context.jsonld"
    ],
    "@type": "oecd:Incident",
    "@id": "https://oecd.ai/incident/OECD-2024-219",
    "incident_id": "OECD-2024-219",
    "title": "AI System Failure Related to British Female Politicians Victimized by Deepfake Pornography",
    "description": "An AI system failure occurred with similar characteristics to the documented incident involving Unknown deepfake creators. The system exhibited comparable failure modes resulting in harm to affected stakeholders.",
    "date": "2024-11-07",
    "aiSystem": {
      "@type": "oecd:AISystem",
      "name": "Intelligent System",
      "version": "1.7",
      "relation": [
        "oecd:DirectCause"
      ]
    },
    "developer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/Unknown_deepfake_creators",
      "name": "Unknown deepfake creators"
    },
    "deployer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/Unknown_deepfake_creators",
      "name": "Unknown deepfake creators"
    },
    "severity": "oecd:SeriousIncident",
    "harmType": [
      "oecd:OtherHarm"
    ],
    "harmQuantification": {
      "@type": "oecd:HarmQuantification",
      "affected_stakeholders": "4169 individuals",
      "economic_losses": "$6 million"
    },
    "countries": [
      {
        "@type": "core:Country",
        "@id": "https://www.wikidata.org/wiki/India",
        "name": "India"
      }
    ],
    "affectedStakeholders": [
      {
        "@type": "core:Person",
        "@id": "https://example.org/entities/person/stella-creasy",
        "name": "Stella Creasy"
      },
      {
        "@type": "core:Person",
        "@id": "https://example.org/entities/person/priti-patel",
        "name": "Priti Patel"
      },
      {
        "@type": "core:Person",
        "@id": "https://example.org/entities/person/penny-mordaunt",
        "name": "Penny Mordaunt"
      },
      {
        "@type": "core:Person",
        "@id": "https://example.org/entities/person/gillian-keegan",
        "name": "Gillian Keegan"
      },
      {
        "@type": "core:Person",
        "@id": "https://example.org/entities/person/dehenna-davison",
        "name": "Dehenna Davison"
      },
      {
        "@type": "core:Person",
        "@id": "https://example.org/entities/person/angela-rayner",
        "name": "Angela Rayner"
      }
    ],
    "businessFunction": [
      "oecd:Procurement",
      "oecd:ResearchDevelopment"
    ],
    "submitter": {
      "@type": "oecd:Submitter",
      "@id": "https://example.org/submitter/submitter",
      "role": "Industry Analyst",
      "affiliation": "Government Oversight Committee",
      "stakeholderGroup": "None of the above, but have partial or substantial knowledge of the incident",
      "relationToIncident": "I am a user of the related AI system"
    },
    "unintendedUse": false,
    "sameAs": "https://incidentdatabase.ai/cite/754"
  },
  {
    "@context": [
      "http://localhost:3000/api/schemas/v1/core/context.jsonld",
      "http://localhost:3001/api/schemas/v1/oecd/context.jsonld"
    ],
    "@type": "oecd:Incident",
    "@id": "https://oecd.ai/incident/OECD-2024-220",
    "incident_id": "OECD-2024-220",
    "title": "AI System Failure Related to Tesla Autopilot Misidentified On-Road Horse-Drawn Carriage",
    "description": "An AI system failure occurred with similar characteristics to the documented incident involving Tesla. The system exhibited comparable failure modes resulting in harm to affected stakeholders.",
    "date": "2024-11-11",
    "aiSystem": {
      "@type": "oecd:AISystem",
      "name": "Automated Engine",
      "version": "1.6",
      "relation": [
        "oecd:DirectCause"
      ]
    },
    "developer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/Tesla,_Inc.",
      "name": "Tesla"
    },
    "deployer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/Tesla,_Inc.",
      "name": "Tesla"
    },
    "severity": "oecd:SeriousIncident",
    "harmType": [
      "oecd:OtherHarm"
    ],
    "harmQuantification": {
      "@type": "oecd:HarmQuantification",
      "affected_stakeholders": "4910 individuals"
    },
    "countries": [
      {
        "@type": "core:Country",
        "@id": "https://www.wikidata.org/wiki/France",
        "name": "France"
      }
    ],
    "affectedStakeholders": [
      {
        "@type": "core:Person",
        "@id": "https://example.org/entities/person/tesla-drivers",
        "name": "Tesla drivers"
      },
      {
        "@type": "core:Person",
        "@id": "https://example.org/entities/person/horse-drawn-carriages",
        "name": "horse-drawn carriages"
      }
    ],
    "businessFunction": [
      "oecd:Marketing"
    ],
    "submitter": {
      "@type": "oecd:Submitter",
      "@id": "https://example.org/submitter/submitter",
      "role": "Ethics Officer",
      "affiliation": "Government Oversight Committee",
      "stakeholderGroup": "I represent a government or regulatory body",
      "relationToIncident": "None of the above, but have partial or substantial knowledge of the incident (e.g. first-hand knowledge, research etc.)"
    },
    "unintendedUse": false,
    "sameAs": "https://incidentdatabase.ai/cite/398"
  },
  {
    "@context": [
      "http://localhost:3000/api/schemas/v1/core/context.jsonld",
      "http://localhost:3001/api/schemas/v1/oecd/context.jsonld"
    ],
    "@type": "oecd:Incident",
    "@id": "https://oecd.ai/incident/OECD-2024-221",
    "incident_id": "OECD-2024-221",
    "title": "AI System Failure Related to Bankrate's Resumption of AI-Generated Content Allegedly Continuing to Produce Inaccurate and Misleading Information",
    "description": "An AI system failure occurred with similar characteristics to the documented incident involving Red Ventures. The system exhibited comparable failure modes resulting in harm to affected stakeholders.",
    "date": "2024-11-14",
    "aiSystem": {
      "@type": "oecd:AISystem",
      "name": "Automated Platform",
      "version": "1.4",
      "relation": [
        "oecd:DirectCause"
      ]
    },
    "developer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/Red_Ventures",
      "name": "Red Ventures"
    },
    "deployer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/Red_Ventures",
      "name": "Red Ventures"
    },
    "severity": "oecd:SeriousIncident",
    "harmType": [
      "oecd:OtherHarm"
    ],
    "harmQuantification": {
      "@type": "oecd:HarmQuantification",
      "affected_stakeholders": "25267 individuals",
      "economic_losses": "$10 million"
    },
    "countries": [
      {
        "@type": "core:Country",
        "@id": "https://www.wikidata.org/wiki/Singapore",
        "name": "Singapore"
      },
      {
        "@type": "core:Country",
        "@id": "https://www.wikidata.org/wiki/Sweden",
        "name": "Sweden"
      },
      {
        "@type": "core:Country",
        "@id": "https://www.wikidata.org/wiki/China",
        "name": "China"
      }
    ],
    "affectedStakeholders": [
      {
        "@type": "core:Person",
        "@id": "https://example.org/entities/person/journalistic-integrity",
        "name": "Journalistic integrity"
      },
      {
        "@type": "oecd:StakeholderGroup",
        "@id": "https://example.org/stakeholder-group/general-public",
        "name": "General public"
      }
    ],
    "businessFunction": [
      "oecd:Planning",
      "oecd:Logistics"
    ],
    "submitter": {
      "@type": "oecd:Submitter",
      "@id": "https://example.org/submitter/submitter",
      "role": "Government Inspector",
      "affiliation": "University Research Lab",
      "stakeholderGroup": "I represent a government or regulatory body",
      "relationToIncident": "None of the above, but have partial or substantial knowledge of the incident (e.g. first-hand knowledge, research etc.)"
    },
    "unintendedUse": false,
    "sameAs": "https://incidentdatabase.ai/cite/577"
  },
  {
    "@context": [
      "http://localhost:3000/api/schemas/v1/core/context.jsonld",
      "http://localhost:3001/api/schemas/v1/oecd/context.jsonld"
    ],
    "@type": "oecd:Incident",
    "@id": "https://oecd.ai/incident/OECD-2024-222",
    "incident_id": "OECD-2024-222",
    "title": "Predictive Policing Algorithm Creates Feedback Loops in Minority Neighborhoods",
    "description": "An AI system for predicting crime hotspots consistently directed more police presence to minority neighborhoods, creating a self-reinforcing cycle where increased police presence led to more reported incidents, further biasing the algorithm.",
    "date": "2024-11-25",
    "aiSystem": {
      "@type": "oecd:AISystem",
      "name": "Security/Surveillance Solution Pro",
      "version": "3.0.61",
      "relation": [
        "oecd:DirectCause",
        "oecd:FailureToAct"
      ]
    },
    "developer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/Youth_Laboratories",
      "name": "Youth Laboratories"
    },
    "deployer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/Tesla,_Inc.",
      "name": "Tesla"
    },
    "severity": "oecd:SeriousHazard",
    "harmType": [
      "oecd:HumanRightsHarm",
      "oecd:PsychologicalHarm"
    ],
    "harmQuantification": {
      "@type": "oecd:HarmQuantification",
      "affected_stakeholders": "63440 users",
      "psychological_impact": "Documented stress and anxiety in affected population"
    },
    "countries": [
      {
        "@type": "core:Country",
        "@id": "https://www.wikidata.org/wiki/Netherlands",
        "name": "Netherlands"
      },
      {
        "@type": "core:Country",
        "@id": "https://www.wikidata.org/wiki/South_Korea",
        "name": "South Korea"
      }
    ],
    "affectedStakeholders": [
      {
        "@type": "oecd:StakeholderGroup",
        "@id": "https://example.org/stakeholder-group/children",
        "name": "Children"
      }
    ],
    "businessFunction": [
      "oecd:Compliance",
      "oecd:Planning"
    ],
    "submitter": {
      "@type": "oecd:Submitter",
      "@id": "https://example.org/submitter/reporter",
      "role": "Consumer Advocate",
      "affiliation": "AI Safety Coalition",
      "stakeholderGroup": "None of the above, but have partial or substantial knowledge of the incident",
      "relationToIncident": "None of the above, but have partial or substantial knowledge of the incident (e.g. first-hand knowledge, research etc.)"
    },
    "unintendedUse": false
  },
  {
    "@context": [
      "http://localhost:3000/api/schemas/v1/core/context.jsonld",
      "http://localhost:3001/api/schemas/v1/oecd/context.jsonld"
    ],
    "@type": "oecd:Incident",
    "@id": "https://oecd.ai/incident/OECD-2024-223",
    "incident_id": "OECD-2024-223",
    "title": "Facial Recognition System Falsely Identifies Protesters as Criminals",
    "description": "A law enforcement facial recognition system incorrectly matched peaceful protesters with criminal database entries, leading to wrongful detentions. The AI system showed higher error rates for certain ethnic groups and in crowded scenarios.",
    "date": "2024-12-01",
    "aiSystem": {
      "@type": "oecd:AISystem",
      "name": "Security/Surveillance System Pro",
      "version": "10.9.5",
      "relation": [
        "oecd:DirectCause",
        "oecd:ContributingFactor"
      ]
    },
    "developer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/Microsoft",
      "name": "Microsoft"
    },
    "deployer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/Apple_Inc.",
      "name": "Apple"
    },
    "severity": "oecd:SeriousIncident",
    "harmType": [
      "oecd:PhysicalHarm",
      "oecd:HumanRightsHarm",
      "oecd:ReputationalHarm"
    ],
    "harmQuantification": {
      "@type": "oecd:HarmQuantification",
      "affected_stakeholders": "10108 patients",
      "economic_losses": "$13.3 million"
    },
    "countries": [
      {
        "@type": "core:Country",
        "@id": "https://www.wikidata.org/wiki/China",
        "name": "China"
      },
      {
        "@type": "core:Country",
        "@id": "https://www.wikidata.org/wiki/France",
        "name": "France"
      }
    ],
    "affectedStakeholders": [
      {
        "@type": "oecd:StakeholderGroup",
        "@id": "https://example.org/stakeholder-group/students",
        "name": "Students"
      },
      {
        "@type": "core:Person",
        "@id": "https://example.org/entities/person/bus-passengers",
        "name": "Bus passengers"
      },
      {
        "@type": "oecd:StakeholderGroup",
        "@id": "https://example.org/stakeholder-group/workers",
        "name": "Workers"
      }
    ],
    "businessFunction": [
      "oecd:Compliance"
    ],
    "submitter": {
      "@type": "oecd:Submitter",
      "@id": "https://example.org/submitter/reporter",
      "role": "Consumer Advocate",
      "affiliation": "Consumer Protection Agency",
      "stakeholderGroup": "I work or am affiliated to a public interest body or NGO",
      "relationToIncident": "None of the above, but have partial or substantial knowledge of the incident (e.g. first-hand knowledge, research etc.)"
    },
    "unintendedUse": false
  },
  {
    "@context": [
      "http://localhost:3000/api/schemas/v1/core/context.jsonld",
      "http://localhost:3001/api/schemas/v1/oecd/context.jsonld"
    ],
    "@type": "oecd:Incident",
    "@id": "https://oecd.ai/incident/OECD-2024-224",
    "incident_id": "OECD-2024-224",
    "title": "AI Diagnostic System Misses Critical Symptoms in Emergency Department",
    "description": "An AI triage system in emergency departments failed to identify critical symptoms in patients presenting with atypical manifestations of serious conditions. The system's training data lacked diversity in symptom presentations across different demographics.",
    "date": "2024-12-14",
    "aiSystem": {
      "@type": "oecd:AISystem",
      "name": "Medical AI System",
      "version": "6.13.96",
      "relation": [
        "oecd:DirectCause",
        "oecd:ContributingFactor"
      ]
    },
    "developer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/St_George's_Hospital_Medical_School",
      "name": "St George's Hospital Medical School"
    },
    "deployer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/United_States_Government",
      "name": "United States Government"
    },
    "severity": "oecd:SeriousHazard",
    "harmType": [
      "oecd:PhysicalHarm",
      "oecd:HumanRightsHarm"
    ],
    "harmQuantification": {
      "@type": "oecd:HarmQuantification",
      "affected_stakeholders": "10058 users",
      "economic_losses": "$22.9 million"
    },
    "countries": [
      {
        "@type": "core:Country",
        "@id": "https://www.wikidata.org/wiki/United_States",
        "name": "United States"
      }
    ],
    "affectedStakeholders": [
      {
        "@type": "core:Person",
        "@id": "https://example.org/entities/person/medical-residents",
        "name": "Medical Residents"
      },
      {
        "@type": "oecd:StakeholderGroup",
        "@id": "https://example.org/stakeholder-group/women",
        "name": "Women"
      }
    ],
    "businessFunction": [
      "oecd:OtherFunction"
    ],
    "submitter": {
      "@type": "oecd:Submitter",
      "@id": "https://example.org/submitter/reporter",
      "role": "Data Scientist",
      "affiliation": "Consumer Protection Agency",
      "stakeholderGroup": "I work or am affiliated to a public interest body or NGO",
      "relationToIncident": "None of the above, but have partial or substantial knowledge of the incident (e.g. first-hand knowledge, research etc.)"
    },
    "unintendedUse": false
  },
  {
    "@context": [
      "http://localhost:3000/api/schemas/v1/core/context.jsonld",
      "http://localhost:3001/api/schemas/v1/oecd/context.jsonld"
    ],
    "@type": "oecd:Incident",
    "@id": "https://oecd.ai/incident/OECD-2024-225",
    "incident_id": "OECD-2024-225",
    "title": "AI System Failure Related to Glovo Driver in Italy Fired via Automated Email after Being Killed in Accident",
    "description": "An AI system failure occurred with similar characteristics to the documented incident involving Glovo. The system exhibited comparable failure modes resulting in harm to affected stakeholders.",
    "date": "2024-12-17",
    "aiSystem": {
      "@type": "oecd:AISystem",
      "name": "Smart System",
      "version": "3.6",
      "relation": [
        "oecd:DirectCause"
      ]
    },
    "developer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/Glovo",
      "name": "Glovo"
    },
    "deployer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/Glovo",
      "name": "Glovo"
    },
    "severity": "oecd:SeriousIncident",
    "harmType": [
      "oecd:OtherHarm"
    ],
    "harmQuantification": {
      "@type": "oecd:HarmQuantification",
      "affected_stakeholders": "45220 individuals"
    },
    "countries": [
      {
        "@type": "core:Country",
        "@id": "https://www.wikidata.org/wiki/China",
        "name": "China"
      },
      {
        "@type": "core:Country",
        "@id": "https://www.wikidata.org/wiki/United_States",
        "name": "United States"
      }
    ],
    "affectedStakeholders": [
      {
        "@type": "core:Person",
        "@id": "https://example.org/entities/person/sebastian-galassi-s-family",
        "name": "Sebastian Galassi's family"
      },
      {
        "@type": "core:Person",
        "@id": "https://example.org/entities/person/sebastian-galassi",
        "name": "Sebastian Galassi"
      }
    ],
    "businessFunction": [
      "oecd:HRManagement"
    ],
    "submitter": {
      "@type": "oecd:Submitter",
      "@id": "https://example.org/submitter/submitter",
      "role": "Ethics Officer",
      "affiliation": "AI Safety Institute",
      "stakeholderGroup": "I work or am affiliated to a public interest body or NGO",
      "relationToIncident": "I am an affected stakeholder"
    },
    "unintendedUse": true,
    "sameAs": "https://incidentdatabase.ai/cite/384"
  },
  {
    "@context": [
      "http://localhost:3000/api/schemas/v1/core/context.jsonld",
      "http://localhost:3001/api/schemas/v1/oecd/context.jsonld"
    ],
    "@type": "oecd:Incident",
    "@id": "https://oecd.ai/incident/OECD-2024-226",
    "incident_id": "OECD-2024-226",
    "title": "AI System Failure Related to Deepfake of Kamala Harris Saying Damaging Comments Circulates on X and Is Amplified by Elon Musk",
    "description": "An AI system failure occurred with similar characteristics to the documented incident involving X (Twitter). The system exhibited comparable failure modes resulting in harm to affected stakeholders.",
    "date": "2024-12-23",
    "aiSystem": {
      "@type": "oecd:AISystem",
      "name": "Intelligent System",
      "version": "1.6",
      "relation": [
        "oecd:DirectCause"
      ]
    },
    "developer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/X_(Twitter)",
      "name": "X (Twitter)"
    },
    "deployer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/X_(Twitter)",
      "name": "X (Twitter)"
    },
    "severity": "oecd:SeriousIncident",
    "harmType": [
      "oecd:OtherHarm"
    ],
    "harmQuantification": {
      "@type": "oecd:HarmQuantification",
      "affected_stakeholders": "10636 individuals"
    },
    "countries": [
      {
        "@type": "core:Country",
        "@id": "https://www.wikidata.org/wiki/Germany",
        "name": "Germany"
      },
      {
        "@type": "core:Country",
        "@id": "https://www.wikidata.org/wiki/Japan",
        "name": "Japan"
      }
    ],
    "affectedStakeholders": [
      {
        "@type": "core:Person",
        "@id": "https://example.org/entities/person/truth",
        "name": "Truth"
      },
      {
        "@type": "core:Person",
        "@id": "https://example.org/entities/person/kamala-harris",
        "name": "Kamala Harris"
      },
      {
        "@type": "core:Person",
        "@id": "https://example.org/entities/person/joe-biden",
        "name": "Joe Biden"
      },
      {
        "@type": "oecd:StakeholderGroup",
        "@id": "https://example.org/stakeholder-group/general-public",
        "name": "General public"
      },
      {
        "@type": "core:Person",
        "@id": "https://example.org/entities/person/american-voters",
        "name": "American voters"
      }
    ],
    "businessFunction": [
      "oecd:HRManagement",
      "oecd:Sales"
    ],
    "submitter": {
      "@type": "oecd:Submitter",
      "@id": "https://example.org/submitter/submitter",
      "role": "AI Safety Researcher",
      "affiliation": "Digital Rights Foundation",
      "stakeholderGroup": "I represent a government or regulatory body",
      "relationToIncident": "None of the above, but have partial or substantial knowledge of the incident (e.g. first-hand knowledge, research etc.)"
    },
    "unintendedUse": true,
    "sameAs": "https://incidentdatabase.ai/cite/756"
  },
  {
    "@context": [
      "http://localhost:3000/api/schemas/v1/core/context.jsonld",
      "http://localhost:3001/api/schemas/v1/oecd/context.jsonld"
    ],
    "@type": "oecd:Incident",
    "@id": "https://oecd.ai/incident/OECD-2024-227",
    "incident_id": "OECD-2024-227",
    "title": "AI System Failure Related to Starship’s Autonomous Food Delivery Robot Allegedly Stranded at Railroad Crossing in Oregon, Run over by Freight Train",
    "description": "An AI system failure occurred with similar characteristics to the documented incident involving Oregon State University. The system exhibited comparable failure modes resulting in harm to affected stakeholders.",
    "date": "2024-12-27",
    "aiSystem": {
      "@type": "oecd:AISystem",
      "name": "Smart Solution",
      "version": "1.8",
      "relation": [
        "oecd:DirectCause"
      ]
    },
    "developer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/Oregon_State_University",
      "name": "Oregon State University"
    },
    "deployer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/Oregon_State_University",
      "name": "Oregon State University"
    },
    "severity": "oecd:SeriousIncident",
    "harmType": [
      "oecd:OtherHarm"
    ],
    "harmQuantification": {
      "@type": "oecd:HarmQuantification",
      "affected_stakeholders": "4668 individuals",
      "economic_losses": "$1 million"
    },
    "countries": [
      {
        "@type": "core:Country",
        "@id": "https://www.wikidata.org/wiki/China",
        "name": "China"
      }
    ],
    "affectedStakeholders": [
      {
        "@type": "core:Person",
        "@id": "https://example.org/entities/person/oregon-state-university",
        "name": "Oregon State University"
      },
      {
        "@type": "core:Person",
        "@id": "https://example.org/entities/person/freight-train-crew",
        "name": "freight train crew"
      }
    ],
    "businessFunction": [
      "oecd:HRManagement"
    ],
    "submitter": {
      "@type": "oecd:Submitter",
      "@id": "https://example.org/submitter/submitter",
      "role": "Academic Researcher",
      "affiliation": "University Research Lab",
      "stakeholderGroup": "I work or am affiliated to a public interest body or NGO",
      "relationToIncident": "None of the above, but have partial or substantial knowledge of the incident (e.g. first-hand knowledge, research etc.)"
    },
    "unintendedUse": false,
    "sameAs": "https://incidentdatabase.ai/cite/176"
  },
  {
    "@context": [
      "http://localhost:3000/api/schemas/v1/core/context.jsonld",
      "http://localhost:3001/api/schemas/v1/oecd/context.jsonld"
    ],
    "@type": "oecd:Incident",
    "@id": "https://oecd.ai/incident/OECD-2025-228",
    "incident_id": "OECD-2025-228",
    "title": "AI System Failure Related to British Female Politicians Victimized by Deepfake Pornography",
    "description": "An AI system failure occurred with similar characteristics to the documented incident involving Unknown deepfake creators. The system exhibited comparable failure modes resulting in harm to affected stakeholders.",
    "date": "2025-01-23",
    "aiSystem": {
      "@type": "oecd:AISystem",
      "name": "Automated Platform",
      "version": "3.6",
      "relation": [
        "oecd:DirectCause"
      ]
    },
    "developer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/Unknown_deepfake_creators",
      "name": "Unknown deepfake creators"
    },
    "deployer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/Unknown_deepfake_creators",
      "name": "Unknown deepfake creators"
    },
    "severity": "oecd:SeriousIncident",
    "harmType": [
      "oecd:OtherHarm"
    ],
    "harmQuantification": {
      "@type": "oecd:HarmQuantification",
      "affected_stakeholders": "27655 individuals"
    },
    "countries": [
      {
        "@type": "core:Country",
        "@id": "https://www.wikidata.org/wiki/Mexico",
        "name": "Mexico"
      }
    ],
    "affectedStakeholders": [
      {
        "@type": "core:Person",
        "@id": "https://example.org/entities/person/stella-creasy",
        "name": "Stella Creasy"
      },
      {
        "@type": "core:Person",
        "@id": "https://example.org/entities/person/priti-patel",
        "name": "Priti Patel"
      },
      {
        "@type": "core:Person",
        "@id": "https://example.org/entities/person/penny-mordaunt",
        "name": "Penny Mordaunt"
      },
      {
        "@type": "core:Person",
        "@id": "https://example.org/entities/person/gillian-keegan",
        "name": "Gillian Keegan"
      },
      {
        "@type": "core:Person",
        "@id": "https://example.org/entities/person/dehenna-davison",
        "name": "Dehenna Davison"
      },
      {
        "@type": "core:Person",
        "@id": "https://example.org/entities/person/angela-rayner",
        "name": "Angela Rayner"
      }
    ],
    "businessFunction": [
      "oecd:QualityControl"
    ],
    "submitter": {
      "@type": "oecd:Submitter",
      "@id": "https://example.org/submitter/submitter",
      "role": "AI Safety Researcher",
      "affiliation": "AI Safety Institute",
      "stakeholderGroup": "I work or am affiliated to a public interest body or NGO",
      "relationToIncident": "I am an affected stakeholder"
    },
    "unintendedUse": false,
    "sameAs": "https://incidentdatabase.ai/cite/754"
  },
  {
    "@context": [
      "http://localhost:3000/api/schemas/v1/core/context.jsonld",
      "http://localhost:3001/api/schemas/v1/oecd/context.jsonld"
    ],
    "@type": "oecd:Incident",
    "@id": "https://oecd.ai/incident/OECD-2025-229",
    "incident_id": "OECD-2025-229",
    "title": "AI System Failure Related to Class Action Lawsuit Over Alleged Defects in Volkswagen's AI-Driven AEB Systems",
    "description": "An AI system failure occurred with similar characteristics to the documented incident involving Volkswagen Group of America. The system exhibited comparable failure modes resulting in harm to affected stakeholders.",
    "date": "2025-03-21",
    "aiSystem": {
      "@type": "oecd:AISystem",
      "name": "AI Engine",
      "version": "4.4",
      "relation": [
        "oecd:DirectCause"
      ]
    },
    "developer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/Volkswagen_Group_of_America",
      "name": "Volkswagen Group of America"
    },
    "deployer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/Volkswagen_Group_of_America",
      "name": "Volkswagen Group of America"
    },
    "severity": "oecd:SeriousIncident",
    "harmType": [
      "oecd:OtherHarm"
    ],
    "harmQuantification": {
      "@type": "oecd:HarmQuantification",
      "affected_stakeholders": "38477 individuals"
    },
    "countries": [
      {
        "@type": "core:Country",
        "@id": "https://www.wikidata.org/wiki/Netherlands",
        "name": "Netherlands"
      },
      {
        "@type": "core:Country",
        "@id": "https://www.wikidata.org/wiki/Japan",
        "name": "Japan"
      },
      {
        "@type": "core:Country",
        "@id": "https://www.wikidata.org/wiki/Brazil",
        "name": "Brazil"
      }
    ],
    "affectedStakeholders": [
      {
        "@type": "core:Person",
        "@id": "https://example.org/entities/person/volkswagen-drivers",
        "name": "Volkswagen drivers"
      },
      {
        "@type": "oecd:StakeholderGroup",
        "@id": "https://example.org/stakeholder-group/potential-passengers-and-road-users-at-risk-due-to-malfunctioning-aeb-systems",
        "name": "Potential passengers and road users at risk due to malfunctioning AEB systems"
      }
    ],
    "businessFunction": [
      "oecd:Marketing"
    ],
    "submitter": {
      "@type": "oecd:Submitter",
      "@id": "https://example.org/submitter/submitter",
      "role": "Ethics Officer",
      "affiliation": "AI Safety Institute",
      "stakeholderGroup": "None of the above, but have partial or substantial knowledge of the incident",
      "relationToIncident": "None of the above, but have partial or substantial knowledge of the incident (e.g. first-hand knowledge, research etc.)"
    },
    "unintendedUse": true,
    "sameAs": "https://incidentdatabase.ai/cite/746"
  },
  {
    "@context": [
      "http://localhost:3000/api/schemas/v1/core/context.jsonld",
      "http://localhost:3001/api/schemas/v1/oecd/context.jsonld"
    ],
    "@type": "oecd:Incident",
    "@id": "https://oecd.ai/incident/OECD-2025-230",
    "incident_id": "OECD-2025-230",
    "title": "AI System Failure Related to Bankrate's Resumption of AI-Generated Content Allegedly Continuing to Produce Inaccurate and Misleading Information",
    "description": "An AI system failure occurred with similar characteristics to the documented incident involving Red Ventures. The system exhibited comparable failure modes resulting in harm to affected stakeholders.",
    "date": "2025-04-19",
    "aiSystem": {
      "@type": "oecd:AISystem",
      "name": "Smart System",
      "version": "5.5",
      "relation": [
        "oecd:DirectCause"
      ]
    },
    "developer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/Red_Ventures",
      "name": "Red Ventures"
    },
    "deployer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/Red_Ventures",
      "name": "Red Ventures"
    },
    "severity": "oecd:SeriousIncident",
    "harmType": [
      "oecd:OtherHarm"
    ],
    "harmQuantification": {
      "@type": "oecd:HarmQuantification",
      "affected_stakeholders": "47290 individuals"
    },
    "countries": [
      {
        "@type": "core:Country",
        "@id": "https://www.wikidata.org/wiki/Singapore",
        "name": "Singapore"
      },
      {
        "@type": "core:Country",
        "@id": "https://www.wikidata.org/wiki/China",
        "name": "China"
      }
    ],
    "affectedStakeholders": [
      {
        "@type": "core:Person",
        "@id": "https://example.org/entities/person/journalistic-integrity",
        "name": "Journalistic integrity"
      },
      {
        "@type": "oecd:StakeholderGroup",
        "@id": "https://example.org/stakeholder-group/general-public",
        "name": "General public"
      }
    ],
    "businessFunction": [
      "oecd:ResearchDevelopment"
    ],
    "submitter": {
      "@type": "oecd:Submitter",
      "@id": "https://example.org/submitter/submitter",
      "role": "Academic Researcher",
      "affiliation": "Government Oversight Committee",
      "stakeholderGroup": "I represent a government or regulatory body",
      "relationToIncident": "None of the above, but have partial or substantial knowledge of the incident (e.g. first-hand knowledge, research etc.)"
    },
    "unintendedUse": false,
    "sameAs": "https://incidentdatabase.ai/cite/577"
  },
  {
    "@context": [
      "http://localhost:3000/api/schemas/v1/core/context.jsonld",
      "http://localhost:3001/api/schemas/v1/oecd/context.jsonld"
    ],
    "@type": "oecd:Incident",
    "@id": "https://oecd.ai/incident/OECD-2025-231",
    "incident_id": "OECD-2025-231",
    "title": "AI System Failure Related to Female Celebrities' Faces Shown in Sexually Suggestive Ads for Deepfake App",
    "description": "An AI system failure occurred with similar characteristics to the documented incident involving Facemega. The system exhibited comparable failure modes resulting in harm to affected stakeholders.",
    "date": "2025-04-23",
    "aiSystem": {
      "@type": "oecd:AISystem",
      "name": "Smart System",
      "version": "1.5",
      "relation": [
        "oecd:DirectCause"
      ]
    },
    "developer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/Facemega",
      "name": "Facemega"
    },
    "deployer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/Facemega",
      "name": "Facemega"
    },
    "severity": "oecd:SeriousIncident",
    "harmType": [
      "oecd:OtherHarm"
    ],
    "harmQuantification": {
      "@type": "oecd:HarmQuantification",
      "affected_stakeholders": "45616 individuals"
    },
    "countries": [
      {
        "@type": "core:Country",
        "@id": "https://www.wikidata.org/wiki/Sweden",
        "name": "Sweden"
      },
      {
        "@type": "core:Country",
        "@id": "https://www.wikidata.org/wiki/Mexico",
        "name": "Mexico"
      },
      {
        "@type": "core:Country",
        "@id": "https://www.wikidata.org/wiki/Japan",
        "name": "Japan"
      }
    ],
    "affectedStakeholders": [
      {
        "@type": "core:Person",
        "@id": "https://example.org/entities/person/scarlett-johansson",
        "name": "Scarlett Johansson"
      },
      {
        "@type": "core:Person",
        "@id": "https://example.org/entities/person/female-celebrities",
        "name": "female celebrities"
      },
      {
        "@type": "core:Person",
        "@id": "https://example.org/entities/person/emma-watson",
        "name": "Emma Watson"
      }
    ],
    "businessFunction": [
      "oecd:Production",
      "oecd:HRManagement"
    ],
    "submitter": {
      "@type": "oecd:Submitter",
      "@id": "https://example.org/submitter/submitter",
      "role": "AI Safety Researcher",
      "affiliation": "Tech Policy Center",
      "stakeholderGroup": "I represent a government or regulatory body",
      "relationToIncident": "None of the above, but have partial or substantial knowledge of the incident (e.g. first-hand knowledge, research etc.)"
    },
    "unintendedUse": false,
    "sameAs": "https://incidentdatabase.ai/cite/494"
  },
  {
    "@context": [
      "http://localhost:3000/api/schemas/v1/core/context.jsonld",
      "http://localhost:3001/api/schemas/v1/oecd/context.jsonld"
    ],
    "@type": "oecd:Incident",
    "@id": "https://oecd.ai/incident/OECD-2025-232",
    "incident_id": "OECD-2025-232",
    "title": "AI System Failure Related to Female Celebrities' Faces Shown in Sexually Suggestive Ads for Deepfake App",
    "description": "An AI system failure occurred with similar characteristics to the documented incident involving Facemega. The system exhibited comparable failure modes resulting in harm to affected stakeholders.",
    "date": "2025-05-26",
    "aiSystem": {
      "@type": "oecd:AISystem",
      "name": "Smart Solution",
      "version": "2.7",
      "relation": [
        "oecd:DirectCause"
      ]
    },
    "developer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/Facemega",
      "name": "Facemega"
    },
    "deployer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/Facemega",
      "name": "Facemega"
    },
    "severity": "oecd:SeriousIncident",
    "harmType": [
      "oecd:OtherHarm"
    ],
    "harmQuantification": {
      "@type": "oecd:HarmQuantification",
      "affected_stakeholders": "6164 individuals"
    },
    "countries": [
      {
        "@type": "core:Country",
        "@id": "https://www.wikidata.org/wiki/United_Kingdom",
        "name": "United Kingdom"
      }
    ],
    "affectedStakeholders": [
      {
        "@type": "core:Person",
        "@id": "https://example.org/entities/person/scarlett-johansson",
        "name": "Scarlett Johansson"
      },
      {
        "@type": "core:Person",
        "@id": "https://example.org/entities/person/female-celebrities",
        "name": "female celebrities"
      },
      {
        "@type": "core:Person",
        "@id": "https://example.org/entities/person/emma-watson",
        "name": "Emma Watson"
      }
    ],
    "businessFunction": [
      "oecd:ResearchDevelopment"
    ],
    "submitter": {
      "@type": "oecd:Submitter",
      "@id": "https://example.org/submitter/submitter",
      "role": "Government Inspector",
      "affiliation": "AI Safety Institute",
      "stakeholderGroup": "None of the above, but have partial or substantial knowledge of the incident",
      "relationToIncident": "None of the above, but have partial or substantial knowledge of the incident (e.g. first-hand knowledge, research etc.)"
    },
    "unintendedUse": false,
    "sameAs": "https://incidentdatabase.ai/cite/494"
  },
  {
    "@context": [
      "http://localhost:3000/api/schemas/v1/core/context.jsonld",
      "http://localhost:3001/api/schemas/v1/oecd/context.jsonld"
    ],
    "@type": "oecd:Incident",
    "@id": "https://oecd.ai/incident/OECD-2025-233",
    "incident_id": "OECD-2025-233",
    "title": "AI System Failure Related to Class Action Lawsuit Over Alleged Defects in Volkswagen's AI-Driven AEB Systems",
    "description": "An AI system failure occurred with similar characteristics to the documented incident involving Volkswagen Group of America. The system exhibited comparable failure modes resulting in harm to affected stakeholders.",
    "date": "2025-05-29",
    "aiSystem": {
      "@type": "oecd:AISystem",
      "name": "Automated Solution",
      "version": "2.0",
      "relation": [
        "oecd:DirectCause"
      ]
    },
    "developer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/Volkswagen_Group_of_America",
      "name": "Volkswagen Group of America"
    },
    "deployer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/Volkswagen_Group_of_America",
      "name": "Volkswagen Group of America"
    },
    "severity": "oecd:SeriousIncident",
    "harmType": [
      "oecd:OtherHarm"
    ],
    "harmQuantification": {
      "@type": "oecd:HarmQuantification",
      "affected_stakeholders": "40484 individuals",
      "economic_losses": "$2 million"
    },
    "countries": [
      {
        "@type": "core:Country",
        "@id": "https://www.wikidata.org/wiki/Canada",
        "name": "Canada"
      },
      {
        "@type": "core:Country",
        "@id": "https://www.wikidata.org/wiki/Japan",
        "name": "Japan"
      }
    ],
    "affectedStakeholders": [
      {
        "@type": "core:Person",
        "@id": "https://example.org/entities/person/volkswagen-drivers",
        "name": "Volkswagen drivers"
      },
      {
        "@type": "oecd:StakeholderGroup",
        "@id": "https://example.org/stakeholder-group/potential-passengers-and-road-users-at-risk-due-to-malfunctioning-aeb-systems",
        "name": "Potential passengers and road users at risk due to malfunctioning AEB systems"
      }
    ],
    "businessFunction": [
      "oecd:ICTManagement"
    ],
    "submitter": {
      "@type": "oecd:Submitter",
      "@id": "https://example.org/submitter/submitter",
      "role": "Industry Analyst",
      "affiliation": "Tech Policy Center",
      "stakeholderGroup": "None of the above, but have partial or substantial knowledge of the incident",
      "relationToIncident": "None of the above, but have partial or substantial knowledge of the incident (e.g. first-hand knowledge, research etc.)"
    },
    "unintendedUse": false,
    "sameAs": "https://incidentdatabase.ai/cite/746"
  },
  {
    "@context": [
      "http://localhost:3000/api/schemas/v1/core/context.jsonld",
      "http://localhost:3001/api/schemas/v1/oecd/context.jsonld"
    ],
    "@type": "oecd:Incident",
    "@id": "https://oecd.ai/incident/OECD-2025-234",
    "incident_id": "OECD-2025-234",
    "title": "AI System Failure Related to AI-Generated Fake Audio of Verbal Abuse Incident Circulates of British Labour Leader Keir Starmer",
    "description": "An AI system failure occurred with similar characteristics to the documented incident involving unknown. The system exhibited comparable failure modes resulting in harm to affected stakeholders.",
    "date": "2025-07-25",
    "aiSystem": {
      "@type": "oecd:AISystem",
      "name": "AI Solution",
      "version": "4.2",
      "relation": [
        "oecd:DirectCause"
      ]
    },
    "developer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/unknown",
      "name": "unknown"
    },
    "deployer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/unknown",
      "name": "unknown"
    },
    "severity": "oecd:SeriousIncident",
    "harmType": [
      "oecd:OtherHarm"
    ],
    "harmQuantification": {
      "@type": "oecd:HarmQuantification",
      "affected_stakeholders": "3172 individuals",
      "economic_losses": "$3 million"
    },
    "countries": [
      {
        "@type": "core:Country",
        "@id": "https://www.wikidata.org/wiki/South_Korea",
        "name": "South Korea"
      }
    ],
    "affectedStakeholders": [
      {
        "@type": "core:Person",
        "@id": "https://example.org/entities/person/uk-labour-party",
        "name": "UK Labour Party"
      },
      {
        "@type": "core:Person",
        "@id": "https://example.org/entities/person/keir-starmer",
        "name": "Keir Starmer"
      }
    ],
    "businessFunction": [
      "oecd:QualityControl",
      "oecd:Logistics"
    ],
    "submitter": {
      "@type": "oecd:Submitter",
      "@id": "https://example.org/submitter/submitter",
      "role": "Journalist",
      "affiliation": "AI Safety Institute",
      "stakeholderGroup": "I represent a government or regulatory body",
      "relationToIncident": "None of the above, but have partial or substantial knowledge of the incident (e.g. first-hand knowledge, research etc.)"
    },
    "unintendedUse": false,
    "sameAs": "https://incidentdatabase.ai/cite/601"
  },
  {
    "@context": [
      "http://localhost:3000/api/schemas/v1/core/context.jsonld",
      "http://localhost:3001/api/schemas/v1/oecd/context.jsonld"
    ],
    "@type": "oecd:Incident",
    "@id": "https://oecd.ai/incident/OECD-2025-235",
    "incident_id": "OECD-2025-235",
    "title": "AI System Failure Related to AI-Generated Fake Audio of Verbal Abuse Incident Circulates of British Labour Leader Keir Starmer",
    "description": "An AI system failure occurred with similar characteristics to the documented incident involving unknown. The system exhibited comparable failure modes resulting in harm to affected stakeholders.",
    "date": "2025-08-22",
    "aiSystem": {
      "@type": "oecd:AISystem",
      "name": "Intelligent System",
      "version": "3.9",
      "relation": [
        "oecd:DirectCause"
      ]
    },
    "developer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/unknown",
      "name": "unknown"
    },
    "deployer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/unknown",
      "name": "unknown"
    },
    "severity": "oecd:SeriousIncident",
    "harmType": [
      "oecd:OtherHarm"
    ],
    "harmQuantification": {
      "@type": "oecd:HarmQuantification",
      "affected_stakeholders": "13940 individuals",
      "economic_losses": "$4 million"
    },
    "countries": [
      {
        "@type": "core:Country",
        "@id": "https://www.wikidata.org/wiki/United_States",
        "name": "United States"
      },
      {
        "@type": "core:Country",
        "@id": "https://www.wikidata.org/wiki/United_Kingdom",
        "name": "United Kingdom"
      },
      {
        "@type": "core:Country",
        "@id": "https://www.wikidata.org/wiki/India",
        "name": "India"
      }
    ],
    "affectedStakeholders": [
      {
        "@type": "core:Person",
        "@id": "https://example.org/entities/person/uk-labour-party",
        "name": "UK Labour Party"
      },
      {
        "@type": "core:Person",
        "@id": "https://example.org/entities/person/keir-starmer",
        "name": "Keir Starmer"
      }
    ],
    "businessFunction": [
      "oecd:Sales",
      "oecd:Maintenance"
    ],
    "submitter": {
      "@type": "oecd:Submitter",
      "@id": "https://example.org/submitter/submitter",
      "role": "Academic Researcher",
      "affiliation": "Digital Rights Foundation",
      "stakeholderGroup": "I represent a government or regulatory body",
      "relationToIncident": "I am a user of the related AI system"
    },
    "unintendedUse": false,
    "sameAs": "https://incidentdatabase.ai/cite/601"
  },
  {
    "@context": [
      "http://localhost:3000/api/schemas/v1/core/context.jsonld",
      "http://localhost:3001/api/schemas/v1/oecd/context.jsonld"
    ],
    "@type": "oecd:Incident",
    "@id": "https://oecd.ai/incident/OECD-2025-236",
    "incident_id": "OECD-2025-236",
    "title": "AI System Failure Related to Bankrate's Resumption of AI-Generated Content Allegedly Continuing to Produce Inaccurate and Misleading Information",
    "description": "An AI system failure occurred with similar characteristics to the documented incident involving Red Ventures. The system exhibited comparable failure modes resulting in harm to affected stakeholders.",
    "date": "2025-09-27",
    "aiSystem": {
      "@type": "oecd:AISystem",
      "name": "Intelligent Platform",
      "version": "3.4",
      "relation": [
        "oecd:DirectCause"
      ]
    },
    "developer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/Red_Ventures",
      "name": "Red Ventures"
    },
    "deployer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/Red_Ventures",
      "name": "Red Ventures"
    },
    "severity": "oecd:SeriousIncident",
    "harmType": [
      "oecd:OtherHarm"
    ],
    "harmQuantification": {
      "@type": "oecd:HarmQuantification",
      "affected_stakeholders": "45336 individuals",
      "economic_losses": "$7 million"
    },
    "countries": [
      {
        "@type": "core:Country",
        "@id": "https://www.wikidata.org/wiki/Italy",
        "name": "Italy"
      }
    ],
    "affectedStakeholders": [
      {
        "@type": "core:Person",
        "@id": "https://example.org/entities/person/journalistic-integrity",
        "name": "Journalistic integrity"
      },
      {
        "@type": "oecd:StakeholderGroup",
        "@id": "https://example.org/stakeholder-group/general-public",
        "name": "General public"
      }
    ],
    "businessFunction": [
      "oecd:Logistics",
      "oecd:CustomerService"
    ],
    "submitter": {
      "@type": "oecd:Submitter",
      "@id": "https://example.org/submitter/submitter",
      "role": "Government Inspector",
      "affiliation": "AI Safety Institute",
      "stakeholderGroup": "None of the above, but have partial or substantial knowledge of the incident",
      "relationToIncident": "None of the above, but have partial or substantial knowledge of the incident (e.g. first-hand knowledge, research etc.)"
    },
    "unintendedUse": true,
    "sameAs": "https://incidentdatabase.ai/cite/577"
  },
  {
    "@context": [
      "http://localhost:3000/api/schemas/v1/core/context.jsonld",
      "http://localhost:3001/api/schemas/v1/oecd/context.jsonld"
    ],
    "@type": "oecd:Incident",
    "@id": "https://oecd.ai/incident/OECD-2025-237",
    "incident_id": "OECD-2025-237",
    "title": "AI System Failure Related to AI Chatbots Reportedly Inaccurately Conveyed Real-Time Political News",
    "description": "An AI system failure occurred with similar characteristics to the documented incident involving Perplexity. The system exhibited comparable failure modes resulting in harm to affected stakeholders.",
    "date": "2025-10-10",
    "aiSystem": {
      "@type": "oecd:AISystem",
      "name": "Automated System",
      "version": "5.2",
      "relation": [
        "oecd:DirectCause"
      ]
    },
    "developer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/Perplexity",
      "name": "Perplexity"
    },
    "deployer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/Perplexity",
      "name": "Perplexity"
    },
    "severity": "oecd:SeriousIncident",
    "harmType": [
      "oecd:OtherHarm"
    ],
    "harmQuantification": {
      "@type": "oecd:HarmQuantification",
      "affected_stakeholders": "24992 individuals"
    },
    "countries": [
      {
        "@type": "core:Country",
        "@id": "https://www.wikidata.org/wiki/South_Korea",
        "name": "South Korea"
      }
    ],
    "affectedStakeholders": [
      {
        "@type": "core:Person",
        "@id": "https://example.org/entities/person/journalism",
        "name": "Journalism"
      },
      {
        "@type": "oecd:StakeholderGroup",
        "@id": "https://example.org/stakeholder-group/general-public",
        "name": "General public"
      },
      {
        "@type": "oecd:StakeholderGroup",
        "@id": "https://example.org/stakeholder-group/chatbot-users",
        "name": "Chatbot users"
      }
    ],
    "businessFunction": [
      "oecd:Accounting",
      "oecd:Sales"
    ],
    "submitter": {
      "@type": "oecd:Submitter",
      "@id": "https://example.org/submitter/submitter",
      "role": "Government Inspector",
      "affiliation": "University Research Lab",
      "stakeholderGroup": "None of the above, but have partial or substantial knowledge of the incident",
      "relationToIncident": "None of the above, but have partial or substantial knowledge of the incident (e.g. first-hand knowledge, research etc.)"
    },
    "unintendedUse": true,
    "sameAs": "https://incidentdatabase.ai/cite/750"
  },
  {
    "@context": [
      "http://localhost:3000/api/schemas/v1/core/context.jsonld",
      "http://localhost:3001/api/schemas/v1/oecd/context.jsonld"
    ],
    "@type": "oecd:Incident",
    "@id": "https://oecd.ai/incident/OECD-2025-238",
    "incident_id": "OECD-2025-238",
    "title": "AI System Failure Related to AI-Generated Fake Audio of Verbal Abuse Incident Circulates of British Labour Leader Keir Starmer",
    "description": "An AI system failure occurred with similar characteristics to the documented incident involving unknown. The system exhibited comparable failure modes resulting in harm to affected stakeholders.",
    "date": "2025-11-28",
    "aiSystem": {
      "@type": "oecd:AISystem",
      "name": "Intelligent System",
      "version": "3.2",
      "relation": [
        "oecd:DirectCause"
      ]
    },
    "developer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/unknown",
      "name": "unknown"
    },
    "deployer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/unknown",
      "name": "unknown"
    },
    "severity": "oecd:SeriousIncident",
    "harmType": [
      "oecd:OtherHarm"
    ],
    "harmQuantification": {
      "@type": "oecd:HarmQuantification",
      "affected_stakeholders": "17797 individuals"
    },
    "countries": [
      {
        "@type": "core:Country",
        "@id": "https://www.wikidata.org/wiki/Spain",
        "name": "Spain"
      },
      {
        "@type": "core:Country",
        "@id": "https://www.wikidata.org/wiki/Japan",
        "name": "Japan"
      }
    ],
    "affectedStakeholders": [
      {
        "@type": "core:Person",
        "@id": "https://example.org/entities/person/uk-labour-party",
        "name": "UK Labour Party"
      },
      {
        "@type": "core:Person",
        "@id": "https://example.org/entities/person/keir-starmer",
        "name": "Keir Starmer"
      }
    ],
    "businessFunction": [
      "oecd:ResearchDevelopment",
      "oecd:Sales"
    ],
    "submitter": {
      "@type": "oecd:Submitter",
      "@id": "https://example.org/submitter/submitter",
      "role": "Ethics Officer",
      "affiliation": "AI Safety Institute",
      "stakeholderGroup": "I represent a government or regulatory body",
      "relationToIncident": "I am an affected stakeholder"
    },
    "unintendedUse": false,
    "sameAs": "https://incidentdatabase.ai/cite/601"
  },
  {
    "@context": [
      "http://localhost:3000/api/schemas/v1/core/context.jsonld",
      "http://localhost:3001/api/schemas/v1/oecd/context.jsonld"
    ],
    "@type": "oecd:Incident",
    "@id": "https://oecd.ai/incident/OECD-2025-239",
    "incident_id": "OECD-2025-239",
    "title": "AI System Failure Related to Bankrate's Resumption of AI-Generated Content Allegedly Continuing to Produce Inaccurate and Misleading Information",
    "description": "An AI system failure occurred with similar characteristics to the documented incident involving Red Ventures. The system exhibited comparable failure modes resulting in harm to affected stakeholders.",
    "date": "2025-12-11",
    "aiSystem": {
      "@type": "oecd:AISystem",
      "name": "AI System",
      "version": "5.4",
      "relation": [
        "oecd:DirectCause"
      ]
    },
    "developer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/Red_Ventures",
      "name": "Red Ventures"
    },
    "deployer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/Red_Ventures",
      "name": "Red Ventures"
    },
    "severity": "oecd:SeriousIncident",
    "harmType": [
      "oecd:OtherHarm"
    ],
    "harmQuantification": {
      "@type": "oecd:HarmQuantification",
      "affected_stakeholders": "16345 individuals"
    },
    "countries": [
      {
        "@type": "core:Country",
        "@id": "https://www.wikidata.org/wiki/Germany",
        "name": "Germany"
      },
      {
        "@type": "core:Country",
        "@id": "https://www.wikidata.org/wiki/Mexico",
        "name": "Mexico"
      }
    ],
    "affectedStakeholders": [
      {
        "@type": "core:Person",
        "@id": "https://example.org/entities/person/journalistic-integrity",
        "name": "Journalistic integrity"
      },
      {
        "@type": "oecd:StakeholderGroup",
        "@id": "https://example.org/stakeholder-group/general-public",
        "name": "General public"
      }
    ],
    "businessFunction": [
      "oecd:ResearchDevelopment",
      "oecd:Marketing"
    ],
    "submitter": {
      "@type": "oecd:Submitter",
      "@id": "https://example.org/submitter/submitter",
      "role": "Industry Analyst",
      "affiliation": "AI Safety Institute",
      "stakeholderGroup": "I represent a government or regulatory body",
      "relationToIncident": "None of the above, but have partial or substantial knowledge of the incident (e.g. first-hand knowledge, research etc.)"
    },
    "unintendedUse": false,
    "sameAs": "https://incidentdatabase.ai/cite/577"
  },
  {
    "@context": [
      "http://localhost:3000/api/schemas/v1/core/context.jsonld",
      "http://localhost:3001/api/schemas/v1/oecd/context.jsonld"
    ],
    "@type": "oecd:Incident",
    "@id": "https://oecd.ai/incident/OECD-2025-240",
    "incident_id": "OECD-2025-240",
    "title": "AI System Failure Related to Deepfake of Kamala Harris Saying Damaging Comments Circulates on X and Is Amplified by Elon Musk",
    "description": "An AI system failure occurred with similar characteristics to the documented incident involving X (Twitter). The system exhibited comparable failure modes resulting in harm to affected stakeholders.",
    "date": "2025-12-30",
    "aiSystem": {
      "@type": "oecd:AISystem",
      "name": "AI Solution",
      "version": "1.3",
      "relation": [
        "oecd:DirectCause"
      ]
    },
    "developer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/X_(Twitter)",
      "name": "X (Twitter)"
    },
    "deployer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/X_(Twitter)",
      "name": "X (Twitter)"
    },
    "severity": "oecd:SeriousIncident",
    "harmType": [
      "oecd:OtherHarm"
    ],
    "harmQuantification": {
      "@type": "oecd:HarmQuantification",
      "affected_stakeholders": "25075 individuals"
    },
    "countries": [
      {
        "@type": "core:Country",
        "@id": "https://www.wikidata.org/wiki/Spain",
        "name": "Spain"
      }
    ],
    "affectedStakeholders": [
      {
        "@type": "core:Person",
        "@id": "https://example.org/entities/person/truth",
        "name": "Truth"
      },
      {
        "@type": "core:Person",
        "@id": "https://example.org/entities/person/kamala-harris",
        "name": "Kamala Harris"
      },
      {
        "@type": "core:Person",
        "@id": "https://example.org/entities/person/joe-biden",
        "name": "Joe Biden"
      },
      {
        "@type": "oecd:StakeholderGroup",
        "@id": "https://example.org/stakeholder-group/general-public",
        "name": "General public"
      },
      {
        "@type": "core:Person",
        "@id": "https://example.org/entities/person/american-voters",
        "name": "American voters"
      }
    ],
    "businessFunction": [
      "oecd:Planning"
    ],
    "submitter": {
      "@type": "oecd:Submitter",
      "@id": "https://example.org/submitter/submitter",
      "role": "AI Safety Researcher",
      "affiliation": "University Research Lab",
      "stakeholderGroup": "None of the above, but have partial or substantial knowledge of the incident",
      "relationToIncident": "I am an affected stakeholder"
    },
    "unintendedUse": false,
    "sameAs": "https://incidentdatabase.ai/cite/756"
  },
  {
    "@context": [
      "http://localhost:3000/api/schemas/v1/core/context.jsonld",
      "http://localhost:3001/api/schemas/v1/oecd/context.jsonld"
    ],
    "@type": "oecd:Incident",
    "@id": "https://oecd.ai/incident/OECD-2026-241",
    "incident_id": "OECD-2026-241",
    "title": "AI System Failure Related to AI Chatbots Reportedly Inaccurately Conveyed Real-Time Political News",
    "description": "An AI system failure occurred with similar characteristics to the documented incident involving Perplexity. The system exhibited comparable failure modes resulting in harm to affected stakeholders.",
    "date": "2026-01-29",
    "aiSystem": {
      "@type": "oecd:AISystem",
      "name": "AI System",
      "version": "4.9",
      "relation": [
        "oecd:DirectCause"
      ]
    },
    "developer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/Perplexity",
      "name": "Perplexity"
    },
    "deployer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/Perplexity",
      "name": "Perplexity"
    },
    "severity": "oecd:SeriousIncident",
    "harmType": [
      "oecd:OtherHarm"
    ],
    "harmQuantification": {
      "@type": "oecd:HarmQuantification",
      "affected_stakeholders": "37557 individuals",
      "economic_losses": "$9 million"
    },
    "countries": [
      {
        "@type": "core:Country",
        "@id": "https://www.wikidata.org/wiki/Netherlands",
        "name": "Netherlands"
      }
    ],
    "affectedStakeholders": [
      {
        "@type": "core:Person",
        "@id": "https://example.org/entities/person/journalism",
        "name": "Journalism"
      },
      {
        "@type": "oecd:StakeholderGroup",
        "@id": "https://example.org/stakeholder-group/general-public",
        "name": "General public"
      },
      {
        "@type": "oecd:StakeholderGroup",
        "@id": "https://example.org/stakeholder-group/chatbot-users",
        "name": "Chatbot users"
      }
    ],
    "businessFunction": [
      "oecd:Compliance"
    ],
    "submitter": {
      "@type": "oecd:Submitter",
      "@id": "https://example.org/submitter/submitter",
      "role": "Ethics Officer",
      "affiliation": "AI Safety Institute",
      "stakeholderGroup": "I represent a government or regulatory body",
      "relationToIncident": "I am a user of the related AI system"
    },
    "unintendedUse": false,
    "sameAs": "https://incidentdatabase.ai/cite/750"
  },
  {
    "@context": [
      "http://localhost:3000/api/schemas/v1/core/context.jsonld",
      "http://localhost:3001/api/schemas/v1/oecd/context.jsonld"
    ],
    "@type": "oecd:Incident",
    "@id": "https://oecd.ai/incident/OECD-2026-242",
    "incident_id": "OECD-2026-242",
    "title": "AI System Failure Related to AI Chatbots Reportedly Inaccurately Conveyed Real-Time Political News",
    "description": "An AI system failure occurred with similar characteristics to the documented incident involving Perplexity. The system exhibited comparable failure modes resulting in harm to affected stakeholders.",
    "date": "2026-02-21",
    "aiSystem": {
      "@type": "oecd:AISystem",
      "name": "AI System",
      "version": "2.2",
      "relation": [
        "oecd:DirectCause"
      ]
    },
    "developer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/Perplexity",
      "name": "Perplexity"
    },
    "deployer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/Perplexity",
      "name": "Perplexity"
    },
    "severity": "oecd:SeriousIncident",
    "harmType": [
      "oecd:OtherHarm"
    ],
    "harmQuantification": {
      "@type": "oecd:HarmQuantification",
      "affected_stakeholders": "47481 individuals",
      "economic_losses": "$1 million"
    },
    "countries": [
      {
        "@type": "core:Country",
        "@id": "https://www.wikidata.org/wiki/South_Korea",
        "name": "South Korea"
      }
    ],
    "affectedStakeholders": [
      {
        "@type": "core:Person",
        "@id": "https://example.org/entities/person/journalism",
        "name": "Journalism"
      },
      {
        "@type": "oecd:StakeholderGroup",
        "@id": "https://example.org/stakeholder-group/general-public",
        "name": "General public"
      },
      {
        "@type": "oecd:StakeholderGroup",
        "@id": "https://example.org/stakeholder-group/chatbot-users",
        "name": "Chatbot users"
      }
    ],
    "businessFunction": [
      "oecd:Production",
      "oecd:Procurement"
    ],
    "submitter": {
      "@type": "oecd:Submitter",
      "@id": "https://example.org/submitter/submitter",
      "role": "Ethics Officer",
      "affiliation": "AI Safety Institute",
      "stakeholderGroup": "I represent a government or regulatory body",
      "relationToIncident": "I am a user of the related AI system"
    },
    "unintendedUse": true,
    "sameAs": "https://incidentdatabase.ai/cite/750"
  },
  {
    "@context": [
      "http://localhost:3000/api/schemas/v1/core/context.jsonld",
      "http://localhost:3001/api/schemas/v1/oecd/context.jsonld"
    ],
    "@type": "oecd:Incident",
    "@id": "https://oecd.ai/incident/OECD-2026-243",
    "incident_id": "OECD-2026-243",
    "title": "AI System Failure Related to British Female Politicians Victimized by Deepfake Pornography",
    "description": "An AI system failure occurred with similar characteristics to the documented incident involving Unknown deepfake creators. The system exhibited comparable failure modes resulting in harm to affected stakeholders.",
    "date": "2026-03-12",
    "aiSystem": {
      "@type": "oecd:AISystem",
      "name": "Smart System",
      "version": "2.3",
      "relation": [
        "oecd:DirectCause"
      ]
    },
    "developer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/Unknown_deepfake_creators",
      "name": "Unknown deepfake creators"
    },
    "deployer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/Unknown_deepfake_creators",
      "name": "Unknown deepfake creators"
    },
    "severity": "oecd:SeriousIncident",
    "harmType": [
      "oecd:OtherHarm"
    ],
    "harmQuantification": {
      "@type": "oecd:HarmQuantification",
      "affected_stakeholders": "31883 individuals"
    },
    "countries": [
      {
        "@type": "core:Country",
        "@id": "https://www.wikidata.org/wiki/Australia",
        "name": "Australia"
      },
      {
        "@type": "core:Country",
        "@id": "https://www.wikidata.org/wiki/France",
        "name": "France"
      },
      {
        "@type": "core:Country",
        "@id": "https://www.wikidata.org/wiki/Canada",
        "name": "Canada"
      }
    ],
    "affectedStakeholders": [
      {
        "@type": "core:Person",
        "@id": "https://example.org/entities/person/stella-creasy",
        "name": "Stella Creasy"
      },
      {
        "@type": "core:Person",
        "@id": "https://example.org/entities/person/priti-patel",
        "name": "Priti Patel"
      },
      {
        "@type": "core:Person",
        "@id": "https://example.org/entities/person/penny-mordaunt",
        "name": "Penny Mordaunt"
      },
      {
        "@type": "core:Person",
        "@id": "https://example.org/entities/person/gillian-keegan",
        "name": "Gillian Keegan"
      },
      {
        "@type": "core:Person",
        "@id": "https://example.org/entities/person/dehenna-davison",
        "name": "Dehenna Davison"
      },
      {
        "@type": "core:Person",
        "@id": "https://example.org/entities/person/angela-rayner",
        "name": "Angela Rayner"
      }
    ],
    "businessFunction": [
      "oecd:HRManagement",
      "oecd:Production"
    ],
    "submitter": {
      "@type": "oecd:Submitter",
      "@id": "https://example.org/submitter/submitter",
      "role": "Academic Researcher",
      "affiliation": "AI Safety Institute",
      "stakeholderGroup": "None of the above, but have partial or substantial knowledge of the incident",
      "relationToIncident": "I am a user of the related AI system"
    },
    "unintendedUse": true,
    "sameAs": "https://incidentdatabase.ai/cite/754"
  },
  {
    "@context": [
      "http://localhost:3000/api/schemas/v1/core/context.jsonld",
      "http://localhost:3001/api/schemas/v1/oecd/context.jsonld"
    ],
    "@type": "oecd:Incident",
    "@id": "https://oecd.ai/incident/OECD-2026-244",
    "incident_id": "OECD-2026-244",
    "title": "AI System Failure Related to Deepfake of Kamala Harris Saying Damaging Comments Circulates on X and Is Amplified by Elon Musk",
    "description": "An AI system failure occurred with similar characteristics to the documented incident involving X (Twitter). The system exhibited comparable failure modes resulting in harm to affected stakeholders.",
    "date": "2026-04-19",
    "aiSystem": {
      "@type": "oecd:AISystem",
      "name": "Smart Solution",
      "version": "4.4",
      "relation": [
        "oecd:DirectCause"
      ]
    },
    "developer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/X_(Twitter)",
      "name": "X (Twitter)"
    },
    "deployer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/X_(Twitter)",
      "name": "X (Twitter)"
    },
    "severity": "oecd:SeriousIncident",
    "harmType": [
      "oecd:OtherHarm"
    ],
    "harmQuantification": {
      "@type": "oecd:HarmQuantification",
      "affected_stakeholders": "46641 individuals"
    },
    "countries": [
      {
        "@type": "core:Country",
        "@id": "https://www.wikidata.org/wiki/Canada",
        "name": "Canada"
      }
    ],
    "affectedStakeholders": [
      {
        "@type": "core:Person",
        "@id": "https://example.org/entities/person/truth",
        "name": "Truth"
      },
      {
        "@type": "core:Person",
        "@id": "https://example.org/entities/person/kamala-harris",
        "name": "Kamala Harris"
      },
      {
        "@type": "core:Person",
        "@id": "https://example.org/entities/person/joe-biden",
        "name": "Joe Biden"
      },
      {
        "@type": "oecd:StakeholderGroup",
        "@id": "https://example.org/stakeholder-group/general-public",
        "name": "General public"
      },
      {
        "@type": "core:Person",
        "@id": "https://example.org/entities/person/american-voters",
        "name": "American voters"
      }
    ],
    "businessFunction": [
      "oecd:Procurement"
    ],
    "submitter": {
      "@type": "oecd:Submitter",
      "@id": "https://example.org/submitter/submitter",
      "role": "Journalist",
      "affiliation": "Tech Policy Center",
      "stakeholderGroup": "I work or am affiliated to a public interest body or NGO",
      "relationToIncident": "I am an affected stakeholder"
    },
    "unintendedUse": true,
    "sameAs": "https://incidentdatabase.ai/cite/756"
  },
  {
    "@context": [
      "http://localhost:3000/api/schemas/v1/core/context.jsonld",
      "http://localhost:3001/api/schemas/v1/oecd/context.jsonld"
    ],
    "@type": "oecd:Incident",
    "@id": "https://oecd.ai/incident/OECD-2026-245",
    "incident_id": "OECD-2026-245",
    "title": "AI System Failure Related to Deepfake of Kamala Harris Saying Damaging Comments Circulates on X and Is Amplified by Elon Musk",
    "description": "An AI system failure occurred with similar characteristics to the documented incident involving X (Twitter). The system exhibited comparable failure modes resulting in harm to affected stakeholders.",
    "date": "2026-05-03",
    "aiSystem": {
      "@type": "oecd:AISystem",
      "name": "Intelligent Solution",
      "version": "2.2",
      "relation": [
        "oecd:DirectCause"
      ]
    },
    "developer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/X_(Twitter)",
      "name": "X (Twitter)"
    },
    "deployer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/X_(Twitter)",
      "name": "X (Twitter)"
    },
    "severity": "oecd:SeriousIncident",
    "harmType": [
      "oecd:OtherHarm"
    ],
    "harmQuantification": {
      "@type": "oecd:HarmQuantification",
      "affected_stakeholders": "31658 individuals"
    },
    "countries": [
      {
        "@type": "core:Country",
        "@id": "https://www.wikidata.org/wiki/Canada",
        "name": "Canada"
      }
    ],
    "affectedStakeholders": [
      {
        "@type": "core:Person",
        "@id": "https://example.org/entities/person/truth",
        "name": "Truth"
      },
      {
        "@type": "core:Person",
        "@id": "https://example.org/entities/person/kamala-harris",
        "name": "Kamala Harris"
      },
      {
        "@type": "core:Person",
        "@id": "https://example.org/entities/person/joe-biden",
        "name": "Joe Biden"
      },
      {
        "@type": "oecd:StakeholderGroup",
        "@id": "https://example.org/stakeholder-group/general-public",
        "name": "General public"
      },
      {
        "@type": "core:Person",
        "@id": "https://example.org/entities/person/american-voters",
        "name": "American voters"
      }
    ],
    "businessFunction": [
      "oecd:HRManagement"
    ],
    "submitter": {
      "@type": "oecd:Submitter",
      "@id": "https://example.org/submitter/submitter",
      "role": "AI Safety Researcher",
      "affiliation": "AI Safety Institute",
      "stakeholderGroup": "None of the above, but have partial or substantial knowledge of the incident",
      "relationToIncident": "I am an affected stakeholder"
    },
    "unintendedUse": false,
    "sameAs": "https://incidentdatabase.ai/cite/756"
  },
  {
    "@context": [
      "http://localhost:3000/api/schemas/v1/core/context.jsonld",
      "http://localhost:3001/api/schemas/v1/oecd/context.jsonld"
    ],
    "@type": "oecd:Incident",
    "@id": "https://oecd.ai/incident/OECD-2026-246",
    "incident_id": "OECD-2026-246",
    "title": "AI System Failure Related to Class Action Lawsuit Over Alleged Defects in Volkswagen's AI-Driven AEB Systems",
    "description": "An AI system failure occurred with similar characteristics to the documented incident involving Volkswagen Group of America. The system exhibited comparable failure modes resulting in harm to affected stakeholders.",
    "date": "2026-07-22",
    "aiSystem": {
      "@type": "oecd:AISystem",
      "name": "AI Solution",
      "version": "4.1",
      "relation": [
        "oecd:DirectCause"
      ]
    },
    "developer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/Volkswagen_Group_of_America",
      "name": "Volkswagen Group of America"
    },
    "deployer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/Volkswagen_Group_of_America",
      "name": "Volkswagen Group of America"
    },
    "severity": "oecd:SeriousIncident",
    "harmType": [
      "oecd:OtherHarm"
    ],
    "harmQuantification": {
      "@type": "oecd:HarmQuantification",
      "affected_stakeholders": "23934 individuals",
      "economic_losses": "$10 million"
    },
    "countries": [
      {
        "@type": "core:Country",
        "@id": "https://www.wikidata.org/wiki/Mexico",
        "name": "Mexico"
      },
      {
        "@type": "core:Country",
        "@id": "https://www.wikidata.org/wiki/France",
        "name": "France"
      },
      {
        "@type": "core:Country",
        "@id": "https://www.wikidata.org/wiki/Netherlands",
        "name": "Netherlands"
      }
    ],
    "affectedStakeholders": [
      {
        "@type": "core:Person",
        "@id": "https://example.org/entities/person/volkswagen-drivers",
        "name": "Volkswagen drivers"
      },
      {
        "@type": "oecd:StakeholderGroup",
        "@id": "https://example.org/stakeholder-group/potential-passengers-and-road-users-at-risk-due-to-malfunctioning-aeb-systems",
        "name": "Potential passengers and road users at risk due to malfunctioning AEB systems"
      }
    ],
    "businessFunction": [
      "oecd:QualityControl"
    ],
    "submitter": {
      "@type": "oecd:Submitter",
      "@id": "https://example.org/submitter/submitter",
      "role": "AI Safety Researcher",
      "affiliation": "Digital Rights Foundation",
      "stakeholderGroup": "I represent a government or regulatory body",
      "relationToIncident": "I am a user of the related AI system"
    },
    "unintendedUse": false,
    "sameAs": "https://incidentdatabase.ai/cite/746"
  },
  {
    "@context": [
      "http://localhost:3000/api/schemas/v1/core/context.jsonld",
      "http://localhost:3001/api/schemas/v1/oecd/context.jsonld"
    ],
    "@type": "oecd:Incident",
    "@id": "https://oecd.ai/incident/OECD-2026-247",
    "incident_id": "OECD-2026-247",
    "title": "AI System Failure Related to AI Chatbots Reportedly Inaccurately Conveyed Real-Time Political News",
    "description": "An AI system failure occurred with similar characteristics to the documented incident involving Perplexity. The system exhibited comparable failure modes resulting in harm to affected stakeholders.",
    "date": "2026-09-24",
    "aiSystem": {
      "@type": "oecd:AISystem",
      "name": "AI Solution",
      "version": "4.5",
      "relation": [
        "oecd:DirectCause"
      ]
    },
    "developer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/Perplexity",
      "name": "Perplexity"
    },
    "deployer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/Perplexity",
      "name": "Perplexity"
    },
    "severity": "oecd:SeriousIncident",
    "harmType": [
      "oecd:OtherHarm"
    ],
    "harmQuantification": {
      "@type": "oecd:HarmQuantification",
      "affected_stakeholders": "1659 individuals",
      "economic_losses": "$5 million"
    },
    "countries": [
      {
        "@type": "core:Country",
        "@id": "https://www.wikidata.org/wiki/China",
        "name": "China"
      },
      {
        "@type": "core:Country",
        "@id": "https://www.wikidata.org/wiki/Canada",
        "name": "Canada"
      },
      {
        "@type": "core:Country",
        "@id": "https://www.wikidata.org/wiki/United_States",
        "name": "United States"
      }
    ],
    "affectedStakeholders": [
      {
        "@type": "core:Person",
        "@id": "https://example.org/entities/person/journalism",
        "name": "Journalism"
      },
      {
        "@type": "oecd:StakeholderGroup",
        "@id": "https://example.org/stakeholder-group/general-public",
        "name": "General public"
      },
      {
        "@type": "oecd:StakeholderGroup",
        "@id": "https://example.org/stakeholder-group/chatbot-users",
        "name": "Chatbot users"
      }
    ],
    "businessFunction": [
      "oecd:Procurement",
      "oecd:Planning"
    ],
    "submitter": {
      "@type": "oecd:Submitter",
      "@id": "https://example.org/submitter/submitter",
      "role": "AI Safety Researcher",
      "affiliation": "Tech Policy Center",
      "stakeholderGroup": "I represent a government or regulatory body",
      "relationToIncident": "I am an affected stakeholder"
    },
    "unintendedUse": true,
    "sameAs": "https://incidentdatabase.ai/cite/750"
  },
  {
    "@context": [
      "http://localhost:3000/api/schemas/v1/core/context.jsonld",
      "http://localhost:3001/api/schemas/v1/oecd/context.jsonld"
    ],
    "@type": "oecd:Incident",
    "@id": "https://oecd.ai/incident/OECD-2026-248",
    "incident_id": "OECD-2026-248",
    "title": "AI System Failure Related to AI Chatbots Reportedly Inaccurately Conveyed Real-Time Political News",
    "description": "An AI system failure occurred with similar characteristics to the documented incident involving Perplexity. The system exhibited comparable failure modes resulting in harm to affected stakeholders.",
    "date": "2026-10-04",
    "aiSystem": {
      "@type": "oecd:AISystem",
      "name": "Intelligent System",
      "version": "5.7",
      "relation": [
        "oecd:DirectCause"
      ]
    },
    "developer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/Perplexity",
      "name": "Perplexity"
    },
    "deployer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/Perplexity",
      "name": "Perplexity"
    },
    "severity": "oecd:SeriousIncident",
    "harmType": [
      "oecd:OtherHarm"
    ],
    "harmQuantification": {
      "@type": "oecd:HarmQuantification",
      "affected_stakeholders": "34695 individuals",
      "economic_losses": "$7 million"
    },
    "countries": [
      {
        "@type": "core:Country",
        "@id": "https://www.wikidata.org/wiki/United_Kingdom",
        "name": "United Kingdom"
      }
    ],
    "affectedStakeholders": [
      {
        "@type": "core:Person",
        "@id": "https://example.org/entities/person/journalism",
        "name": "Journalism"
      },
      {
        "@type": "oecd:StakeholderGroup",
        "@id": "https://example.org/stakeholder-group/general-public",
        "name": "General public"
      },
      {
        "@type": "oecd:StakeholderGroup",
        "@id": "https://example.org/stakeholder-group/chatbot-users",
        "name": "Chatbot users"
      }
    ],
    "businessFunction": [
      "oecd:CustomerService",
      "oecd:Accounting"
    ],
    "submitter": {
      "@type": "oecd:Submitter",
      "@id": "https://example.org/submitter/submitter",
      "role": "Industry Analyst",
      "affiliation": "Government Oversight Committee",
      "stakeholderGroup": "I represent a government or regulatory body",
      "relationToIncident": "I am an affected stakeholder"
    },
    "unintendedUse": false,
    "sameAs": "https://incidentdatabase.ai/cite/750"
  },
  {
    "@context": [
      "http://localhost:3000/api/schemas/v1/core/context.jsonld",
      "http://localhost:3001/api/schemas/v1/oecd/context.jsonld"
    ],
    "@type": "oecd:Incident",
    "@id": "https://oecd.ai/incident/OECD-2026-249",
    "incident_id": "OECD-2026-249",
    "title": "AI System Failure Related to Deepfake of Kamala Harris Saying Damaging Comments Circulates on X and Is Amplified by Elon Musk",
    "description": "An AI system failure occurred with similar characteristics to the documented incident involving X (Twitter). The system exhibited comparable failure modes resulting in harm to affected stakeholders.",
    "date": "2026-11-09",
    "aiSystem": {
      "@type": "oecd:AISystem",
      "name": "Intelligent System",
      "version": "3.7",
      "relation": [
        "oecd:DirectCause"
      ]
    },
    "developer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/X_(Twitter)",
      "name": "X (Twitter)"
    },
    "deployer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/X_(Twitter)",
      "name": "X (Twitter)"
    },
    "severity": "oecd:SeriousIncident",
    "harmType": [
      "oecd:OtherHarm"
    ],
    "harmQuantification": {
      "@type": "oecd:HarmQuantification",
      "affected_stakeholders": "8267 individuals",
      "economic_losses": "$9 million"
    },
    "countries": [
      {
        "@type": "core:Country",
        "@id": "https://www.wikidata.org/wiki/Mexico",
        "name": "Mexico"
      },
      {
        "@type": "core:Country",
        "@id": "https://www.wikidata.org/wiki/Canada",
        "name": "Canada"
      }
    ],
    "affectedStakeholders": [
      {
        "@type": "core:Person",
        "@id": "https://example.org/entities/person/truth",
        "name": "Truth"
      },
      {
        "@type": "core:Person",
        "@id": "https://example.org/entities/person/kamala-harris",
        "name": "Kamala Harris"
      },
      {
        "@type": "core:Person",
        "@id": "https://example.org/entities/person/joe-biden",
        "name": "Joe Biden"
      },
      {
        "@type": "oecd:StakeholderGroup",
        "@id": "https://example.org/stakeholder-group/general-public",
        "name": "General public"
      },
      {
        "@type": "core:Person",
        "@id": "https://example.org/entities/person/american-voters",
        "name": "American voters"
      }
    ],
    "businessFunction": [
      "oecd:ICTManagement"
    ],
    "submitter": {
      "@type": "oecd:Submitter",
      "@id": "https://example.org/submitter/submitter",
      "role": "Ethics Officer",
      "affiliation": "Digital Rights Foundation",
      "stakeholderGroup": "I work or am affiliated to a public interest body or NGO",
      "relationToIncident": "I am a user of the related AI system"
    },
    "unintendedUse": false,
    "sameAs": "https://incidentdatabase.ai/cite/756"
  },
  {
    "@context": [
      "http://localhost:3000/api/schemas/v1/core/context.jsonld",
      "http://localhost:3001/api/schemas/v1/oecd/context.jsonld"
    ],
    "@type": "oecd:Incident",
    "@id": "https://oecd.ai/incident/OECD-2026-250",
    "incident_id": "OECD-2026-250",
    "title": "AI System Failure Related to Class Action Lawsuit Over Alleged Defects in Volkswagen's AI-Driven AEB Systems",
    "description": "An AI system failure occurred with similar characteristics to the documented incident involving Volkswagen Group of America. The system exhibited comparable failure modes resulting in harm to affected stakeholders.",
    "date": "2026-11-25",
    "aiSystem": {
      "@type": "oecd:AISystem",
      "name": "Intelligent Solution",
      "version": "5.0",
      "relation": [
        "oecd:DirectCause"
      ]
    },
    "developer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/Volkswagen_Group_of_America",
      "name": "Volkswagen Group of America"
    },
    "deployer": {
      "@type": "core:Organization",
      "@id": "https://en.wikipedia.org/wiki/Volkswagen_Group_of_America",
      "name": "Volkswagen Group of America"
    },
    "severity": "oecd:SeriousIncident",
    "harmType": [
      "oecd:OtherHarm"
    ],
    "harmQuantification": {
      "@type": "oecd:HarmQuantification",
      "affected_stakeholders": "28578 individuals"
    },
    "countries": [
      {
        "@type": "core:Country",
        "@id": "https://www.wikidata.org/wiki/South_Korea",
        "name": "South Korea"
      },
      {
        "@type": "core:Country",
        "@id": "https://www.wikidata.org/wiki/Singapore",
        "name": "Singapore"
      },
      {
        "@type": "core:Country",
        "@id": "https://www.wikidata.org/wiki/Israel",
        "name": "Israel"
      }
    ],
    "affectedStakeholders": [
      {
        "@type": "core:Person",
        "@id": "https://example.org/entities/person/volkswagen-drivers",
        "name": "Volkswagen drivers"
      },
      {
        "@type": "oecd:StakeholderGroup",
        "@id": "https://example.org/stakeholder-group/potential-passengers-and-road-users-at-risk-due-to-malfunctioning-aeb-systems",
        "name": "Potential passengers and road users at risk due to malfunctioning AEB systems"
      }
    ],
    "businessFunction": [
      "oecd:QualityControl"
    ],
    "submitter": {
      "@type": "oecd:Submitter",
      "@id": "https://example.org/submitter/submitter",
      "role": "AI Safety Researcher",
      "affiliation": "AI Safety Institute",
      "stakeholderGroup": "I represent a government or regulatory body",
      "relationToIncident": "I am a user of the related AI system"
    },
    "unintendedUse": true,
    "sameAs": "https://incidentdatabase.ai/cite/746"
  }
]